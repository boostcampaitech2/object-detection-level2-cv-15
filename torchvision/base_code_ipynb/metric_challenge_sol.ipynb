{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"detection","language":"python","name":"detection"},"colab":{"name":"metric_challenge_sol.ipynb","provenance":[{"file_id":"1o9gJfmLbnXXccSF8FgAec1exQ3730aUp","timestamp":1632718173451}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","execution_count":1,"source":["!pip install tqdm\n","!pip install pycocotools"],"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /opt/conda/envs/detection/lib/python3.7/site-packages (4.62.3)\n","Requirement already satisfied: pycocotools in /opt/conda/envs/detection/lib/python3.7/site-packages (2.0.2)\n","Requirement already satisfied: cython>=0.27.3 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools) (0.29.24)\n","Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools) (3.4.3)\n","Requirement already satisfied: setuptools>=18.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from pycocotools) (58.0.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (8.3.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n","Requirement already satisfied: numpy>=1.16 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.20.3)\n","Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/detection/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n","Requirement already satisfied: six in /opt/conda/envs/detection/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"]}],"metadata":{"id":"8c7dbb27"}},{"cell_type":"code","execution_count":2,"source":["import pandas as pd\n","import numpy as np\n","import json\n","from tqdm import tqdm\n","from pycocotools.coco import COCO"],"outputs":[],"metadata":{"id":"0c243d84"}},{"cell_type":"code","execution_count":4,"source":["GT_JSON = '/opt/ml/detection/dataset/train.json'\n","PRED_CSV = '/opt/ml/detection/faster_rcnn/faster_rcnn_scratch_submission.csv'\n","\n","\n","    \n","# load ground truth\n","with open(GT_JSON, 'r') as outfile:\n","    test_anno = (json.load(outfile))\n","\n","# load prediction\n","pred_df = pd.read_csv(PRED_CSV)\n","\n","   "],"outputs":[],"metadata":{"id":"239e1778"}},{"cell_type":"code","execution_count":5,"source":["'''\n","[\n","    [file_name 1, confidence_score, x_min, x_max, y_min, y_max], \n","    [file_name 2 confidence_score, x_min, x_max, y_min, y_max],\n","    ,,,\n","    [file_name , confidence_score, x_min, x_max, y_min, y_max]\n","]\n","'''\n","    \n","new_pred = []\n","\n","file_names = pred_df['image_id'].values.tolist()\n","bboxes = pred_df['PredictionString'].values.tolist()\n","    \n","'''\n","create new_pred\n","'''\n","    \n","for i, bbox in enumerate(bboxes):\n","    if isinstance(bbox, float):\n","        print(f'{file_names[i]} empty box')\n","\n","for file_name, bbox in tqdm(zip(file_names, bboxes)):\n","    boxes = np.array(str(bbox).split(' '))\n","    \n","    if len(boxes) % 6 == 1:\n","        boxes = boxes[:-1].reshape(-1, 6)\n","    elif len(boxes) % 6 == 0:\n","        boxes = boxes.reshape(-1, 6)\n","    else:\n","        raise Exception('error', 'invalid box count')\n","    for box in boxes:\n","        new_pred.append([file_name, box[0], box[1], float(box[2]), float(box[4]), float(box[3]), float(box[5])])"],"outputs":[{"output_type":"stream","name":"stdout","text":["test/1528.jpg empty box\n","test/4787.jpg empty box\n"]},{"output_type":"stream","name":"stderr","text":["4871it [00:00, 8976.15it/s]\n"]}],"metadata":{"id":"78d556fc"}},{"cell_type":"code","execution_count":6,"source":["'''\n","[\n","    [file_name 1, confidence_score, x_min, x_max, y_min, y_max], \n","    [file_name 2, confidence_score, x_min, x_max, y_min, y_max],\n","    ,,,\n","    [file_name , confidence_score, x_min, x_max, y_min, y_max]\n","]\n","'''\n","    \n","gt = []\n","\n","'''\n","create gt\n","'''\n","    \n","coco = COCO(GT_JSON)\n","   \n","'''\n","coco.getImgIds(): return image id list\n","    \n","coco.loadImgs(image_id): return image_info\n","    \n","image_info['file_name']: return file name\n","   \n","coco.getAnnIds(imgIds=image_info['id']): return annotation id\n","    \n","coco.loadAnns(ann_ids): return annotation information list (annotation_info_list)\n","    \n","annotation_info_list[i]['bbox']: return i'th annotation [x_min, y_min, w, h]\n","    \n","annotation_info_list[i]['category_id']: return i'th annotation category\n","    \n","'''\n","    \n","for image_id in coco.getImgIds():\n","        \n","    image_info = coco.loadImgs(image_id)[0]\n","    annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n","    annotation_info_list = coco.loadAnns(annotation_id)\n","        \n","    file_name = image_info['file_name']\n","        \n","    for annotation in annotation_info_list:\n","        gt.append([file_name, annotation['category_id'],\n","                   float(annotation['bbox'][0]),\n","                   float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n","                   float(annotation['bbox'][1]),\n","                   (float(annotation['bbox'][1]) + float(annotation['bbox'][3]))])"],"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=0.16s)\n","creating index...\n","index created!\n"]}],"metadata":{"id":"12e02aee"}},{"cell_type":"code","execution_count":7,"source":["def compute_overlap(boxes, query_boxes):\n","    \"\"\"\n","    Args\n","        a: (N, 4) ndarray of float\n","        b: (K, 4) ndarray of float\n","    Returns\n","        overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n","    \"\"\"\n","    N = boxes.shape[0]\n","    K = query_boxes.shape[0]\n","    overlaps = np.zeros((N, K), dtype=np.float64)\n","    for k in range(K):\n","        box_area = (\n","            (query_boxes[k, 2] - query_boxes[k, 0]) *\n","            (query_boxes[k, 3] - query_boxes[k, 1])\n","        )\n","        for n in range(N):\n","            iw = (\n","                min(boxes[n, 2], query_boxes[k, 2]) -\n","                max(boxes[n, 0], query_boxes[k, 0])\n","            )\n","            if iw > 0:\n","                ih = (\n","                    min(boxes[n, 3], query_boxes[k, 3]) -\n","                    max(boxes[n, 1], query_boxes[k, 1])\n","                )\n","                if ih > 0:\n","                    ua = np.float64(\n","                        (boxes[n, 2] - boxes[n, 0]) *\n","                        (boxes[n, 3] - boxes[n, 1]) +\n","                        box_area - iw * ih\n","                    )\n","                    overlaps[n, k] = iw * ih / ua\n","    return overlaps"],"outputs":[],"metadata":{"id":"5f828493"}},{"cell_type":"code","execution_count":8,"source":["def get_real_annotations(table):\n","    res = dict()\n","    ids = table['ImageID'].values.astype(np.str)\n","    labels = table['LabelName'].values.astype(np.str)\n","    xmin = table['XMin'].values.astype(np.float32)\n","    xmax = table['XMax'].values.astype(np.float32)\n","    ymin = table['YMin'].values.astype(np.float32)\n","    ymax = table['YMax'].values.astype(np.float32)\n","\n","    for i in range(len(ids)):\n","        id = ids[i]\n","        label = labels[i]\n","        if id not in res:\n","            res[id] = dict()\n","        if label not in res[id]:\n","            res[id][label] = []\n","        box = [xmin[i], ymin[i], xmax[i], ymax[i]]\n","        res[id][label].append(box)\n","\n","    return res\n","\n","\n","def get_detections(table):\n","    res = dict()\n","    ids = table['ImageID'].values.astype(np.str)\n","    labels = table['LabelName'].values.astype(np.str)\n","    scores = table['Conf'].values.astype(np.float32)\n","    xmin = table['XMin'].values.astype(np.float32)\n","    xmax = table['XMax'].values.astype(np.float32)\n","    ymin = table['YMin'].values.astype(np.float32)\n","    ymax = table['YMax'].values.astype(np.float32)\n","\n","    for i in range(len(ids)):\n","        id = ids[i]\n","        label = labels[i]\n","        if id not in res:\n","            res[id] = dict()\n","        if label not in res[id]:\n","            res[id][label] = []\n","        box = [xmin[i], ymin[i], xmax[i], ymax[i], scores[i]]\n","        res[id][label].append(box)\n","\n","    return res\n","\n","\n","def _compute_ap(recall, precision):\n","    \"\"\" Compute the average precision, given the recall and precision curves.\n","    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n","    # Arguments\n","        recall:    The recall curve (list).\n","        precision: The precision curve (list).\n","    # Returns\n","        The average precision as computed in py-faster-rcnn.\n","    \"\"\"\n","    # correct AP calculation\n","    # first append sentinel values at the end\n","    mrec = np.concatenate(([0.], recall, [1.]))\n","    mpre = np.concatenate(([0.], precision, [0.]))\n","\n","    # compute the precision envelope\n","    for i in range(mpre.size - 1, 0, -1):\n","        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n","\n","    # to calculate area under PR curve, look for points\n","    # where X axis (recall) changes value\n","    i = np.where(mrec[1:] != mrec[:-1])[0]\n","\n","    # and sum (\\Delta recall) * prec\n","    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n","    return ap"],"outputs":[],"metadata":{"id":"adbb4699"}},{"cell_type":"code","execution_count":10,"source":["def mean_average_precision_for_boxes(ann, pred, iou_threshold=0.5):\n","    \"\"\"\n","    :param ann: path to CSV-file with annotations or numpy array of shape (N, 6)\n","    :param pred: path to CSV-file with predictions (detections) or numpy array of shape (N, 7)\n","    :param iou_threshold: IoU between boxes which count as 'match'. Default: 0.5\n","    :return: tuple, where first value is mAP and second values is dict with AP for each class.\n","    \"\"\"\n","\n","    if isinstance(ann, str):\n","        valid = pd.read_csv(ann)\n","    else:\n","        valid = pd.DataFrame(ann, columns=['ImageID', 'LabelName', 'XMin', 'XMax', 'YMin', 'YMax'])\n","\n","    if isinstance(pred, str):\n","        preds = pd.read_csv(pred)\n","    else:\n","        preds = pd.DataFrame(pred, columns=['ImageID', 'LabelName', 'Conf', 'XMin', 'XMax', 'YMin', 'YMax'])\n","\n","    ann_unique = valid['ImageID'].unique()\n","    preds_unique = preds['ImageID'].unique()\n","\n","    print('Number of files in annotations: {}'.format(len(ann_unique)))\n","    print('Number of files in predictions: {}'.format(len(preds_unique)))\n","\n","\n","    unique_classes = valid['LabelName'].unique().astype(np.str)\n","    \n","    print('Unique classes: {}'.format(len(unique_classes)))\n","\n","    all_detections = get_detections(preds)\n","    all_annotations = get_real_annotations(valid)\n","    \n","    print('Detections length: {}'.format(len(all_detections)))\n","    print('Annotations length: {}'.format(len(all_annotations)))\n","\n","    average_precisions = {}\n","    for zz, label in enumerate(sorted(unique_classes)):\n","\n","        # Negative class\n","        if str(label) == 'nan':\n","            continue\n","\n","        false_positives = []\n","        true_positives = []\n","        scores = []\n","        num_annotations = 0.0\n","\n","        for i in range(len(ann_unique)):\n","            detections = []\n","            annotations = []\n","            id = ann_unique[i]\n","            if id in all_detections:\n","                if label in all_detections[id]:\n","                    detections = all_detections[id][label]\n","            if id in all_annotations:\n","                if label in all_annotations[id]:\n","                    annotations = all_annotations[id][label]\n","\n","            if len(detections) == 0 and len(annotations) == 0:\n","                continue\n","\n","            num_annotations += len(annotations)\n","            detected_annotations = []\n","\n","            annotations = np.array(annotations, dtype=np.float64)\n","            for d in detections:\n","                scores.append(d[4])\n","\n","                if len(annotations) == 0:\n","                    false_positives.append(1)\n","                    true_positives.append(0)\n","                    continue\n","\n","                overlaps = compute_overlap(np.expand_dims(np.array(d, dtype=np.float64), axis=0), annotations)\n","                assigned_annotation = np.argmax(overlaps, axis=1)\n","                max_overlap = overlaps[0, assigned_annotation]\n","\n","                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n","                    false_positives.append(0)\n","                    true_positives.append(1)\n","                    detected_annotations.append(assigned_annotation)\n","                else:\n","                    false_positives.append(1)\n","                    true_positives.append(0)\n","\n","        if num_annotations == 0:\n","            average_precisions[label] = 0, 0\n","            continue\n","\n","        false_positives = np.array(false_positives)\n","        true_positives = np.array(true_positives)\n","        scores = np.array(scores)\n","\n","        # sort by score\n","        indices = np.argsort(-scores)\n","        false_positives = false_positives[indices]\n","        true_positives = true_positives[indices]\n","\n","        # compute false positives and true positives\n","        false_positives = np.cumsum(false_positives)\n","        true_positives = np.cumsum(true_positives)\n","\n","        # compute recall and precision\n","        recall = true_positives / num_annotations\n","        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n","\n","        # compute average precision\n","        average_precision = _compute_ap(recall, precision)\n","        average_precisions[label] = average_precision, num_annotations\n","        s1 = \"{:30s} | {:.6f} | {:7d}\".format(label, average_precision, int(num_annotations))\n","        print(s1)\n","\n","    present_classes = 0\n","    precision = 0\n","    for label, (average_precision, num_annotations) in average_precisions.items():\n","        if num_annotations > 0:\n","            present_classes += 1\n","            precision += average_precision\n","            \n","    mean_ap = precision / present_classes\n","    print('mAP: {:.6f}'.format(mean_ap))\n","    \n","    return mean_ap, average_precisions"],"outputs":[],"metadata":{"id":"b3ae4b69"}},{"cell_type":"code","execution_count":11,"source":["'''\n","calculate mAP\n","'''\n","\n","mean_ap, average_precisions = mean_average_precision_for_boxes(gt, new_pred, iou_threshold=0.5)\n","\n","print(mean_ap)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Number of files in annotations: 4883\n","Number of files in predictions: 4869\n","Unique classes: 10\n"]},{"output_type":"stream","name":"stderr","text":["/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/opt/conda/envs/detection/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["Detections length: 4869\n","Annotations length: 4883\n","0                              | 0.000000 |    3966\n","1                              | 0.000000 |    6352\n","2                              | 0.000000 |     897\n","3                              | 0.000000 |     936\n","4                              | 0.000000 |     982\n","5                              | 0.000000 |    2943\n","6                              | 0.000000 |    1263\n","7                              | 0.000000 |    5178\n","8                              | 0.000000 |     159\n","9                              | 0.000000 |     468\n","mAP: 0.000000\n","0.0\n"]}],"metadata":{"id":"a0938f82"}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"id":"ef39d7ef"}}]}
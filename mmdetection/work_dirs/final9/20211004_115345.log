2021-10-04 11:53:46,703 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-SXM2-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.5.3
MMCV: 1.3.14
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.15.1+3ee336b
------------------------------------------------------------

2021-10-04 11:53:48,116 - mmdet - INFO - Distributed training: False
2021-10-04 11:53:49,529 - mmdet - INFO - Config:
model = dict(
    type='CascadeRCNN',
    backbone=dict(
        type='SwinTransformer',
        embed_dims=96,
        depths=[2, 2, 6, 2],
        num_heads=[3, 6, 12, 24],
        window_size=7,
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.2,
        patch_norm=True,
        out_indices=(0, 1, 2, 3),
        with_cp=False,
        convert_weights=True,
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'
        )),
    neck=dict(
        type='FPN',
        in_channels=[96, 192, 384, 768],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 0.7, 1.0, 1.5, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(
            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),
    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))
        ]),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=0,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=2000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=[
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.6,
                    neg_iou_thr=0.6,
                    min_pos_iou=0.6,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False),
            dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.7,
                    min_pos_iou=0.7,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100)))
dataset_type = 'CocoDataset'
data_root = '../dataset/'
classes = [
    'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
    'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'
]
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.0),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 1024),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.0),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file='../dataset/train.json',
        img_prefix='../dataset/',
        classes=[
            'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
            'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1024, 1024), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.0),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file='../dataset/train.json',
        img_prefix='../dataset/',
        classes=[
            'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
            'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.0),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='../dataset/test.json',
        img_prefix='../dataset/',
        classes=[
            'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
            'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 1024),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip', flip_ratio=0.0),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='bbox')
optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=5)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'
work_dir = './work_dirs/final9'
gpu_ids = range(0, 1)

2021-10-04 11:53:50,327 - mmdet - INFO - Use load_from_http loader
2021-10-04 11:53:50,454 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2021-10-04 11:53:50,476 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2021-10-04 11:53:50,484 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-10-04 11:53:50,800 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2021-10-04 11:53:51,117 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'layer': 'Linear', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 96, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CascadeRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([5, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([5]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([20, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([20]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_cls.weight - torch.Size([11, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.0.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.0.fc_reg.weight - torch.Size([4, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.0.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.0.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.0.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.0.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.1.fc_cls.weight - torch.Size([11, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.1.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.1.fc_reg.weight - torch.Size([4, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.1.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.1.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.1.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.1.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.2.fc_cls.weight - torch.Size([11, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.2.fc_cls.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.2.fc_reg.weight - torch.Size([4, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.2.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.2.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.2.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=normal, bias=0 

roi_head.bbox_head.2.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=normal, bias=0 
2021-10-04 11:53:54,662 - mmdet - INFO - Start running, host: root@b4c81fddccab, work_dir: /opt/ml/detection/mmdetection/work_dirs/final9
2021-10-04 11:53:54,662 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2021-10-04 11:53:54,662 - mmdet - INFO - workflow: [('train', 1)], max: 5 epochs
2021-10-04 11:54:40,325 - mmdet - INFO - Epoch [1][50/1221]	lr: 9.890e-05, eta: 1:32:06, time: 0.913, data_time: 0.055, memory: 12892, loss_rpn_cls: 0.6627, loss_rpn_bbox: 0.0554, s0.loss_cls: 1.2448, s0.acc: 78.4160, s0.loss_bbox: 0.0619, s1.loss_cls: 0.2869, s1.acc: 83.3398, s1.loss_bbox: 0.0151, s2.loss_cls: 0.2521, s2.acc: 71.4268, s2.loss_bbox: 0.0047, loss: 2.5836
2021-10-04 11:55:23,982 - mmdet - INFO - Epoch [1][100/1221]	lr: 1.988e-04, eta: 1:29:21, time: 0.873, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.4628, loss_rpn_bbox: 0.0560, s0.loss_cls: 0.3160, s0.acc: 95.6611, s0.loss_bbox: 0.1246, s1.loss_cls: 0.0861, s1.acc: 97.9453, s1.loss_bbox: 0.0370, s2.loss_cls: 0.0369, s2.acc: 98.2939, s2.loss_bbox: 0.0083, loss: 1.1278
2021-10-04 11:56:07,254 - mmdet - INFO - Epoch [1][150/1221]	lr: 2.987e-04, eta: 1:27:42, time: 0.865, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.2510, loss_rpn_bbox: 0.0568, s0.loss_cls: 0.2979, s0.acc: 94.7451, s0.loss_bbox: 0.1414, s1.loss_cls: 0.0838, s1.acc: 97.7217, s1.loss_bbox: 0.0366, s2.loss_cls: 0.0302, s2.acc: 98.6768, s2.loss_bbox: 0.0074, loss: 0.9050
2021-10-04 11:56:50,262 - mmdet - INFO - Epoch [1][200/1221]	lr: 3.986e-04, eta: 1:26:23, time: 0.860, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1552, loss_rpn_bbox: 0.0385, s0.loss_cls: 0.2645, s0.acc: 94.9316, s0.loss_bbox: 0.1370, s1.loss_cls: 0.0738, s1.acc: 97.7773, s1.loss_bbox: 0.0380, s2.loss_cls: 0.0249, s2.acc: 98.7979, s2.loss_bbox: 0.0074, loss: 0.7394
2021-10-04 11:57:33,237 - mmdet - INFO - Epoch [1][250/1221]	lr: 4.985e-04, eta: 1:25:18, time: 0.859, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1436, loss_rpn_bbox: 0.0418, s0.loss_cls: 0.2644, s0.acc: 94.5225, s0.loss_bbox: 0.1442, s1.loss_cls: 0.0749, s1.acc: 97.5762, s1.loss_bbox: 0.0414, s2.loss_cls: 0.0240, s2.acc: 98.7227, s2.loss_bbox: 0.0077, loss: 0.7420
2021-10-04 11:58:16,390 - mmdet - INFO - Epoch [1][300/1221]	lr: 5.984e-04, eta: 1:24:23, time: 0.863, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1816, loss_rpn_bbox: 0.0513, s0.loss_cls: 0.2985, s0.acc: 93.7520, s0.loss_bbox: 0.1577, s1.loss_cls: 0.0835, s1.acc: 97.2080, s1.loss_bbox: 0.0460, s2.loss_cls: 0.0279, s2.acc: 98.4434, s2.loss_bbox: 0.0085, loss: 0.8551
2021-10-04 11:58:59,440 - mmdet - INFO - Epoch [1][350/1221]	lr: 6.983e-04, eta: 1:23:30, time: 0.861, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1319, loss_rpn_bbox: 0.0373, s0.loss_cls: 0.2708, s0.acc: 94.1680, s0.loss_bbox: 0.1510, s1.loss_cls: 0.0770, s1.acc: 97.3496, s1.loss_bbox: 0.0464, s2.loss_cls: 0.0235, s2.acc: 98.6455, s2.loss_bbox: 0.0084, loss: 0.7465
2021-10-04 11:59:42,436 - mmdet - INFO - Epoch [1][400/1221]	lr: 7.982e-04, eta: 1:22:39, time: 0.860, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1653, loss_rpn_bbox: 0.0514, s0.loss_cls: 0.3187, s0.acc: 93.1182, s0.loss_bbox: 0.1747, s1.loss_cls: 0.0950, s1.acc: 96.7041, s1.loss_bbox: 0.0577, s2.loss_cls: 0.0296, s2.acc: 98.2764, s2.loss_bbox: 0.0105, loss: 0.9028
2021-10-04 12:00:25,590 - mmdet - INFO - Epoch [1][450/1221]	lr: 8.981e-04, eta: 1:21:52, time: 0.863, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1345, loss_rpn_bbox: 0.0432, s0.loss_cls: 0.2790, s0.acc: 93.9082, s0.loss_bbox: 0.1516, s1.loss_cls: 0.0839, s1.acc: 96.9502, s1.loss_bbox: 0.0538, s2.loss_cls: 0.0258, s2.acc: 98.4512, s2.loss_bbox: 0.0098, loss: 0.7817
2021-10-04 12:01:08,865 - mmdet - INFO - Epoch [1][500/1221]	lr: 9.980e-04, eta: 1:21:07, time: 0.865, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1115, loss_rpn_bbox: 0.0379, s0.loss_cls: 0.2813, s0.acc: 93.6084, s0.loss_bbox: 0.1589, s1.loss_cls: 0.0877, s1.acc: 96.7861, s1.loss_bbox: 0.0600, s2.loss_cls: 0.0246, s2.acc: 98.5166, s2.loss_bbox: 0.0100, loss: 0.7719
2021-10-04 12:01:51,776 - mmdet - INFO - Epoch [1][550/1221]	lr: 1.000e-03, eta: 1:20:18, time: 0.858, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1053, loss_rpn_bbox: 0.0435, s0.loss_cls: 0.2861, s0.acc: 93.4590, s0.loss_bbox: 0.1557, s1.loss_cls: 0.0912, s1.acc: 96.4717, s1.loss_bbox: 0.0627, s2.loss_cls: 0.0280, s2.acc: 98.2471, s2.loss_bbox: 0.0125, loss: 0.7850
2021-10-04 12:02:34,705 - mmdet - INFO - Epoch [1][600/1221]	lr: 1.000e-03, eta: 1:19:31, time: 0.859, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.1017, loss_rpn_bbox: 0.0407, s0.loss_cls: 0.2706, s0.acc: 93.6836, s0.loss_bbox: 0.1516, s1.loss_cls: 0.0905, s1.acc: 96.3555, s1.loss_bbox: 0.0663, s2.loss_cls: 0.0263, s2.acc: 98.3135, s2.loss_bbox: 0.0128, loss: 0.7604
2021-10-04 12:03:17,118 - mmdet - INFO - Epoch [1][650/1221]	lr: 1.000e-03, eta: 1:18:40, time: 0.848, data_time: 0.010, memory: 12892, loss_rpn_cls: 0.0946, loss_rpn_bbox: 0.0380, s0.loss_cls: 0.2727, s0.acc: 93.5479, s0.loss_bbox: 0.1494, s1.loss_cls: 0.0953, s1.acc: 96.0410, s1.loss_bbox: 0.0712, s2.loss_cls: 0.0291, s2.acc: 98.0635, s2.loss_bbox: 0.0151, loss: 0.7654
2021-10-04 12:03:59,617 - mmdet - INFO - Epoch [1][700/1221]	lr: 1.000e-03, eta: 1:17:50, time: 0.850, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0973, loss_rpn_bbox: 0.0460, s0.loss_cls: 0.2796, s0.acc: 93.5283, s0.loss_bbox: 0.1466, s1.loss_cls: 0.0959, s1.acc: 96.0635, s1.loss_bbox: 0.0695, s2.loss_cls: 0.0307, s2.acc: 97.9541, s2.loss_bbox: 0.0159, loss: 0.7815
2021-10-04 12:04:42,828 - mmdet - INFO - Epoch [1][750/1221]	lr: 1.000e-03, eta: 1:17:07, time: 0.864, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0912, loss_rpn_bbox: 0.0471, s0.loss_cls: 0.2894, s0.acc: 93.0117, s0.loss_bbox: 0.1606, s1.loss_cls: 0.1018, s1.acc: 95.7363, s1.loss_bbox: 0.0741, s2.loss_cls: 0.0333, s2.acc: 97.6924, s2.loss_bbox: 0.0180, loss: 0.8154
2021-10-04 12:05:25,875 - mmdet - INFO - Epoch [1][800/1221]	lr: 1.000e-03, eta: 1:16:23, time: 0.861, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0980, loss_rpn_bbox: 0.0543, s0.loss_cls: 0.2994, s0.acc: 92.8008, s0.loss_bbox: 0.1663, s1.loss_cls: 0.1095, s1.acc: 95.3047, s1.loss_bbox: 0.0818, s2.loss_cls: 0.0357, s2.acc: 97.5391, s2.loss_bbox: 0.0186, loss: 0.8635
2021-10-04 12:06:08,823 - mmdet - INFO - Epoch [1][850/1221]	lr: 1.000e-03, eta: 1:15:38, time: 0.859, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0778, loss_rpn_bbox: 0.0412, s0.loss_cls: 0.2759, s0.acc: 93.2959, s0.loss_bbox: 0.1523, s1.loss_cls: 0.1010, s1.acc: 95.5381, s1.loss_bbox: 0.0784, s2.loss_cls: 0.0334, s2.acc: 97.5908, s2.loss_bbox: 0.0203, loss: 0.7803
2021-10-04 12:06:51,956 - mmdet - INFO - Epoch [1][900/1221]	lr: 1.000e-03, eta: 1:14:55, time: 0.863, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0740, loss_rpn_bbox: 0.0400, s0.loss_cls: 0.2595, s0.acc: 93.7549, s0.loss_bbox: 0.1384, s1.loss_cls: 0.0981, s1.acc: 95.6768, s1.loss_bbox: 0.0745, s2.loss_cls: 0.0325, s2.acc: 97.6709, s2.loss_bbox: 0.0189, loss: 0.7359
2021-10-04 12:07:35,088 - mmdet - INFO - Epoch [1][950/1221]	lr: 1.000e-03, eta: 1:14:11, time: 0.863, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0907, loss_rpn_bbox: 0.0490, s0.loss_cls: 0.3085, s0.acc: 92.3760, s0.loss_bbox: 0.1687, s1.loss_cls: 0.1208, s1.acc: 94.4951, s1.loss_bbox: 0.0948, s2.loss_cls: 0.0422, s2.acc: 96.8145, s2.loss_bbox: 0.0261, loss: 0.9009
2021-10-04 12:08:18,094 - mmdet - INFO - Exp name: final9.py
2021-10-04 12:08:18,094 - mmdet - INFO - Epoch [1][1000/1221]	lr: 1.000e-03, eta: 1:13:27, time: 0.860, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0861, loss_rpn_bbox: 0.0458, s0.loss_cls: 0.3350, s0.acc: 91.3652, s0.loss_bbox: 0.1840, s1.loss_cls: 0.1315, s1.acc: 93.7246, s1.loss_bbox: 0.1070, s2.loss_cls: 0.0461, s2.acc: 96.4746, s2.loss_bbox: 0.0287, loss: 0.9642
2021-10-04 12:09:01,366 - mmdet - INFO - Epoch [1][1050/1221]	lr: 1.000e-03, eta: 1:12:44, time: 0.866, data_time: 0.013, memory: 12892, loss_rpn_cls: 0.0838, loss_rpn_bbox: 0.0507, s0.loss_cls: 0.3107, s0.acc: 92.1396, s0.loss_bbox: 0.1795, s1.loss_cls: 0.1210, s1.acc: 94.3467, s1.loss_bbox: 0.0970, s2.loss_cls: 0.0405, s2.acc: 96.9121, s2.loss_bbox: 0.0260, loss: 0.9092
2021-10-04 12:09:44,226 - mmdet - INFO - Epoch [1][1100/1221]	lr: 1.000e-03, eta: 1:12:00, time: 0.857, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0762, loss_rpn_bbox: 0.0455, s0.loss_cls: 0.2803, s0.acc: 92.6953, s0.loss_bbox: 0.1588, s1.loss_cls: 0.1133, s1.acc: 94.4043, s1.loss_bbox: 0.0936, s2.loss_cls: 0.0413, s2.acc: 96.6465, s2.loss_bbox: 0.0290, loss: 0.8379
2021-10-04 12:10:27,062 - mmdet - INFO - Epoch [1][1150/1221]	lr: 1.000e-03, eta: 1:11:15, time: 0.857, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0752, loss_rpn_bbox: 0.0443, s0.loss_cls: 0.3029, s0.acc: 92.2441, s0.loss_bbox: 0.1711, s1.loss_cls: 0.1212, s1.acc: 94.0957, s1.loss_bbox: 0.1008, s2.loss_cls: 0.0446, s2.acc: 96.3086, s2.loss_bbox: 0.0314, loss: 0.8915
2021-10-04 12:11:10,008 - mmdet - INFO - Epoch [1][1200/1221]	lr: 1.000e-03, eta: 1:10:31, time: 0.859, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0868, loss_rpn_bbox: 0.0455, s0.loss_cls: 0.3413, s0.acc: 91.1230, s0.loss_bbox: 0.1937, s1.loss_cls: 0.1361, s1.acc: 93.2383, s1.loss_bbox: 0.1141, s2.loss_cls: 0.0487, s2.acc: 95.8320, s2.loss_bbox: 0.0348, loss: 1.0009
2021-10-04 12:11:28,054 - mmdet - INFO - Saving checkpoint at 1 epochs
2021-10-04 12:18:02,547 - mmdet - INFO - Evaluating bbox...
2021-10-04 12:18:21,952 - mmdet - INFO - Exp name: final9.py
2021-10-04 12:18:21,957 - mmdet - INFO - Epoch(val) [1][4883]	bbox_mAP: 0.0280, bbox_mAP_50: 0.0740, bbox_mAP_75: 0.0160, bbox_mAP_s: 0.0000, bbox_mAP_m: 0.0020, bbox_mAP_l: 0.0350, bbox_mAP_copypaste: 0.028 0.074 0.016 0.000 0.002 0.035
2021-10-04 12:19:07,344 - mmdet - INFO - Epoch [2][50/1221]	lr: 1.000e-03, eta: 1:08:30, time: 0.907, data_time: 0.057, memory: 12892, loss_rpn_cls: 0.0715, loss_rpn_bbox: 0.0446, s0.loss_cls: 0.3194, s0.acc: 91.7393, s0.loss_bbox: 0.1805, s1.loss_cls: 0.1327, s1.acc: 93.4521, s1.loss_bbox: 0.1103, s2.loss_cls: 0.0492, s2.acc: 95.7441, s2.loss_bbox: 0.0368, loss: 0.9449
2021-10-04 12:19:50,401 - mmdet - INFO - Epoch [2][100/1221]	lr: 1.000e-03, eta: 1:07:49, time: 0.861, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0652, loss_rpn_bbox: 0.0383, s0.loss_cls: 0.2689, s0.acc: 92.9688, s0.loss_bbox: 0.1469, s1.loss_cls: 0.1173, s1.acc: 94.1191, s1.loss_bbox: 0.0980, s2.loss_cls: 0.0441, s2.acc: 96.0742, s2.loss_bbox: 0.0338, loss: 0.8125
2021-10-04 12:20:33,390 - mmdet - INFO - Epoch [2][150/1221]	lr: 1.000e-03, eta: 1:07:08, time: 0.860, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0697, loss_rpn_bbox: 0.0415, s0.loss_cls: 0.3050, s0.acc: 91.8389, s0.loss_bbox: 0.1699, s1.loss_cls: 0.1315, s1.acc: 93.2803, s1.loss_bbox: 0.1103, s2.loss_cls: 0.0507, s2.acc: 95.4219, s2.loss_bbox: 0.0393, loss: 0.9179
2021-10-04 12:21:16,702 - mmdet - INFO - Epoch [2][200/1221]	lr: 1.000e-03, eta: 1:06:28, time: 0.866, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0597, loss_rpn_bbox: 0.0397, s0.loss_cls: 0.3260, s0.acc: 91.3174, s0.loss_bbox: 0.1849, s1.loss_cls: 0.1393, s1.acc: 92.8350, s1.loss_bbox: 0.1202, s2.loss_cls: 0.0538, s2.acc: 95.0537, s2.loss_bbox: 0.0439, loss: 0.9674
2021-10-04 12:21:59,903 - mmdet - INFO - Epoch [2][250/1221]	lr: 1.000e-03, eta: 1:05:47, time: 0.864, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0686, loss_rpn_bbox: 0.0432, s0.loss_cls: 0.3024, s0.acc: 91.7070, s0.loss_bbox: 0.1752, s1.loss_cls: 0.1309, s1.acc: 93.2598, s1.loss_bbox: 0.1144, s2.loss_cls: 0.0517, s2.acc: 95.0293, s2.loss_bbox: 0.0435, loss: 0.9298
2021-10-04 12:22:43,371 - mmdet - INFO - Epoch [2][300/1221]	lr: 1.000e-03, eta: 1:05:07, time: 0.869, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0716, loss_rpn_bbox: 0.0444, s0.loss_cls: 0.3099, s0.acc: 91.8496, s0.loss_bbox: 0.1645, s1.loss_cls: 0.1382, s1.acc: 92.9941, s1.loss_bbox: 0.1129, s2.loss_cls: 0.0541, s2.acc: 95.1914, s2.loss_bbox: 0.0412, loss: 0.9367
2021-10-04 12:23:26,428 - mmdet - INFO - Epoch [2][350/1221]	lr: 1.000e-03, eta: 1:04:26, time: 0.861, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0640, loss_rpn_bbox: 0.0502, s0.loss_cls: 0.3040, s0.acc: 91.8076, s0.loss_bbox: 0.1730, s1.loss_cls: 0.1326, s1.acc: 93.0391, s1.loss_bbox: 0.1148, s2.loss_cls: 0.0534, s2.acc: 94.9971, s2.loss_bbox: 0.0442, loss: 0.9362
2021-10-04 12:24:09,502 - mmdet - INFO - Epoch [2][400/1221]	lr: 1.000e-03, eta: 1:03:45, time: 0.861, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0611, loss_rpn_bbox: 0.0404, s0.loss_cls: 0.3137, s0.acc: 91.5615, s0.loss_bbox: 0.1748, s1.loss_cls: 0.1371, s1.acc: 92.9297, s1.loss_bbox: 0.1188, s2.loss_cls: 0.0523, s2.acc: 95.1279, s2.loss_bbox: 0.0434, loss: 0.9416
2021-10-04 12:24:52,504 - mmdet - INFO - Epoch [2][450/1221]	lr: 1.000e-03, eta: 1:03:03, time: 0.860, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0558, loss_rpn_bbox: 0.0393, s0.loss_cls: 0.2925, s0.acc: 92.3750, s0.loss_bbox: 0.1564, s1.loss_cls: 0.1308, s1.acc: 93.4092, s1.loss_bbox: 0.1086, s2.loss_cls: 0.0513, s2.acc: 95.2129, s2.loss_bbox: 0.0430, loss: 0.8778
2021-10-04 12:25:35,517 - mmdet - INFO - Epoch [2][500/1221]	lr: 1.000e-03, eta: 1:02:21, time: 0.860, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0699, loss_rpn_bbox: 0.0474, s0.loss_cls: 0.3064, s0.acc: 91.7646, s0.loss_bbox: 0.1658, s1.loss_cls: 0.1365, s1.acc: 92.8682, s1.loss_bbox: 0.1155, s2.loss_cls: 0.0561, s2.acc: 94.6572, s2.loss_bbox: 0.0454, loss: 0.9430
2021-10-04 12:26:18,657 - mmdet - INFO - Epoch [2][550/1221]	lr: 1.000e-03, eta: 1:01:40, time: 0.863, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0671, loss_rpn_bbox: 0.0432, s0.loss_cls: 0.3032, s0.acc: 91.7168, s0.loss_bbox: 0.1668, s1.loss_cls: 0.1360, s1.acc: 92.7686, s1.loss_bbox: 0.1150, s2.loss_cls: 0.0545, s2.acc: 94.7168, s2.loss_bbox: 0.0450, loss: 0.9308
2021-10-04 12:27:01,589 - mmdet - INFO - Epoch [2][600/1221]	lr: 1.000e-03, eta: 1:00:57, time: 0.859, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0720, loss_rpn_bbox: 0.0498, s0.loss_cls: 0.3378, s0.acc: 90.9131, s0.loss_bbox: 0.1834, s1.loss_cls: 0.1502, s1.acc: 92.1260, s1.loss_bbox: 0.1229, s2.loss_cls: 0.0587, s2.acc: 94.2676, s2.loss_bbox: 0.0469, loss: 1.0216
2021-10-04 12:27:44,570 - mmdet - INFO - Epoch [2][650/1221]	lr: 1.000e-03, eta: 1:00:15, time: 0.860, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0578, loss_rpn_bbox: 0.0343, s0.loss_cls: 0.2829, s0.acc: 92.5049, s0.loss_bbox: 0.1450, s1.loss_cls: 0.1311, s1.acc: 93.1455, s1.loss_bbox: 0.1114, s2.loss_cls: 0.0535, s2.acc: 94.7031, s2.loss_bbox: 0.0469, loss: 0.8629
2021-10-04 12:28:27,465 - mmdet - INFO - Epoch [2][700/1221]	lr: 1.000e-03, eta: 0:59:33, time: 0.858, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0588, loss_rpn_bbox: 0.0383, s0.loss_cls: 0.2951, s0.acc: 91.9004, s0.loss_bbox: 0.1555, s1.loss_cls: 0.1388, s1.acc: 92.4414, s1.loss_bbox: 0.1143, s2.loss_cls: 0.0582, s2.acc: 94.1230, s2.loss_bbox: 0.0498, loss: 0.9087
2021-10-04 12:29:10,544 - mmdet - INFO - Epoch [2][750/1221]	lr: 1.000e-03, eta: 0:58:51, time: 0.862, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0674, loss_rpn_bbox: 0.0443, s0.loss_cls: 0.3039, s0.acc: 91.3057, s0.loss_bbox: 0.1706, s1.loss_cls: 0.1413, s1.acc: 92.2148, s1.loss_bbox: 0.1263, s2.loss_cls: 0.0592, s2.acc: 93.9502, s2.loss_bbox: 0.0513, loss: 0.9644
2021-10-04 12:29:53,746 - mmdet - INFO - Epoch [2][800/1221]	lr: 1.000e-03, eta: 0:58:09, time: 0.864, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0689, loss_rpn_bbox: 0.0526, s0.loss_cls: 0.3111, s0.acc: 91.2666, s0.loss_bbox: 0.1820, s1.loss_cls: 0.1419, s1.acc: 92.1592, s1.loss_bbox: 0.1328, s2.loss_cls: 0.0575, s2.acc: 94.1133, s2.loss_bbox: 0.0521, loss: 0.9988
2021-10-04 12:30:36,857 - mmdet - INFO - Epoch [2][850/1221]	lr: 1.000e-03, eta: 0:57:28, time: 0.862, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0653, loss_rpn_bbox: 0.0490, s0.loss_cls: 0.3157, s0.acc: 91.1162, s0.loss_bbox: 0.1812, s1.loss_cls: 0.1498, s1.acc: 91.7097, s1.loss_bbox: 0.1393, s2.loss_cls: 0.0626, s2.acc: 93.4051, s2.loss_bbox: 0.0593, loss: 1.0221
2021-10-04 12:31:20,186 - mmdet - INFO - Epoch [2][900/1221]	lr: 1.000e-03, eta: 0:56:46, time: 0.867, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0531, loss_rpn_bbox: 0.0419, s0.loss_cls: 0.2724, s0.acc: 92.6123, s0.loss_bbox: 0.1505, s1.loss_cls: 0.1256, s1.acc: 93.2100, s1.loss_bbox: 0.1056, s2.loss_cls: 0.0537, s2.acc: 94.6429, s2.loss_bbox: 0.0462, loss: 0.8490
2021-10-04 12:32:03,287 - mmdet - INFO - Epoch [2][950/1221]	lr: 1.000e-03, eta: 0:56:04, time: 0.862, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0578, loss_rpn_bbox: 0.0431, s0.loss_cls: 0.3084, s0.acc: 91.5264, s0.loss_bbox: 0.1684, s1.loss_cls: 0.1439, s1.acc: 92.0801, s1.loss_bbox: 0.1243, s2.loss_cls: 0.0600, s2.acc: 93.6475, s2.loss_bbox: 0.0534, loss: 0.9594
2021-10-04 12:32:46,448 - mmdet - INFO - Epoch [2][1000/1221]	lr: 1.000e-03, eta: 0:55:22, time: 0.863, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0535, loss_rpn_bbox: 0.0410, s0.loss_cls: 0.3015, s0.acc: 91.6523, s0.loss_bbox: 0.1627, s1.loss_cls: 0.1425, s1.acc: 92.3164, s1.loss_bbox: 0.1216, s2.loss_cls: 0.0607, s2.acc: 93.7354, s2.loss_bbox: 0.0509, loss: 0.9346
2021-10-04 12:33:29,599 - mmdet - INFO - Epoch [2][1050/1221]	lr: 1.000e-03, eta: 0:54:40, time: 0.863, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0615, loss_rpn_bbox: 0.0405, s0.loss_cls: 0.3150, s0.acc: 91.4971, s0.loss_bbox: 0.1707, s1.loss_cls: 0.1477, s1.acc: 92.1290, s1.loss_bbox: 0.1273, s2.loss_cls: 0.0621, s2.acc: 93.7875, s2.loss_bbox: 0.0551, loss: 0.9800
2021-10-04 12:34:12,724 - mmdet - INFO - Epoch [2][1100/1221]	lr: 1.000e-03, eta: 0:53:57, time: 0.862, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0565, loss_rpn_bbox: 0.0459, s0.loss_cls: 0.3220, s0.acc: 91.2861, s0.loss_bbox: 0.1788, s1.loss_cls: 0.1422, s1.acc: 92.3320, s1.loss_bbox: 0.1251, s2.loss_cls: 0.0593, s2.acc: 93.7178, s2.loss_bbox: 0.0533, loss: 0.9830
2021-10-04 12:34:55,827 - mmdet - INFO - Epoch [2][1150/1221]	lr: 1.000e-03, eta: 0:53:15, time: 0.862, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0602, loss_rpn_bbox: 0.0386, s0.loss_cls: 0.2949, s0.acc: 91.8135, s0.loss_bbox: 0.1582, s1.loss_cls: 0.1426, s1.acc: 92.0516, s1.loss_bbox: 0.1255, s2.loss_cls: 0.0602, s2.acc: 93.4960, s2.loss_bbox: 0.0563, loss: 0.9367
2021-10-04 12:35:38,894 - mmdet - INFO - Epoch [2][1200/1221]	lr: 1.000e-03, eta: 0:52:33, time: 0.861, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0485, loss_rpn_bbox: 0.0307, s0.loss_cls: 0.2885, s0.acc: 92.2500, s0.loss_bbox: 0.1488, s1.loss_cls: 0.1383, s1.acc: 92.7432, s1.loss_bbox: 0.1179, s2.loss_cls: 0.0615, s2.acc: 93.7295, s2.loss_bbox: 0.0537, loss: 0.8879
2021-10-04 12:35:56,995 - mmdet - INFO - Saving checkpoint at 2 epochs
2021-10-04 12:42:32,371 - mmdet - INFO - Evaluating bbox...
2021-10-04 12:42:54,358 - mmdet - INFO - Exp name: final9.py
2021-10-04 12:42:54,359 - mmdet - INFO - Epoch(val) [2][4883]	bbox_mAP: 0.1050, bbox_mAP_50: 0.2100, bbox_mAP_75: 0.0970, bbox_mAP_s: 0.0010, bbox_mAP_m: 0.0130, bbox_mAP_l: 0.1290, bbox_mAP_copypaste: 0.105 0.210 0.097 0.001 0.013 0.129
2021-10-04 12:43:39,954 - mmdet - INFO - Epoch [3][50/1221]	lr: 1.000e-03, eta: 0:51:10, time: 0.911, data_time: 0.057, memory: 12892, loss_rpn_cls: 0.0555, loss_rpn_bbox: 0.0439, s0.loss_cls: 0.3009, s0.acc: 91.4961, s0.loss_bbox: 0.1679, s1.loss_cls: 0.1384, s1.acc: 92.2603, s1.loss_bbox: 0.1273, s2.loss_cls: 0.0614, s2.acc: 93.2197, s2.loss_bbox: 0.0566, loss: 0.9520
2021-10-04 12:44:23,250 - mmdet - INFO - Epoch [3][100/1221]	lr: 1.000e-03, eta: 0:50:29, time: 0.866, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0537, loss_rpn_bbox: 0.0356, s0.loss_cls: 0.3008, s0.acc: 91.6387, s0.loss_bbox: 0.1615, s1.loss_cls: 0.1413, s1.acc: 92.3066, s1.loss_bbox: 0.1217, s2.loss_cls: 0.0613, s2.acc: 93.6309, s2.loss_bbox: 0.0545, loss: 0.9305
2021-10-04 12:45:06,509 - mmdet - INFO - Epoch [3][150/1221]	lr: 1.000e-03, eta: 0:49:47, time: 0.865, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0531, loss_rpn_bbox: 0.0448, s0.loss_cls: 0.2924, s0.acc: 91.7236, s0.loss_bbox: 0.1660, s1.loss_cls: 0.1410, s1.acc: 91.9886, s1.loss_bbox: 0.1295, s2.loss_cls: 0.0613, s2.acc: 93.2788, s2.loss_bbox: 0.0581, loss: 0.9462
2021-10-04 12:45:49,733 - mmdet - INFO - Epoch [3][200/1221]	lr: 1.000e-03, eta: 0:49:05, time: 0.864, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0556, loss_rpn_bbox: 0.0392, s0.loss_cls: 0.2987, s0.acc: 91.7168, s0.loss_bbox: 0.1595, s1.loss_cls: 0.1435, s1.acc: 92.0990, s1.loss_bbox: 0.1266, s2.loss_cls: 0.0615, s2.acc: 93.6157, s2.loss_bbox: 0.0566, loss: 0.9412
2021-10-04 12:46:32,814 - mmdet - INFO - Epoch [3][250/1221]	lr: 1.000e-03, eta: 0:48:24, time: 0.862, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0486, loss_rpn_bbox: 0.0351, s0.loss_cls: 0.2778, s0.acc: 92.2695, s0.loss_bbox: 0.1508, s1.loss_cls: 0.1335, s1.acc: 92.5146, s1.loss_bbox: 0.1186, s2.loss_cls: 0.0585, s2.acc: 93.6133, s2.loss_bbox: 0.0545, loss: 0.8774
2021-10-04 12:47:16,076 - mmdet - INFO - Epoch [3][300/1221]	lr: 1.000e-03, eta: 0:47:42, time: 0.865, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0427, loss_rpn_bbox: 0.0342, s0.loss_cls: 0.2719, s0.acc: 92.1602, s0.loss_bbox: 0.1489, s1.loss_cls: 0.1314, s1.acc: 92.3317, s1.loss_bbox: 0.1237, s2.loss_cls: 0.0593, s2.acc: 93.2489, s2.loss_bbox: 0.0585, loss: 0.8706
2021-10-04 12:47:59,121 - mmdet - INFO - Epoch [3][350/1221]	lr: 1.000e-03, eta: 0:47:00, time: 0.861, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0517, loss_rpn_bbox: 0.0401, s0.loss_cls: 0.2944, s0.acc: 91.3643, s0.loss_bbox: 0.1689, s1.loss_cls: 0.1472, s1.acc: 91.3974, s1.loss_bbox: 0.1363, s2.loss_cls: 0.0660, s2.acc: 92.6984, s2.loss_bbox: 0.0637, loss: 0.9682
2021-10-04 12:48:42,604 - mmdet - INFO - Epoch [3][400/1221]	lr: 1.000e-03, eta: 0:46:18, time: 0.870, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0473, loss_rpn_bbox: 0.0396, s0.loss_cls: 0.2820, s0.acc: 91.9395, s0.loss_bbox: 0.1566, s1.loss_cls: 0.1379, s1.acc: 92.1338, s1.loss_bbox: 0.1224, s2.loss_cls: 0.0640, s2.acc: 93.2021, s2.loss_bbox: 0.0585, loss: 0.9084
2021-10-04 12:49:25,700 - mmdet - INFO - Epoch [3][450/1221]	lr: 1.000e-03, eta: 0:45:36, time: 0.862, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0584, loss_rpn_bbox: 0.0501, s0.loss_cls: 0.3026, s0.acc: 91.4639, s0.loss_bbox: 0.1681, s1.loss_cls: 0.1417, s1.acc: 91.9860, s1.loss_bbox: 0.1291, s2.loss_cls: 0.0633, s2.acc: 92.9051, s2.loss_bbox: 0.0599, loss: 0.9732
2021-10-04 12:50:09,100 - mmdet - INFO - Epoch [3][500/1221]	lr: 1.000e-03, eta: 0:44:55, time: 0.868, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0492, loss_rpn_bbox: 0.0365, s0.loss_cls: 0.2736, s0.acc: 92.2451, s0.loss_bbox: 0.1460, s1.loss_cls: 0.1330, s1.acc: 92.5497, s1.loss_bbox: 0.1193, s2.loss_cls: 0.0607, s2.acc: 93.5068, s2.loss_bbox: 0.0586, loss: 0.8770
2021-10-04 12:50:52,380 - mmdet - INFO - Epoch [3][550/1221]	lr: 1.000e-03, eta: 0:44:13, time: 0.866, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0505, loss_rpn_bbox: 0.0465, s0.loss_cls: 0.2957, s0.acc: 91.2432, s0.loss_bbox: 0.1659, s1.loss_cls: 0.1461, s1.acc: 91.4865, s1.loss_bbox: 0.1356, s2.loss_cls: 0.0661, s2.acc: 92.5676, s2.loss_bbox: 0.0638, loss: 0.9702
2021-10-04 12:51:35,477 - mmdet - INFO - Epoch [3][600/1221]	lr: 1.000e-03, eta: 0:43:31, time: 0.862, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0577, loss_rpn_bbox: 0.0387, s0.loss_cls: 0.3204, s0.acc: 90.9004, s0.loss_bbox: 0.1772, s1.loss_cls: 0.1523, s1.acc: 91.4141, s1.loss_bbox: 0.1400, s2.loss_cls: 0.0666, s2.acc: 92.8297, s2.loss_bbox: 0.0654, loss: 1.0183
2021-10-04 12:52:18,390 - mmdet - INFO - Epoch [3][650/1221]	lr: 1.000e-03, eta: 0:42:48, time: 0.858, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0495, loss_rpn_bbox: 0.0379, s0.loss_cls: 0.2978, s0.acc: 91.4033, s0.loss_bbox: 0.1620, s1.loss_cls: 0.1443, s1.acc: 91.7188, s1.loss_bbox: 0.1295, s2.loss_cls: 0.0649, s2.acc: 92.8018, s2.loss_bbox: 0.0614, loss: 0.9473
2021-10-04 12:53:01,491 - mmdet - INFO - Epoch [3][700/1221]	lr: 1.000e-03, eta: 0:42:06, time: 0.862, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0556, loss_rpn_bbox: 0.0421, s0.loss_cls: 0.3042, s0.acc: 91.2441, s0.loss_bbox: 0.1686, s1.loss_cls: 0.1476, s1.acc: 91.6429, s1.loss_bbox: 0.1315, s2.loss_cls: 0.0628, s2.acc: 93.1497, s2.loss_bbox: 0.0602, loss: 0.9724
2021-10-04 12:53:44,572 - mmdet - INFO - Epoch [3][750/1221]	lr: 1.000e-03, eta: 0:41:24, time: 0.862, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0517, loss_rpn_bbox: 0.0382, s0.loss_cls: 0.2776, s0.acc: 91.9746, s0.loss_bbox: 0.1516, s1.loss_cls: 0.1347, s1.acc: 92.2296, s1.loss_bbox: 0.1263, s2.loss_cls: 0.0609, s2.acc: 93.1272, s2.loss_bbox: 0.0605, loss: 0.9015
2021-10-04 12:54:27,244 - mmdet - INFO - Epoch [3][800/1221]	lr: 1.000e-03, eta: 0:40:41, time: 0.853, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0512, loss_rpn_bbox: 0.0393, s0.loss_cls: 0.2975, s0.acc: 91.2373, s0.loss_bbox: 0.1637, s1.loss_cls: 0.1445, s1.acc: 91.5434, s1.loss_bbox: 0.1304, s2.loss_cls: 0.0642, s2.acc: 92.7164, s2.loss_bbox: 0.0621, loss: 0.9530
2021-10-04 12:55:10,509 - mmdet - INFO - Epoch [3][850/1221]	lr: 1.000e-03, eta: 0:39:59, time: 0.865, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0551, loss_rpn_bbox: 0.0400, s0.loss_cls: 0.2937, s0.acc: 91.3369, s0.loss_bbox: 0.1663, s1.loss_cls: 0.1450, s1.acc: 91.5288, s1.loss_bbox: 0.1376, s2.loss_cls: 0.0663, s2.acc: 92.6154, s2.loss_bbox: 0.0663, loss: 0.9704
2021-10-04 12:55:53,258 - mmdet - INFO - Epoch [3][900/1221]	lr: 1.000e-03, eta: 0:39:17, time: 0.855, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.0426, s0.loss_cls: 0.2987, s0.acc: 91.2686, s0.loss_bbox: 0.1671, s1.loss_cls: 0.1430, s1.acc: 91.6251, s1.loss_bbox: 0.1344, s2.loss_cls: 0.0628, s2.acc: 93.0365, s2.loss_bbox: 0.0626, loss: 0.9601
2021-10-04 12:56:35,823 - mmdet - INFO - Epoch [3][950/1221]	lr: 1.000e-03, eta: 0:38:34, time: 0.851, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0593, loss_rpn_bbox: 0.0409, s0.loss_cls: 0.3140, s0.acc: 91.2207, s0.loss_bbox: 0.1712, s1.loss_cls: 0.1503, s1.acc: 91.6425, s1.loss_bbox: 0.1332, s2.loss_cls: 0.0679, s2.acc: 92.6025, s2.loss_bbox: 0.0622, loss: 0.9990
2021-10-04 12:57:18,961 - mmdet - INFO - Epoch [3][1000/1221]	lr: 1.000e-03, eta: 0:37:52, time: 0.863, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0563, loss_rpn_bbox: 0.0415, s0.loss_cls: 0.3122, s0.acc: 91.0264, s0.loss_bbox: 0.1681, s1.loss_cls: 0.1496, s1.acc: 91.2480, s1.loss_bbox: 0.1339, s2.loss_cls: 0.0663, s2.acc: 92.5595, s2.loss_bbox: 0.0632, loss: 0.9910
2021-10-04 12:58:02,248 - mmdet - INFO - Epoch [3][1050/1221]	lr: 1.000e-03, eta: 0:37:09, time: 0.866, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0504, loss_rpn_bbox: 0.0434, s0.loss_cls: 0.2918, s0.acc: 91.6816, s0.loss_bbox: 0.1574, s1.loss_cls: 0.1422, s1.acc: 91.7859, s1.loss_bbox: 0.1277, s2.loss_cls: 0.0641, s2.acc: 92.5190, s2.loss_bbox: 0.0608, loss: 0.9379
2021-10-04 12:58:45,407 - mmdet - INFO - Epoch [3][1100/1221]	lr: 1.000e-03, eta: 0:36:27, time: 0.863, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0455, loss_rpn_bbox: 0.0358, s0.loss_cls: 0.2544, s0.acc: 92.8564, s0.loss_bbox: 0.1330, s1.loss_cls: 0.1265, s1.acc: 92.6943, s1.loss_bbox: 0.1114, s2.loss_cls: 0.0584, s2.acc: 93.0713, s2.loss_bbox: 0.0568, loss: 0.8217
2021-10-04 12:59:28,568 - mmdet - INFO - Epoch [3][1150/1221]	lr: 1.000e-03, eta: 0:35:45, time: 0.863, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0437, loss_rpn_bbox: 0.0378, s0.loss_cls: 0.2908, s0.acc: 91.4502, s0.loss_bbox: 0.1641, s1.loss_cls: 0.1399, s1.acc: 91.7382, s1.loss_bbox: 0.1315, s2.loss_cls: 0.0635, s2.acc: 92.6929, s2.loss_bbox: 0.0621, loss: 0.9335
2021-10-04 13:00:11,872 - mmdet - INFO - Epoch [3][1200/1221]	lr: 1.000e-03, eta: 0:35:02, time: 0.866, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0537, loss_rpn_bbox: 0.0375, s0.loss_cls: 0.3054, s0.acc: 91.4727, s0.loss_bbox: 0.1611, s1.loss_cls: 0.1483, s1.acc: 91.6465, s1.loss_bbox: 0.1343, s2.loss_cls: 0.0661, s2.acc: 92.5108, s2.loss_bbox: 0.0624, loss: 0.9689
2021-10-04 13:00:30,042 - mmdet - INFO - Saving checkpoint at 3 epochs
2021-10-04 13:07:07,781 - mmdet - INFO - Evaluating bbox...
2021-10-04 13:07:32,167 - mmdet - INFO - Exp name: final9.py
2021-10-04 13:07:32,168 - mmdet - INFO - Epoch(val) [3][4883]	bbox_mAP: 0.1600, bbox_mAP_50: 0.2970, bbox_mAP_75: 0.1570, bbox_mAP_s: 0.0030, bbox_mAP_m: 0.0230, bbox_mAP_l: 0.1960, bbox_mAP_copypaste: 0.160 0.297 0.157 0.003 0.023 0.196
2021-10-04 13:08:17,871 - mmdet - INFO - Epoch [4][50/1221]	lr: 1.000e-03, eta: 0:33:52, time: 0.913, data_time: 0.057, memory: 12892, loss_rpn_cls: 0.0425, loss_rpn_bbox: 0.0373, s0.loss_cls: 0.2831, s0.acc: 91.5264, s0.loss_bbox: 0.1593, s1.loss_cls: 0.1412, s1.acc: 91.5305, s1.loss_bbox: 0.1308, s2.loss_cls: 0.0653, s2.acc: 92.6041, s2.loss_bbox: 0.0640, loss: 0.9236
2021-10-04 13:09:01,081 - mmdet - INFO - Epoch [4][100/1221]	lr: 1.000e-03, eta: 0:33:10, time: 0.864, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0424, loss_rpn_bbox: 0.0351, s0.loss_cls: 0.2510, s0.acc: 92.7510, s0.loss_bbox: 0.1316, s1.loss_cls: 0.1261, s1.acc: 92.5605, s1.loss_bbox: 0.1165, s2.loss_cls: 0.0593, s2.acc: 93.1152, s2.loss_bbox: 0.0561, loss: 0.8180
2021-10-04 13:09:44,357 - mmdet - INFO - Epoch [4][150/1221]	lr: 1.000e-03, eta: 0:32:28, time: 0.865, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0495, loss_rpn_bbox: 0.0399, s0.loss_cls: 0.2766, s0.acc: 91.7783, s0.loss_bbox: 0.1560, s1.loss_cls: 0.1360, s1.acc: 92.0062, s1.loss_bbox: 0.1310, s2.loss_cls: 0.0612, s2.acc: 92.9504, s2.loss_bbox: 0.0636, loss: 0.9137
2021-10-04 13:10:27,603 - mmdet - INFO - Epoch [4][200/1221]	lr: 1.000e-03, eta: 0:31:46, time: 0.865, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0399, loss_rpn_bbox: 0.0358, s0.loss_cls: 0.2608, s0.acc: 92.1416, s0.loss_bbox: 0.1447, s1.loss_cls: 0.1308, s1.acc: 92.0927, s1.loss_bbox: 0.1220, s2.loss_cls: 0.0600, s2.acc: 92.8655, s2.loss_bbox: 0.0603, loss: 0.8543
2021-10-04 13:11:10,857 - mmdet - INFO - Epoch [4][250/1221]	lr: 1.000e-03, eta: 0:31:04, time: 0.865, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0401, loss_rpn_bbox: 0.0302, s0.loss_cls: 0.2659, s0.acc: 92.3027, s0.loss_bbox: 0.1422, s1.loss_cls: 0.1310, s1.acc: 92.3134, s1.loss_bbox: 0.1174, s2.loss_cls: 0.0606, s2.acc: 93.1729, s2.loss_bbox: 0.0586, loss: 0.8458
2021-10-04 13:11:54,207 - mmdet - INFO - Epoch [4][300/1221]	lr: 1.000e-03, eta: 0:30:22, time: 0.867, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0476, loss_rpn_bbox: 0.0384, s0.loss_cls: 0.2985, s0.acc: 91.2881, s0.loss_bbox: 0.1594, s1.loss_cls: 0.1461, s1.acc: 91.5464, s1.loss_bbox: 0.1330, s2.loss_cls: 0.0663, s2.acc: 92.4304, s2.loss_bbox: 0.0648, loss: 0.9542
2021-10-04 13:12:37,547 - mmdet - INFO - Epoch [4][350/1221]	lr: 1.000e-03, eta: 0:29:40, time: 0.867, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0483, loss_rpn_bbox: 0.0348, s0.loss_cls: 0.2871, s0.acc: 91.6318, s0.loss_bbox: 0.1576, s1.loss_cls: 0.1358, s1.acc: 92.1854, s1.loss_bbox: 0.1266, s2.loss_cls: 0.0612, s2.acc: 92.9669, s2.loss_bbox: 0.0601, loss: 0.9114
2021-10-04 13:13:20,803 - mmdet - INFO - Epoch [4][400/1221]	lr: 1.000e-03, eta: 0:28:58, time: 0.865, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0506, loss_rpn_bbox: 0.0413, s0.loss_cls: 0.2898, s0.acc: 91.5781, s0.loss_bbox: 0.1559, s1.loss_cls: 0.1419, s1.acc: 91.6053, s1.loss_bbox: 0.1305, s2.loss_cls: 0.0654, s2.acc: 92.4206, s2.loss_bbox: 0.0613, loss: 0.9367
2021-10-04 13:14:04,079 - mmdet - INFO - Epoch [4][450/1221]	lr: 1.000e-03, eta: 0:28:15, time: 0.865, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0454, loss_rpn_bbox: 0.0411, s0.loss_cls: 0.2818, s0.acc: 91.4863, s0.loss_bbox: 0.1538, s1.loss_cls: 0.1415, s1.acc: 91.4624, s1.loss_bbox: 0.1313, s2.loss_cls: 0.0664, s2.acc: 92.1693, s2.loss_bbox: 0.0660, loss: 0.9273
2021-10-04 13:14:47,343 - mmdet - INFO - Epoch [4][500/1221]	lr: 1.000e-03, eta: 0:27:33, time: 0.865, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0401, loss_rpn_bbox: 0.0345, s0.loss_cls: 0.2395, s0.acc: 92.8652, s0.loss_bbox: 0.1323, s1.loss_cls: 0.1192, s1.acc: 92.8781, s1.loss_bbox: 0.1106, s2.loss_cls: 0.0569, s2.acc: 93.2928, s2.loss_bbox: 0.0570, loss: 0.7900
2021-10-04 13:15:30,605 - mmdet - INFO - Epoch [4][550/1221]	lr: 1.000e-03, eta: 0:26:51, time: 0.865, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0480, loss_rpn_bbox: 0.0371, s0.loss_cls: 0.2685, s0.acc: 92.0625, s0.loss_bbox: 0.1471, s1.loss_cls: 0.1351, s1.acc: 91.9547, s1.loss_bbox: 0.1292, s2.loss_cls: 0.0612, s2.acc: 92.7451, s2.loss_bbox: 0.0643, loss: 0.8904
2021-10-04 13:16:13,718 - mmdet - INFO - Epoch [4][600/1221]	lr: 1.000e-03, eta: 0:26:08, time: 0.862, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0460, loss_rpn_bbox: 0.0319, s0.loss_cls: 0.2628, s0.acc: 92.2900, s0.loss_bbox: 0.1342, s1.loss_cls: 0.1353, s1.acc: 92.0571, s1.loss_bbox: 0.1206, s2.loss_cls: 0.0624, s2.acc: 92.7659, s2.loss_bbox: 0.0599, loss: 0.8530
2021-10-04 13:16:56,913 - mmdet - INFO - Epoch [4][650/1221]	lr: 1.000e-03, eta: 0:25:26, time: 0.864, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0432, loss_rpn_bbox: 0.0377, s0.loss_cls: 0.3029, s0.acc: 91.2139, s0.loss_bbox: 0.1679, s1.loss_cls: 0.1453, s1.acc: 91.3978, s1.loss_bbox: 0.1377, s2.loss_cls: 0.0656, s2.acc: 92.5021, s2.loss_bbox: 0.0661, loss: 0.9662
2021-10-04 13:17:40,227 - mmdet - INFO - Epoch [4][700/1221]	lr: 1.000e-03, eta: 0:24:44, time: 0.866, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0463, loss_rpn_bbox: 0.0436, s0.loss_cls: 0.3121, s0.acc: 90.8584, s0.loss_bbox: 0.1710, s1.loss_cls: 0.1532, s1.acc: 90.9960, s1.loss_bbox: 0.1430, s2.loss_cls: 0.0692, s2.acc: 91.8441, s2.loss_bbox: 0.0697, loss: 1.0080
2021-10-04 13:18:23,151 - mmdet - INFO - Epoch [4][750/1221]	lr: 1.000e-03, eta: 0:24:01, time: 0.858, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0423, loss_rpn_bbox: 0.0429, s0.loss_cls: 0.2936, s0.acc: 91.3271, s0.loss_bbox: 0.1660, s1.loss_cls: 0.1412, s1.acc: 91.5826, s1.loss_bbox: 0.1430, s2.loss_cls: 0.0645, s2.acc: 92.4776, s2.loss_bbox: 0.0707, loss: 0.9642
2021-10-04 13:19:06,307 - mmdet - INFO - Epoch [4][800/1221]	lr: 1.000e-03, eta: 0:23:19, time: 0.863, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0457, loss_rpn_bbox: 0.0396, s0.loss_cls: 0.3035, s0.acc: 90.9883, s0.loss_bbox: 0.1636, s1.loss_cls: 0.1502, s1.acc: 91.0216, s1.loss_bbox: 0.1391, s2.loss_cls: 0.0672, s2.acc: 92.1266, s2.loss_bbox: 0.0666, loss: 0.9754
2021-10-04 13:19:49,724 - mmdet - INFO - Epoch [4][850/1221]	lr: 1.000e-03, eta: 0:22:37, time: 0.868, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0399, loss_rpn_bbox: 0.0347, s0.loss_cls: 0.2740, s0.acc: 91.7852, s0.loss_bbox: 0.1534, s1.loss_cls: 0.1330, s1.acc: 91.9358, s1.loss_bbox: 0.1314, s2.loss_cls: 0.0605, s2.acc: 93.0248, s2.loss_bbox: 0.0651, loss: 0.8921
2021-10-04 13:20:32,974 - mmdet - INFO - Epoch [4][900/1221]	lr: 1.000e-03, eta: 0:21:54, time: 0.865, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0471, loss_rpn_bbox: 0.0422, s0.loss_cls: 0.2995, s0.acc: 91.0615, s0.loss_bbox: 0.1639, s1.loss_cls: 0.1500, s1.acc: 90.8046, s1.loss_bbox: 0.1433, s2.loss_cls: 0.0707, s2.acc: 91.4296, s2.loss_bbox: 0.0720, loss: 0.9887
2021-10-04 13:21:16,293 - mmdet - INFO - Epoch [4][950/1221]	lr: 1.000e-03, eta: 0:21:12, time: 0.866, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0491, loss_rpn_bbox: 0.0382, s0.loss_cls: 0.3037, s0.acc: 91.2627, s0.loss_bbox: 0.1610, s1.loss_cls: 0.1469, s1.acc: 91.4111, s1.loss_bbox: 0.1355, s2.loss_cls: 0.0684, s2.acc: 92.0534, s2.loss_bbox: 0.0644, loss: 0.9673
2021-10-04 13:21:59,544 - mmdet - INFO - Epoch [4][1000/1221]	lr: 1.000e-03, eta: 0:20:29, time: 0.865, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0441, loss_rpn_bbox: 0.0365, s0.loss_cls: 0.2712, s0.acc: 91.8887, s0.loss_bbox: 0.1437, s1.loss_cls: 0.1330, s1.acc: 92.1854, s1.loss_bbox: 0.1200, s2.loss_cls: 0.0615, s2.acc: 93.0511, s2.loss_bbox: 0.0600, loss: 0.8701
2021-10-04 13:22:42,707 - mmdet - INFO - Epoch [4][1050/1221]	lr: 1.000e-03, eta: 0:19:47, time: 0.863, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0535, loss_rpn_bbox: 0.0449, s0.loss_cls: 0.2796, s0.acc: 91.6768, s0.loss_bbox: 0.1521, s1.loss_cls: 0.1422, s1.acc: 91.4895, s1.loss_bbox: 0.1331, s2.loss_cls: 0.0674, s2.acc: 92.2717, s2.loss_bbox: 0.0671, loss: 0.9398
2021-10-04 13:23:26,094 - mmdet - INFO - Epoch [4][1100/1221]	lr: 1.000e-03, eta: 0:19:04, time: 0.868, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0431, loss_rpn_bbox: 0.0344, s0.loss_cls: 0.2580, s0.acc: 92.1865, s0.loss_bbox: 0.1504, s1.loss_cls: 0.1248, s1.acc: 92.3542, s1.loss_bbox: 0.1294, s2.loss_cls: 0.0579, s2.acc: 93.0527, s2.loss_bbox: 0.0627, loss: 0.8607
2021-10-04 13:24:09,549 - mmdet - INFO - Epoch [4][1150/1221]	lr: 1.000e-03, eta: 0:18:22, time: 0.869, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0500, loss_rpn_bbox: 0.0409, s0.loss_cls: 0.2986, s0.acc: 91.0742, s0.loss_bbox: 0.1640, s1.loss_cls: 0.1428, s1.acc: 91.4937, s1.loss_bbox: 0.1382, s2.loss_cls: 0.0624, s2.acc: 92.6148, s2.loss_bbox: 0.0663, loss: 0.9632
2021-10-04 13:24:52,600 - mmdet - INFO - Epoch [4][1200/1221]	lr: 1.000e-03, eta: 0:17:39, time: 0.861, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0547, loss_rpn_bbox: 0.0460, s0.loss_cls: 0.2971, s0.acc: 91.1992, s0.loss_bbox: 0.1655, s1.loss_cls: 0.1453, s1.acc: 91.5044, s1.loss_bbox: 0.1373, s2.loss_cls: 0.0653, s2.acc: 92.3468, s2.loss_bbox: 0.0663, loss: 0.9776
2021-10-04 13:25:10,823 - mmdet - INFO - Saving checkpoint at 4 epochs
2021-10-04 13:31:51,174 - mmdet - INFO - Evaluating bbox...
2021-10-04 13:32:19,402 - mmdet - INFO - Exp name: final9.py
2021-10-04 13:32:19,403 - mmdet - INFO - Epoch(val) [4][4883]	bbox_mAP: 0.2180, bbox_mAP_50: 0.3910, bbox_mAP_75: 0.2150, bbox_mAP_s: 0.0060, bbox_mAP_m: 0.0540, bbox_mAP_l: 0.2610, bbox_mAP_copypaste: 0.218 0.391 0.215 0.006 0.054 0.261
2021-10-04 13:33:04,888 - mmdet - INFO - Epoch [5][50/1221]	lr: 1.000e-03, eta: 0:16:35, time: 0.909, data_time: 0.057, memory: 12892, loss_rpn_cls: 0.0398, loss_rpn_bbox: 0.0394, s0.loss_cls: 0.2670, s0.acc: 91.8311, s0.loss_bbox: 0.1509, s1.loss_cls: 0.1303, s1.acc: 91.8670, s1.loss_bbox: 0.1251, s2.loss_cls: 0.0616, s2.acc: 92.4846, s2.loss_bbox: 0.0628, loss: 0.8769
2021-10-04 13:33:47,882 - mmdet - INFO - Epoch [5][100/1221]	lr: 1.000e-03, eta: 0:15:53, time: 0.860, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0414, loss_rpn_bbox: 0.0414, s0.loss_cls: 0.2609, s0.acc: 92.1670, s0.loss_bbox: 0.1419, s1.loss_cls: 0.1276, s1.acc: 92.4268, s1.loss_bbox: 0.1214, s2.loss_cls: 0.0588, s2.acc: 93.0736, s2.loss_bbox: 0.0599, loss: 0.8534
2021-10-04 13:34:31,034 - mmdet - INFO - Epoch [5][150/1221]	lr: 1.000e-03, eta: 0:15:10, time: 0.863, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0388, loss_rpn_bbox: 0.0426, s0.loss_cls: 0.2701, s0.acc: 91.7021, s0.loss_bbox: 0.1517, s1.loss_cls: 0.1323, s1.acc: 91.7683, s1.loss_bbox: 0.1321, s2.loss_cls: 0.0602, s2.acc: 92.6392, s2.loss_bbox: 0.0658, loss: 0.8936
2021-10-04 13:35:14,433 - mmdet - INFO - Epoch [5][200/1221]	lr: 1.000e-03, eta: 0:14:28, time: 0.868, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0456, loss_rpn_bbox: 0.0389, s0.loss_cls: 0.2807, s0.acc: 91.6533, s0.loss_bbox: 0.1504, s1.loss_cls: 0.1394, s1.acc: 91.5076, s1.loss_bbox: 0.1329, s2.loss_cls: 0.0650, s2.acc: 92.0313, s2.loss_bbox: 0.0691, loss: 0.9220
2021-10-04 13:35:57,623 - mmdet - INFO - Epoch [5][250/1221]	lr: 1.000e-03, eta: 0:13:46, time: 0.864, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0465, loss_rpn_bbox: 0.0382, s0.loss_cls: 0.2838, s0.acc: 91.3438, s0.loss_bbox: 0.1649, s1.loss_cls: 0.1407, s1.acc: 91.4518, s1.loss_bbox: 0.1410, s2.loss_cls: 0.0648, s2.acc: 92.2687, s2.loss_bbox: 0.0697, loss: 0.9497
2021-10-04 13:36:40,657 - mmdet - INFO - Epoch [5][300/1221]	lr: 1.000e-03, eta: 0:13:03, time: 0.861, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0355, loss_rpn_bbox: 0.0377, s0.loss_cls: 0.2547, s0.acc: 92.1875, s0.loss_bbox: 0.1430, s1.loss_cls: 0.1243, s1.acc: 92.3795, s1.loss_bbox: 0.1252, s2.loss_cls: 0.0585, s2.acc: 92.8637, s2.loss_bbox: 0.0630, loss: 0.8419
2021-10-04 13:37:23,919 - mmdet - INFO - Epoch [5][350/1221]	lr: 1.000e-03, eta: 0:12:21, time: 0.865, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0483, loss_rpn_bbox: 0.0390, s0.loss_cls: 0.2950, s0.acc: 90.8291, s0.loss_bbox: 0.1683, s1.loss_cls: 0.1466, s1.acc: 90.8877, s1.loss_bbox: 0.1455, s2.loss_cls: 0.0685, s2.acc: 91.8676, s2.loss_bbox: 0.0713, loss: 0.9824
2021-10-04 13:38:07,137 - mmdet - INFO - Epoch [5][400/1221]	lr: 1.000e-03, eta: 0:11:38, time: 0.864, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0424, loss_rpn_bbox: 0.0378, s0.loss_cls: 0.2664, s0.acc: 92.0576, s0.loss_bbox: 0.1413, s1.loss_cls: 0.1319, s1.acc: 91.9770, s1.loss_bbox: 0.1205, s2.loss_cls: 0.0621, s2.acc: 92.4670, s2.loss_bbox: 0.0622, loss: 0.8645
2021-10-04 13:38:50,330 - mmdet - INFO - Epoch [5][450/1221]	lr: 1.000e-03, eta: 0:10:56, time: 0.864, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0482, loss_rpn_bbox: 0.0371, s0.loss_cls: 0.2634, s0.acc: 92.1885, s0.loss_bbox: 0.1431, s1.loss_cls: 0.1312, s1.acc: 92.2580, s1.loss_bbox: 0.1239, s2.loss_cls: 0.0635, s2.acc: 92.7850, s2.loss_bbox: 0.0661, loss: 0.8765
2021-10-04 13:39:33,429 - mmdet - INFO - Epoch [5][500/1221]	lr: 1.000e-03, eta: 0:10:13, time: 0.862, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0386, loss_rpn_bbox: 0.0333, s0.loss_cls: 0.2550, s0.acc: 92.3955, s0.loss_bbox: 0.1400, s1.loss_cls: 0.1251, s1.acc: 92.3699, s1.loss_bbox: 0.1198, s2.loss_cls: 0.0588, s2.acc: 92.7864, s2.loss_bbox: 0.0598, loss: 0.8305
2021-10-04 13:40:16,590 - mmdet - INFO - Epoch [5][550/1221]	lr: 1.000e-03, eta: 0:09:31, time: 0.863, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0413, loss_rpn_bbox: 0.0333, s0.loss_cls: 0.2739, s0.acc: 91.6787, s0.loss_bbox: 0.1501, s1.loss_cls: 0.1358, s1.acc: 91.7186, s1.loss_bbox: 0.1287, s2.loss_cls: 0.0609, s2.acc: 92.8452, s2.loss_bbox: 0.0623, loss: 0.8863
2021-10-04 13:40:59,332 - mmdet - INFO - Epoch [5][600/1221]	lr: 1.000e-03, eta: 0:08:48, time: 0.855, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0383, loss_rpn_bbox: 0.0372, s0.loss_cls: 0.2832, s0.acc: 91.4980, s0.loss_bbox: 0.1632, s1.loss_cls: 0.1368, s1.acc: 91.6935, s1.loss_bbox: 0.1375, s2.loss_cls: 0.0628, s2.acc: 92.5881, s2.loss_bbox: 0.0684, loss: 0.9274
2021-10-04 13:41:42,555 - mmdet - INFO - Epoch [5][650/1221]	lr: 1.000e-03, eta: 0:08:06, time: 0.864, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0431, loss_rpn_bbox: 0.0356, s0.loss_cls: 0.2724, s0.acc: 91.7354, s0.loss_bbox: 0.1532, s1.loss_cls: 0.1320, s1.acc: 92.0242, s1.loss_bbox: 0.1324, s2.loss_cls: 0.0615, s2.acc: 92.6290, s2.loss_bbox: 0.0659, loss: 0.8959
2021-10-04 13:42:25,415 - mmdet - INFO - Epoch [5][700/1221]	lr: 1.000e-03, eta: 0:07:23, time: 0.857, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0403, loss_rpn_bbox: 0.0382, s0.loss_cls: 0.2568, s0.acc: 92.3037, s0.loss_bbox: 0.1423, s1.loss_cls: 0.1294, s1.acc: 92.2661, s1.loss_bbox: 0.1265, s2.loss_cls: 0.0600, s2.acc: 92.7578, s2.loss_bbox: 0.0641, loss: 0.8577
2021-10-04 13:43:08,468 - mmdet - INFO - Epoch [5][750/1221]	lr: 1.000e-03, eta: 0:06:41, time: 0.861, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0351, loss_rpn_bbox: 0.0312, s0.loss_cls: 0.2461, s0.acc: 92.3301, s0.loss_bbox: 0.1336, s1.loss_cls: 0.1233, s1.acc: 92.1888, s1.loss_bbox: 0.1205, s2.loss_cls: 0.0580, s2.acc: 92.5903, s2.loss_bbox: 0.0621, loss: 0.8098
2021-10-04 13:43:51,597 - mmdet - INFO - Epoch [5][800/1221]	lr: 1.000e-03, eta: 0:05:58, time: 0.863, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0386, loss_rpn_bbox: 0.0338, s0.loss_cls: 0.2444, s0.acc: 92.9775, s0.loss_bbox: 0.1278, s1.loss_cls: 0.1218, s1.acc: 92.9129, s1.loss_bbox: 0.1118, s2.loss_cls: 0.0564, s2.acc: 93.4994, s2.loss_bbox: 0.0586, loss: 0.7932
2021-10-04 13:44:34,783 - mmdet - INFO - Epoch [5][850/1221]	lr: 1.000e-03, eta: 0:05:16, time: 0.864, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0418, loss_rpn_bbox: 0.0312, s0.loss_cls: 0.2605, s0.acc: 92.2188, s0.loss_bbox: 0.1378, s1.loss_cls: 0.1305, s1.acc: 92.2623, s1.loss_bbox: 0.1240, s2.loss_cls: 0.0622, s2.acc: 93.0360, s2.loss_bbox: 0.0642, loss: 0.8522
2021-10-04 13:45:17,967 - mmdet - INFO - Epoch [5][900/1221]	lr: 1.000e-03, eta: 0:04:33, time: 0.864, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0399, loss_rpn_bbox: 0.0379, s0.loss_cls: 0.2709, s0.acc: 91.9580, s0.loss_bbox: 0.1433, s1.loss_cls: 0.1361, s1.acc: 91.9131, s1.loss_bbox: 0.1263, s2.loss_cls: 0.0629, s2.acc: 92.5006, s2.loss_bbox: 0.0644, loss: 0.8817
2021-10-04 13:46:01,315 - mmdet - INFO - Epoch [5][950/1221]	lr: 1.000e-03, eta: 0:03:50, time: 0.867, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0326, loss_rpn_bbox: 0.0383, s0.loss_cls: 0.2753, s0.acc: 91.6104, s0.loss_bbox: 0.1508, s1.loss_cls: 0.1337, s1.acc: 91.6814, s1.loss_bbox: 0.1323, s2.loss_cls: 0.0634, s2.acc: 92.3372, s2.loss_bbox: 0.0658, loss: 0.8921
2021-10-04 13:46:44,800 - mmdet - INFO - Epoch [5][1000/1221]	lr: 1.000e-03, eta: 0:03:08, time: 0.870, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0421, loss_rpn_bbox: 0.0341, s0.loss_cls: 0.2842, s0.acc: 91.1436, s0.loss_bbox: 0.1618, s1.loss_cls: 0.1412, s1.acc: 91.0764, s1.loss_bbox: 0.1406, s2.loss_cls: 0.0658, s2.acc: 91.9997, s2.loss_bbox: 0.0712, loss: 0.9410
2021-10-04 13:47:27,896 - mmdet - INFO - Epoch [5][1050/1221]	lr: 1.000e-03, eta: 0:02:25, time: 0.862, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0361, loss_rpn_bbox: 0.0377, s0.loss_cls: 0.2879, s0.acc: 91.3301, s0.loss_bbox: 0.1528, s1.loss_cls: 0.1423, s1.acc: 91.3462, s1.loss_bbox: 0.1317, s2.loss_cls: 0.0664, s2.acc: 91.9529, s2.loss_bbox: 0.0666, loss: 0.9215
2021-10-04 13:48:11,058 - mmdet - INFO - Epoch [5][1100/1221]	lr: 1.000e-03, eta: 0:01:43, time: 0.863, data_time: 0.011, memory: 12892, loss_rpn_cls: 0.0501, loss_rpn_bbox: 0.0450, s0.loss_cls: 0.2864, s0.acc: 91.4824, s0.loss_bbox: 0.1623, s1.loss_cls: 0.1375, s1.acc: 91.7592, s1.loss_bbox: 0.1375, s2.loss_cls: 0.0635, s2.acc: 92.5566, s2.loss_bbox: 0.0677, loss: 0.9500
2021-10-04 13:48:53,925 - mmdet - INFO - Epoch [5][1150/1221]	lr: 1.000e-03, eta: 0:01:00, time: 0.857, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0497, loss_rpn_bbox: 0.0407, s0.loss_cls: 0.3022, s0.acc: 91.0684, s0.loss_bbox: 0.1679, s1.loss_cls: 0.1418, s1.acc: 91.6590, s1.loss_bbox: 0.1384, s2.loss_cls: 0.0638, s2.acc: 92.6536, s2.loss_bbox: 0.0662, loss: 0.9707
2021-10-04 13:49:36,930 - mmdet - INFO - Epoch [5][1200/1221]	lr: 1.000e-03, eta: 0:00:17, time: 0.860, data_time: 0.012, memory: 12892, loss_rpn_cls: 0.0371, loss_rpn_bbox: 0.0329, s0.loss_cls: 0.2535, s0.acc: 92.4189, s0.loss_bbox: 0.1422, s1.loss_cls: 0.1176, s1.acc: 92.9251, s1.loss_bbox: 0.1182, s2.loss_cls: 0.0548, s2.acc: 93.2371, s2.loss_bbox: 0.0594, loss: 0.8156
2021-10-04 13:49:55,064 - mmdet - INFO - Saving checkpoint at 5 epochs
2021-10-04 13:56:32,485 - mmdet - INFO - Evaluating bbox...
2021-10-04 13:56:57,402 - mmdet - INFO - Exp name: final9.py
2021-10-04 13:56:57,402 - mmdet - INFO - Epoch(val) [5][4883]	bbox_mAP: 0.2580, bbox_mAP_50: 0.4450, bbox_mAP_75: 0.2650, bbox_mAP_s: 0.0050, bbox_mAP_m: 0.0670, bbox_mAP_l: 0.3080, bbox_mAP_copypaste: 0.258 0.445 0.265 0.005 0.067 0.308

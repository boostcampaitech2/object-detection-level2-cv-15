{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '../dataset/train.json', '../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '../dataset/test.json', '../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3)\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/27 13:17:48 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/27 13:17:48 d2.data.datasets.coco]: \u001b[0mLoaded 4883 images in COCO format from ../dataset/train.json\n",
      "\u001b[32m[09/27 13:17:48 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4883 images left.\n",
      "\u001b[32m[09/27 13:17:49 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 3966         |    Paper    | 6352         | Paper pack | 897          |\n",
      "|     Metal     | 936          |    Glass    | 982          |  Plastic   | 2943         |\n",
      "|   Styrofoam   | 1263         | Plastic bag | 5178         |  Battery   | 159          |\n",
      "|   Clothing    | 468          |             |              |            |              |\n",
      "|     total     | 23144        |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[09/27 13:17:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/27 13:17:49 d2.data.common]: \u001b[0mSerializing 4883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 13:17:49 d2.data.common]: \u001b[0mSerialized dataset takes 2.17 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f6e8b1.pkl: 243MB [00:18, 13.2MB/s]                              \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/27 13:18:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/detection/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:103: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  num_fg = fg_inds.nonzero().numel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/27 13:18:31 d2.utils.events]: \u001b[0m eta: 4:37:55  iter: 19  total_loss: 3.051  loss_cls: 2.279  loss_box_reg: 0.678  loss_rpn_cls: 0.05853  loss_rpn_loc: 0.0308  time: 1.1129  data_time: 0.0325  lr: 1.9981e-05  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:18:53 d2.utils.events]: \u001b[0m eta: 4:25:19  iter: 39  total_loss: 2.671  loss_cls: 1.848  loss_box_reg: 0.6851  loss_rpn_cls: 0.04313  loss_rpn_loc: 0.0309  time: 1.0982  data_time: 0.0153  lr: 3.9961e-05  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:19:15 d2.utils.events]: \u001b[0m eta: 4:25:19  iter: 59  total_loss: 1.978  loss_cls: 1.101  loss_box_reg: 0.6909  loss_rpn_cls: 0.09411  loss_rpn_loc: 0.02113  time: 1.0990  data_time: 0.0143  lr: 5.9941e-05  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:19:37 d2.utils.events]: \u001b[0m eta: 4:25:41  iter: 79  total_loss: 1.621  loss_cls: 0.7801  loss_box_reg: 0.7292  loss_rpn_cls: 0.05816  loss_rpn_loc: 0.02808  time: 1.1041  data_time: 0.0189  lr: 7.9921e-05  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:19:59 d2.utils.events]: \u001b[0m eta: 4:24:38  iter: 99  total_loss: 1.578  loss_cls: 0.7506  loss_box_reg: 0.7009  loss_rpn_cls: 0.05017  loss_rpn_loc: 0.03335  time: 1.0971  data_time: 0.0180  lr: 9.9901e-05  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:20:21 d2.utils.events]: \u001b[0m eta: 4:24:16  iter: 119  total_loss: 1.553  loss_cls: 0.7351  loss_box_reg: 0.7196  loss_rpn_cls: 0.04336  loss_rpn_loc: 0.04198  time: 1.0952  data_time: 0.0120  lr: 0.00011988  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:20:43 d2.utils.events]: \u001b[0m eta: 4:24:09  iter: 139  total_loss: 1.55  loss_cls: 0.691  loss_box_reg: 0.7285  loss_rpn_cls: 0.02365  loss_rpn_loc: 0.02086  time: 1.0982  data_time: 0.0119  lr: 0.00013986  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:21:05 d2.utils.events]: \u001b[0m eta: 4:23:47  iter: 159  total_loss: 1.481  loss_cls: 0.6795  loss_box_reg: 0.7314  loss_rpn_cls: 0.03592  loss_rpn_loc: 0.03882  time: 1.0975  data_time: 0.0129  lr: 0.00015984  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:21:27 d2.utils.events]: \u001b[0m eta: 4:23:26  iter: 179  total_loss: 1.422  loss_cls: 0.6466  loss_box_reg: 0.6697  loss_rpn_cls: 0.03525  loss_rpn_loc: 0.03437  time: 1.0990  data_time: 0.0117  lr: 0.00017982  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:21:49 d2.utils.events]: \u001b[0m eta: 4:23:05  iter: 199  total_loss: 1.365  loss_cls: 0.6296  loss_box_reg: 0.6575  loss_rpn_cls: 0.02652  loss_rpn_loc: 0.03174  time: 1.1002  data_time: 0.0121  lr: 0.0001998  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:22:11 d2.utils.events]: \u001b[0m eta: 4:22:43  iter: 219  total_loss: 1.504  loss_cls: 0.651  loss_box_reg: 0.7116  loss_rpn_cls: 0.042  loss_rpn_loc: 0.04094  time: 1.1014  data_time: 0.0123  lr: 0.00021978  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:22:33 d2.utils.events]: \u001b[0m eta: 4:22:00  iter: 239  total_loss: 1.407  loss_cls: 0.5392  loss_box_reg: 0.6952  loss_rpn_cls: 0.03331  loss_rpn_loc: 0.02114  time: 1.1001  data_time: 0.0127  lr: 0.00023976  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:22:55 d2.utils.events]: \u001b[0m eta: 4:21:48  iter: 259  total_loss: 1.295  loss_cls: 0.5604  loss_box_reg: 0.6186  loss_rpn_cls: 0.05366  loss_rpn_loc: 0.04177  time: 1.1010  data_time: 0.0147  lr: 0.00025974  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:23:17 d2.utils.events]: \u001b[0m eta: 4:21:18  iter: 279  total_loss: 1.48  loss_cls: 0.6233  loss_box_reg: 0.7044  loss_rpn_cls: 0.04011  loss_rpn_loc: 0.04159  time: 1.0999  data_time: 0.0139  lr: 0.00027972  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:23:39 d2.utils.events]: \u001b[0m eta: 4:20:56  iter: 299  total_loss: 1.325  loss_cls: 0.598  loss_box_reg: 0.6519  loss_rpn_cls: 0.0313  loss_rpn_loc: 0.0384  time: 1.0996  data_time: 0.0133  lr: 0.0002997  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:24:01 d2.utils.events]: \u001b[0m eta: 4:20:35  iter: 319  total_loss: 1.203  loss_cls: 0.5596  loss_box_reg: 0.557  loss_rpn_cls: 0.03312  loss_rpn_loc: 0.02941  time: 1.1004  data_time: 0.0134  lr: 0.00031968  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:24:23 d2.utils.events]: \u001b[0m eta: 4:20:12  iter: 339  total_loss: 1.166  loss_cls: 0.5358  loss_box_reg: 0.5539  loss_rpn_cls: 0.03872  loss_rpn_loc: 0.03713  time: 1.0999  data_time: 0.0127  lr: 0.00033966  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:24:45 d2.utils.events]: \u001b[0m eta: 4:19:51  iter: 359  total_loss: 1.217  loss_cls: 0.5494  loss_box_reg: 0.5481  loss_rpn_cls: 0.04483  loss_rpn_loc: 0.03448  time: 1.1006  data_time: 0.0126  lr: 0.00035964  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:25:07 d2.utils.events]: \u001b[0m eta: 4:19:28  iter: 379  total_loss: 1.098  loss_cls: 0.5602  loss_box_reg: 0.4708  loss_rpn_cls: 0.02628  loss_rpn_loc: 0.01751  time: 1.0998  data_time: 0.0132  lr: 0.00037962  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:25:29 d2.utils.events]: \u001b[0m eta: 4:19:08  iter: 399  total_loss: 1.045  loss_cls: 0.5584  loss_box_reg: 0.436  loss_rpn_cls: 0.02631  loss_rpn_loc: 0.02186  time: 1.1004  data_time: 0.0124  lr: 0.0003996  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:25:51 d2.utils.events]: \u001b[0m eta: 4:18:47  iter: 419  total_loss: 1.161  loss_cls: 0.5628  loss_box_reg: 0.4712  loss_rpn_cls: 0.03992  loss_rpn_loc: 0.05935  time: 1.1000  data_time: 0.0125  lr: 0.00041958  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:26:14 d2.utils.events]: \u001b[0m eta: 4:18:26  iter: 439  total_loss: 0.9586  loss_cls: 0.4921  loss_box_reg: 0.4249  loss_rpn_cls: 0.02117  loss_rpn_loc: 0.03049  time: 1.1005  data_time: 0.0130  lr: 0.00043956  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:26:36 d2.utils.events]: \u001b[0m eta: 4:18:05  iter: 459  total_loss: 1.032  loss_cls: 0.5158  loss_box_reg: 0.4186  loss_rpn_cls: 0.03573  loss_rpn_loc: 0.01966  time: 1.1010  data_time: 0.0146  lr: 0.00045954  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:26:57 d2.utils.events]: \u001b[0m eta: 4:17:32  iter: 479  total_loss: 1.032  loss_cls: 0.5353  loss_box_reg: 0.4302  loss_rpn_cls: 0.02119  loss_rpn_loc: 0.02494  time: 1.0998  data_time: 0.0125  lr: 0.00047952  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:27:19 d2.utils.events]: \u001b[0m eta: 4:17:15  iter: 499  total_loss: 1.005  loss_cls: 0.5503  loss_box_reg: 0.3844  loss_rpn_cls: 0.02709  loss_rpn_loc: 0.03842  time: 1.1001  data_time: 0.0126  lr: 0.0004995  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:27:42 d2.utils.events]: \u001b[0m eta: 4:16:54  iter: 519  total_loss: 1.063  loss_cls: 0.5521  loss_box_reg: 0.4107  loss_rpn_cls: 0.02644  loss_rpn_loc: 0.03546  time: 1.1006  data_time: 0.0127  lr: 0.00051948  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:28:04 d2.utils.events]: \u001b[0m eta: 4:16:32  iter: 539  total_loss: 1.063  loss_cls: 0.5352  loss_box_reg: 0.3935  loss_rpn_cls: 0.03476  loss_rpn_loc: 0.04169  time: 1.1011  data_time: 0.0146  lr: 0.00053946  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:28:26 d2.utils.events]: \u001b[0m eta: 4:16:11  iter: 559  total_loss: 0.9686  loss_cls: 0.5288  loss_box_reg: 0.3509  loss_rpn_cls: 0.02744  loss_rpn_loc: 0.02661  time: 1.1014  data_time: 0.0134  lr: 0.00055944  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:28:48 d2.utils.events]: \u001b[0m eta: 4:15:40  iter: 579  total_loss: 1.009  loss_cls: 0.5293  loss_box_reg: 0.38  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.02672  time: 1.1009  data_time: 0.0124  lr: 0.00057942  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:29:10 d2.utils.events]: \u001b[0m eta: 4:15:19  iter: 599  total_loss: 0.9739  loss_cls: 0.5157  loss_box_reg: 0.3895  loss_rpn_cls: 0.03699  loss_rpn_loc: 0.02298  time: 1.1013  data_time: 0.0137  lr: 0.0005994  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:29:32 d2.utils.events]: \u001b[0m eta: 4:14:57  iter: 619  total_loss: 0.8531  loss_cls: 0.4484  loss_box_reg: 0.3343  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.01723  time: 1.1017  data_time: 0.0148  lr: 0.00061938  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:29:55 d2.utils.events]: \u001b[0m eta: 4:14:42  iter: 639  total_loss: 1.08  loss_cls: 0.5343  loss_box_reg: 0.3741  loss_rpn_cls: 0.02465  loss_rpn_loc: 0.01884  time: 1.1021  data_time: 0.0135  lr: 0.00063936  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:30:17 d2.utils.events]: \u001b[0m eta: 4:14:21  iter: 659  total_loss: 0.9144  loss_cls: 0.4848  loss_box_reg: 0.349  loss_rpn_cls: 0.04883  loss_rpn_loc: 0.03592  time: 1.1024  data_time: 0.0140  lr: 0.00065934  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:30:39 d2.utils.events]: \u001b[0m eta: 4:14:00  iter: 679  total_loss: 0.9044  loss_cls: 0.4865  loss_box_reg: 0.3332  loss_rpn_cls: 0.02593  loss_rpn_loc: 0.01738  time: 1.1026  data_time: 0.0143  lr: 0.00067932  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:31:01 d2.utils.events]: \u001b[0m eta: 4:13:38  iter: 699  total_loss: 0.8561  loss_cls: 0.4818  loss_box_reg: 0.3071  loss_rpn_cls: 0.0236  loss_rpn_loc: 0.02412  time: 1.1023  data_time: 0.0154  lr: 0.0006993  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:31:23 d2.utils.events]: \u001b[0m eta: 4:13:17  iter: 719  total_loss: 1.043  loss_cls: 0.5299  loss_box_reg: 0.4008  loss_rpn_cls: 0.03839  loss_rpn_loc: 0.04396  time: 1.1026  data_time: 0.0129  lr: 0.00071928  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:31:44 d2.utils.events]: \u001b[0m eta: 4:12:54  iter: 739  total_loss: 0.9338  loss_cls: 0.4794  loss_box_reg: 0.3718  loss_rpn_cls: 0.02743  loss_rpn_loc: 0.02576  time: 1.1008  data_time: 0.0130  lr: 0.00073926  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:32:06 d2.utils.events]: \u001b[0m eta: 4:12:34  iter: 759  total_loss: 0.9684  loss_cls: 0.4809  loss_box_reg: 0.3491  loss_rpn_cls: 0.04315  loss_rpn_loc: 0.03971  time: 1.1011  data_time: 0.0170  lr: 0.00075924  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:32:29 d2.utils.events]: \u001b[0m eta: 4:12:13  iter: 779  total_loss: 0.8751  loss_cls: 0.5017  loss_box_reg: 0.2852  loss_rpn_cls: 0.03328  loss_rpn_loc: 0.03279  time: 1.1014  data_time: 0.0131  lr: 0.00077922  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:32:51 d2.utils.events]: \u001b[0m eta: 4:11:52  iter: 799  total_loss: 0.8912  loss_cls: 0.4727  loss_box_reg: 0.3238  loss_rpn_cls: 0.02175  loss_rpn_loc: 0.02596  time: 1.1017  data_time: 0.0143  lr: 0.0007992  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:33:13 d2.utils.events]: \u001b[0m eta: 4:11:31  iter: 819  total_loss: 0.8622  loss_cls: 0.4939  loss_box_reg: 0.3277  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.02585  time: 1.1020  data_time: 0.0125  lr: 0.00081918  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:33:35 d2.utils.events]: \u001b[0m eta: 4:11:13  iter: 839  total_loss: 0.8474  loss_cls: 0.4927  loss_box_reg: 0.2685  loss_rpn_cls: 0.03156  loss_rpn_loc: 0.02436  time: 1.1023  data_time: 0.0134  lr: 0.00083916  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:33:57 d2.utils.events]: \u001b[0m eta: 4:10:47  iter: 859  total_loss: 0.7531  loss_cls: 0.463  loss_box_reg: 0.2751  loss_rpn_cls: 0.02185  loss_rpn_loc: 0.02183  time: 1.1014  data_time: 0.0124  lr: 0.00085914  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:34:19 d2.utils.events]: \u001b[0m eta: 4:10:25  iter: 879  total_loss: 0.852  loss_cls: 0.4592  loss_box_reg: 0.3036  loss_rpn_cls: 0.02223  loss_rpn_loc: 0.03449  time: 1.1014  data_time: 0.0147  lr: 0.00087912  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:34:41 d2.utils.events]: \u001b[0m eta: 4:10:05  iter: 899  total_loss: 0.8767  loss_cls: 0.4539  loss_box_reg: 0.3431  loss_rpn_cls: 0.03137  loss_rpn_loc: 0.03278  time: 1.1014  data_time: 0.0158  lr: 0.0008991  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:35:03 d2.utils.events]: \u001b[0m eta: 4:09:46  iter: 919  total_loss: 0.8504  loss_cls: 0.4218  loss_box_reg: 0.3483  loss_rpn_cls: 0.02246  loss_rpn_loc: 0.02218  time: 1.1017  data_time: 0.0129  lr: 0.00091908  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:35:25 d2.utils.events]: \u001b[0m eta: 4:09:29  iter: 939  total_loss: 0.8686  loss_cls: 0.4591  loss_box_reg: 0.341  loss_rpn_cls: 0.02466  loss_rpn_loc: 0.03486  time: 1.1019  data_time: 0.0122  lr: 0.00093906  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:35:47 d2.utils.events]: \u001b[0m eta: 4:09:05  iter: 959  total_loss: 0.8431  loss_cls: 0.4499  loss_box_reg: 0.3141  loss_rpn_cls: 0.02955  loss_rpn_loc: 0.03923  time: 1.1015  data_time: 0.0121  lr: 0.00095904  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:36:09 d2.utils.events]: \u001b[0m eta: 4:08:44  iter: 979  total_loss: 0.8379  loss_cls: 0.4641  loss_box_reg: 0.3432  loss_rpn_cls: 0.03608  loss_rpn_loc: 0.02981  time: 1.1018  data_time: 0.0123  lr: 0.00097902  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:36:32 d2.utils.events]: \u001b[0m eta: 4:08:28  iter: 999  total_loss: 0.9386  loss_cls: 0.5088  loss_box_reg: 0.3627  loss_rpn_cls: 0.02849  loss_rpn_loc: 0.0283  time: 1.1020  data_time: 0.0134  lr: 0.000999  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:36:54 d2.utils.events]: \u001b[0m eta: 4:08:02  iter: 1019  total_loss: 0.81  loss_cls: 0.4368  loss_box_reg: 0.2535  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.02163  time: 1.1018  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:37:16 d2.utils.events]: \u001b[0m eta: 4:07:49  iter: 1039  total_loss: 0.8277  loss_cls: 0.4625  loss_box_reg: 0.2933  loss_rpn_cls: 0.02107  loss_rpn_loc: 0.01918  time: 1.1021  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:37:38 d2.utils.events]: \u001b[0m eta: 4:07:27  iter: 1059  total_loss: 0.8945  loss_cls: 0.4845  loss_box_reg: 0.3414  loss_rpn_cls: 0.03032  loss_rpn_loc: 0.03906  time: 1.1022  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:38:00 d2.utils.events]: \u001b[0m eta: 4:07:04  iter: 1079  total_loss: 0.7134  loss_cls: 0.3748  loss_box_reg: 0.2512  loss_rpn_cls: 0.02039  loss_rpn_loc: 0.01915  time: 1.1024  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:38:23 d2.utils.events]: \u001b[0m eta: 4:06:46  iter: 1099  total_loss: 0.8764  loss_cls: 0.4832  loss_box_reg: 0.3102  loss_rpn_cls: 0.02698  loss_rpn_loc: 0.03359  time: 1.1026  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:38:45 d2.utils.events]: \u001b[0m eta: 4:06:26  iter: 1119  total_loss: 0.8703  loss_cls: 0.4858  loss_box_reg: 0.3199  loss_rpn_cls: 0.02375  loss_rpn_loc: 0.02739  time: 1.1028  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:39:07 d2.utils.events]: \u001b[0m eta: 4:06:01  iter: 1139  total_loss: 0.7806  loss_cls: 0.476  loss_box_reg: 0.2457  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.01758  time: 1.1026  data_time: 0.0162  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:39:29 d2.utils.events]: \u001b[0m eta: 4:05:38  iter: 1159  total_loss: 0.882  loss_cls: 0.4696  loss_box_reg: 0.348  loss_rpn_cls: 0.03818  loss_rpn_loc: 0.03361  time: 1.1024  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:39:51 d2.utils.events]: \u001b[0m eta: 4:05:17  iter: 1179  total_loss: 0.8823  loss_cls: 0.5073  loss_box_reg: 0.3073  loss_rpn_cls: 0.02899  loss_rpn_loc: 0.02903  time: 1.1026  data_time: 0.0136  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:40:13 d2.utils.events]: \u001b[0m eta: 4:04:56  iter: 1199  total_loss: 0.8031  loss_cls: 0.4516  loss_box_reg: 0.3012  loss_rpn_cls: 0.02119  loss_rpn_loc: 0.02969  time: 1.1028  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:40:35 d2.utils.events]: \u001b[0m eta: 4:04:34  iter: 1219  total_loss: 0.8102  loss_cls: 0.4617  loss_box_reg: 0.2908  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.01565  time: 1.1029  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:40:57 d2.utils.events]: \u001b[0m eta: 4:04:13  iter: 1239  total_loss: 0.7375  loss_cls: 0.408  loss_box_reg: 0.2751  loss_rpn_cls: 0.02705  loss_rpn_loc: 0.02975  time: 1.1026  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:41:19 d2.utils.events]: \u001b[0m eta: 4:03:47  iter: 1259  total_loss: 0.8185  loss_cls: 0.4609  loss_box_reg: 0.2982  loss_rpn_cls: 0.02221  loss_rpn_loc: 0.03132  time: 1.1028  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:41:42 d2.utils.events]: \u001b[0m eta: 4:03:28  iter: 1279  total_loss: 0.7416  loss_cls: 0.396  loss_box_reg: 0.2903  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.02476  time: 1.1029  data_time: 0.0138  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:42:04 d2.utils.events]: \u001b[0m eta: 4:03:11  iter: 1299  total_loss: 0.8516  loss_cls: 0.4324  loss_box_reg: 0.3327  loss_rpn_cls: 0.02427  loss_rpn_loc: 0.03582  time: 1.1031  data_time: 0.0150  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:42:26 d2.utils.events]: \u001b[0m eta: 4:02:48  iter: 1319  total_loss: 0.8985  loss_cls: 0.5109  loss_box_reg: 0.3229  loss_rpn_cls: 0.02789  loss_rpn_loc: 0.03749  time: 1.1031  data_time: 0.0144  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:42:48 d2.utils.events]: \u001b[0m eta: 4:02:29  iter: 1339  total_loss: 0.9178  loss_cls: 0.4623  loss_box_reg: 0.3191  loss_rpn_cls: 0.0279  loss_rpn_loc: 0.03214  time: 1.1031  data_time: 0.0164  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:43:09 d2.utils.events]: \u001b[0m eta: 4:02:03  iter: 1359  total_loss: 0.7629  loss_cls: 0.4277  loss_box_reg: 0.2862  loss_rpn_cls: 0.02337  loss_rpn_loc: 0.02023  time: 1.1021  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:43:31 d2.utils.events]: \u001b[0m eta: 4:01:44  iter: 1379  total_loss: 0.7546  loss_cls: 0.4383  loss_box_reg: 0.2505  loss_rpn_cls: 0.01786  loss_rpn_loc: 0.01923  time: 1.1022  data_time: 0.0147  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:43:53 d2.utils.events]: \u001b[0m eta: 4:01:20  iter: 1399  total_loss: 0.7889  loss_cls: 0.3984  loss_box_reg: 0.2574  loss_rpn_cls: 0.02286  loss_rpn_loc: 0.0154  time: 1.1023  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:44:16 d2.utils.events]: \u001b[0m eta: 4:01:01  iter: 1419  total_loss: 0.8041  loss_cls: 0.4268  loss_box_reg: 0.2782  loss_rpn_cls: 0.03667  loss_rpn_loc: 0.03461  time: 1.1025  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:44:37 d2.utils.events]: \u001b[0m eta: 4:00:40  iter: 1439  total_loss: 0.7334  loss_cls: 0.4253  loss_box_reg: 0.2842  loss_rpn_cls: 0.0203  loss_rpn_loc: 0.02786  time: 1.1024  data_time: 0.0144  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:45:00 d2.utils.events]: \u001b[0m eta: 4:00:19  iter: 1459  total_loss: 0.8587  loss_cls: 0.4532  loss_box_reg: 0.3411  loss_rpn_cls: 0.02786  loss_rpn_loc: 0.03419  time: 1.1025  data_time: 0.0140  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:45:22 d2.utils.events]: \u001b[0m eta: 4:00:03  iter: 1479  total_loss: 0.7503  loss_cls: 0.4297  loss_box_reg: 0.2793  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.01806  time: 1.1026  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:45:44 d2.utils.events]: \u001b[0m eta: 3:59:38  iter: 1499  total_loss: 0.8168  loss_cls: 0.4519  loss_box_reg: 0.3232  loss_rpn_cls: 0.02488  loss_rpn_loc: 0.023  time: 1.1024  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:46:06 d2.utils.events]: \u001b[0m eta: 3:59:19  iter: 1519  total_loss: 0.803  loss_cls: 0.4075  loss_box_reg: 0.3255  loss_rpn_cls: 0.01898  loss_rpn_loc: 0.0401  time: 1.1026  data_time: 0.0136  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:46:28 d2.utils.events]: \u001b[0m eta: 3:58:57  iter: 1539  total_loss: 0.8266  loss_cls: 0.4853  loss_box_reg: 0.3043  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.02225  time: 1.1027  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:46:50 d2.utils.events]: \u001b[0m eta: 3:58:36  iter: 1559  total_loss: 0.9073  loss_cls: 0.486  loss_box_reg: 0.342  loss_rpn_cls: 0.013  loss_rpn_loc: 0.01457  time: 1.1028  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:47:12 d2.utils.events]: \u001b[0m eta: 3:58:18  iter: 1579  total_loss: 0.6278  loss_cls: 0.3532  loss_box_reg: 0.2397  loss_rpn_cls: 0.009884  loss_rpn_loc: 0.02413  time: 1.1026  data_time: 0.0142  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:47:34 d2.utils.events]: \u001b[0m eta: 3:57:55  iter: 1599  total_loss: 0.8077  loss_cls: 0.4456  loss_box_reg: 0.2889  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.02107  time: 1.1024  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:47:56 d2.utils.events]: \u001b[0m eta: 3:57:32  iter: 1619  total_loss: 0.7956  loss_cls: 0.4589  loss_box_reg: 0.2773  loss_rpn_cls: 0.0236  loss_rpn_loc: 0.01731  time: 1.1023  data_time: 0.0151  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:48:18 d2.utils.events]: \u001b[0m eta: 3:57:05  iter: 1639  total_loss: 0.7171  loss_cls: 0.411  loss_box_reg: 0.3089  loss_rpn_cls: 0.01922  loss_rpn_loc: 0.01827  time: 1.1021  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:48:39 d2.utils.events]: \u001b[0m eta: 3:56:41  iter: 1659  total_loss: 0.8623  loss_cls: 0.4959  loss_box_reg: 0.2584  loss_rpn_cls: 0.02177  loss_rpn_loc: 0.03275  time: 1.1018  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:49:01 d2.utils.events]: \u001b[0m eta: 3:56:20  iter: 1679  total_loss: 0.7743  loss_cls: 0.4784  loss_box_reg: 0.2855  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.01246  time: 1.1018  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:49:23 d2.utils.events]: \u001b[0m eta: 3:56:01  iter: 1699  total_loss: 0.8057  loss_cls: 0.4338  loss_box_reg: 0.297  loss_rpn_cls: 0.01893  loss_rpn_loc: 0.03191  time: 1.1019  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:49:46 d2.utils.events]: \u001b[0m eta: 3:55:42  iter: 1719  total_loss: 0.7533  loss_cls: 0.4575  loss_box_reg: 0.271  loss_rpn_cls: 0.0252  loss_rpn_loc: 0.02949  time: 1.1020  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:50:08 d2.utils.events]: \u001b[0m eta: 3:55:23  iter: 1739  total_loss: 0.6813  loss_cls: 0.3884  loss_box_reg: 0.2375  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.03293  time: 1.1019  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:50:30 d2.utils.events]: \u001b[0m eta: 3:55:03  iter: 1759  total_loss: 0.822  loss_cls: 0.4494  loss_box_reg: 0.3101  loss_rpn_cls: 0.02762  loss_rpn_loc: 0.03046  time: 1.1021  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:50:52 d2.utils.events]: \u001b[0m eta: 3:54:40  iter: 1779  total_loss: 0.8152  loss_cls: 0.4336  loss_box_reg: 0.2895  loss_rpn_cls: 0.02441  loss_rpn_loc: 0.03974  time: 1.1022  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:51:14 d2.utils.events]: \u001b[0m eta: 3:54:19  iter: 1799  total_loss: 0.7439  loss_cls: 0.423  loss_box_reg: 0.2688  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.01374  time: 1.1023  data_time: 0.0155  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:51:37 d2.utils.events]: \u001b[0m eta: 3:53:57  iter: 1819  total_loss: 0.6142  loss_cls: 0.3737  loss_box_reg: 0.2357  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.01117  time: 1.1024  data_time: 0.0147  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:51:59 d2.utils.events]: \u001b[0m eta: 3:53:32  iter: 1839  total_loss: 0.7153  loss_cls: 0.3918  loss_box_reg: 0.2615  loss_rpn_cls: 0.02043  loss_rpn_loc: 0.01685  time: 1.1024  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:52:21 d2.utils.events]: \u001b[0m eta: 3:53:18  iter: 1859  total_loss: 0.7787  loss_cls: 0.4294  loss_box_reg: 0.2549  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.0214  time: 1.1024  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:52:43 d2.utils.events]: \u001b[0m eta: 3:52:58  iter: 1879  total_loss: 0.8764  loss_cls: 0.4702  loss_box_reg: 0.3402  loss_rpn_cls: 0.02419  loss_rpn_loc: 0.03346  time: 1.1025  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:53:05 d2.utils.events]: \u001b[0m eta: 3:52:38  iter: 1899  total_loss: 0.7938  loss_cls: 0.4158  loss_box_reg: 0.3108  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.01769  time: 1.1026  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:53:28 d2.utils.events]: \u001b[0m eta: 3:52:15  iter: 1919  total_loss: 0.7394  loss_cls: 0.4341  loss_box_reg: 0.2556  loss_rpn_cls: 0.0188  loss_rpn_loc: 0.02372  time: 1.1027  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:53:50 d2.utils.events]: \u001b[0m eta: 3:51:50  iter: 1939  total_loss: 0.8027  loss_cls: 0.4677  loss_box_reg: 0.2781  loss_rpn_cls: 0.01631  loss_rpn_loc: 0.02761  time: 1.1028  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:54:12 d2.utils.events]: \u001b[0m eta: 3:51:31  iter: 1959  total_loss: 0.8282  loss_cls: 0.4646  loss_box_reg: 0.3355  loss_rpn_cls: 0.02883  loss_rpn_loc: 0.03006  time: 1.1029  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:54:33 d2.utils.events]: \u001b[0m eta: 3:51:05  iter: 1979  total_loss: 0.7359  loss_cls: 0.394  loss_box_reg: 0.2718  loss_rpn_cls: 0.0256  loss_rpn_loc: 0.0327  time: 1.1021  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:54:55 d2.utils.events]: \u001b[0m eta: 3:50:41  iter: 1999  total_loss: 0.727  loss_cls: 0.4238  loss_box_reg: 0.2738  loss_rpn_cls: 0.02194  loss_rpn_loc: 0.01802  time: 1.1021  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:55:17 d2.utils.events]: \u001b[0m eta: 3:50:19  iter: 2019  total_loss: 0.8406  loss_cls: 0.4349  loss_box_reg: 0.3277  loss_rpn_cls: 0.03359  loss_rpn_loc: 0.03768  time: 1.1021  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:55:39 d2.utils.events]: \u001b[0m eta: 3:49:53  iter: 2039  total_loss: 0.9603  loss_cls: 0.4478  loss_box_reg: 0.3471  loss_rpn_cls: 0.04204  loss_rpn_loc: 0.05891  time: 1.1020  data_time: 0.0140  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:56:01 d2.utils.events]: \u001b[0m eta: 3:49:33  iter: 2059  total_loss: 0.7584  loss_cls: 0.4121  loss_box_reg: 0.3031  loss_rpn_cls: 0.02062  loss_rpn_loc: 0.02384  time: 1.1021  data_time: 0.0136  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:56:23 d2.utils.events]: \u001b[0m eta: 3:49:12  iter: 2079  total_loss: 0.83  loss_cls: 0.4292  loss_box_reg: 0.3019  loss_rpn_cls: 0.02798  loss_rpn_loc: 0.03178  time: 1.1023  data_time: 0.0145  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:56:45 d2.utils.events]: \u001b[0m eta: 3:48:50  iter: 2099  total_loss: 0.7316  loss_cls: 0.4159  loss_box_reg: 0.2986  loss_rpn_cls: 0.02738  loss_rpn_loc: 0.01881  time: 1.1023  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:57:07 d2.utils.events]: \u001b[0m eta: 3:48:28  iter: 2119  total_loss: 0.7047  loss_cls: 0.406  loss_box_reg: 0.2458  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.01779  time: 1.1022  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:57:29 d2.utils.events]: \u001b[0m eta: 3:48:07  iter: 2139  total_loss: 0.7001  loss_cls: 0.3727  loss_box_reg: 0.2575  loss_rpn_cls: 0.01744  loss_rpn_loc: 0.02154  time: 1.1021  data_time: 0.0161  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:57:51 d2.utils.events]: \u001b[0m eta: 3:47:49  iter: 2159  total_loss: 0.6501  loss_cls: 0.3785  loss_box_reg: 0.2325  loss_rpn_cls: 0.02063  loss_rpn_loc: 0.02122  time: 1.1022  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:58:14 d2.utils.events]: \u001b[0m eta: 3:47:27  iter: 2179  total_loss: 0.8745  loss_cls: 0.4591  loss_box_reg: 0.323  loss_rpn_cls: 0.02546  loss_rpn_loc: 0.04246  time: 1.1023  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:58:36 d2.utils.events]: \u001b[0m eta: 3:47:07  iter: 2199  total_loss: 0.8792  loss_cls: 0.4516  loss_box_reg: 0.3517  loss_rpn_cls: 0.02825  loss_rpn_loc: 0.03875  time: 1.1024  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:58:58 d2.utils.events]: \u001b[0m eta: 3:46:44  iter: 2219  total_loss: 0.7969  loss_cls: 0.452  loss_box_reg: 0.3018  loss_rpn_cls: 0.02515  loss_rpn_loc: 0.03086  time: 1.1022  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:59:19 d2.utils.events]: \u001b[0m eta: 3:46:25  iter: 2239  total_loss: 0.7433  loss_cls: 0.4302  loss_box_reg: 0.2566  loss_rpn_cls: 0.02592  loss_rpn_loc: 0.02071  time: 1.1019  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 13:59:41 d2.utils.events]: \u001b[0m eta: 3:46:04  iter: 2259  total_loss: 0.8372  loss_cls: 0.4324  loss_box_reg: 0.3485  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.02147  time: 1.1018  data_time: 0.0132  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:00:03 d2.utils.events]: \u001b[0m eta: 3:45:42  iter: 2279  total_loss: 0.7618  loss_cls: 0.402  loss_box_reg: 0.2649  loss_rpn_cls: 0.02631  loss_rpn_loc: 0.03056  time: 1.1017  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:00:25 d2.utils.events]: \u001b[0m eta: 3:45:20  iter: 2299  total_loss: 0.6889  loss_cls: 0.3831  loss_box_reg: 0.2601  loss_rpn_cls: 0.02966  loss_rpn_loc: 0.03533  time: 1.1018  data_time: 0.0140  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:00:47 d2.utils.events]: \u001b[0m eta: 3:45:04  iter: 2319  total_loss: 0.7356  loss_cls: 0.3914  loss_box_reg: 0.287  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.02207  time: 1.1019  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:01:09 d2.utils.events]: \u001b[0m eta: 3:44:46  iter: 2339  total_loss: 0.8533  loss_cls: 0.4476  loss_box_reg: 0.3482  loss_rpn_cls: 0.02709  loss_rpn_loc: 0.03605  time: 1.1020  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:01:31 d2.utils.events]: \u001b[0m eta: 3:44:28  iter: 2359  total_loss: 0.7313  loss_cls: 0.3463  loss_box_reg: 0.2773  loss_rpn_cls: 0.02634  loss_rpn_loc: 0.03293  time: 1.1019  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:01:53 d2.utils.events]: \u001b[0m eta: 3:44:06  iter: 2379  total_loss: 0.7275  loss_cls: 0.411  loss_box_reg: 0.276  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01573  time: 1.1020  data_time: 0.0138  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:02:15 d2.utils.events]: \u001b[0m eta: 3:43:44  iter: 2399  total_loss: 0.7012  loss_cls: 0.3762  loss_box_reg: 0.2791  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.01866  time: 1.1019  data_time: 0.0150  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:02:37 d2.utils.events]: \u001b[0m eta: 3:43:23  iter: 2419  total_loss: 0.8683  loss_cls: 0.4725  loss_box_reg: 0.3299  loss_rpn_cls: 0.02678  loss_rpn_loc: 0.02648  time: 1.1020  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:03:00 d2.utils.events]: \u001b[0m eta: 3:43:02  iter: 2439  total_loss: 0.6956  loss_cls: 0.3502  loss_box_reg: 0.2593  loss_rpn_cls: 0.02052  loss_rpn_loc: 0.01736  time: 1.1020  data_time: 0.0144  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:03:22 d2.utils.events]: \u001b[0m eta: 3:42:43  iter: 2459  total_loss: 0.622  loss_cls: 0.332  loss_box_reg: 0.2441  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.0134  time: 1.1021  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:03:44 d2.utils.events]: \u001b[0m eta: 3:42:23  iter: 2479  total_loss: 0.7415  loss_cls: 0.3989  loss_box_reg: 0.282  loss_rpn_cls: 0.02344  loss_rpn_loc: 0.02173  time: 1.1022  data_time: 0.0138  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:04:07 d2.utils.events]: \u001b[0m eta: 3:42:04  iter: 2499  total_loss: 0.7403  loss_cls: 0.4073  loss_box_reg: 0.2696  loss_rpn_cls: 0.01885  loss_rpn_loc: 0.02504  time: 1.1023  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:04:28 d2.utils.events]: \u001b[0m eta: 3:41:39  iter: 2519  total_loss: 0.6449  loss_cls: 0.3681  loss_box_reg: 0.2378  loss_rpn_cls: 0.0175  loss_rpn_loc: 0.02173  time: 1.1022  data_time: 0.0135  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:04:51 d2.utils.events]: \u001b[0m eta: 3:41:17  iter: 2539  total_loss: 0.6623  loss_cls: 0.3915  loss_box_reg: 0.2054  loss_rpn_cls: 0.009592  loss_rpn_loc: 0.01571  time: 1.1023  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:05:13 d2.utils.events]: \u001b[0m eta: 3:40:56  iter: 2559  total_loss: 0.7206  loss_cls: 0.365  loss_box_reg: 0.273  loss_rpn_cls: 0.02876  loss_rpn_loc: 0.03051  time: 1.1024  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:05:35 d2.utils.events]: \u001b[0m eta: 3:40:37  iter: 2579  total_loss: 0.7456  loss_cls: 0.4129  loss_box_reg: 0.2623  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.0247  time: 1.1024  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:05:55 d2.utils.events]: \u001b[0m eta: 3:40:05  iter: 2599  total_loss: 0.6635  loss_cls: 0.3861  loss_box_reg: 0.2179  loss_rpn_cls: 0.01905  loss_rpn_loc: 0.01737  time: 1.1014  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:06:17 d2.utils.events]: \u001b[0m eta: 3:39:44  iter: 2619  total_loss: 0.6486  loss_cls: 0.3565  loss_box_reg: 0.258  loss_rpn_cls: 0.01813  loss_rpn_loc: 0.02571  time: 1.1014  data_time: 0.0135  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:06:38 d2.utils.events]: \u001b[0m eta: 3:39:26  iter: 2639  total_loss: 0.7497  loss_cls: 0.4029  loss_box_reg: 0.3116  loss_rpn_cls: 0.02062  loss_rpn_loc: 0.03548  time: 1.1013  data_time: 0.0154  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:07:01 d2.utils.events]: \u001b[0m eta: 3:39:07  iter: 2659  total_loss: 0.7121  loss_cls: 0.3871  loss_box_reg: 0.3121  loss_rpn_cls: 0.01949  loss_rpn_loc: 0.0229  time: 1.1014  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:07:23 d2.utils.events]: \u001b[0m eta: 3:38:48  iter: 2679  total_loss: 0.7012  loss_cls: 0.3702  loss_box_reg: 0.2688  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.01026  time: 1.1015  data_time: 0.0145  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:07:45 d2.utils.events]: \u001b[0m eta: 3:38:24  iter: 2699  total_loss: 0.6897  loss_cls: 0.3581  loss_box_reg: 0.277  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.03581  time: 1.1016  data_time: 0.0137  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:08:07 d2.utils.events]: \u001b[0m eta: 3:37:58  iter: 2719  total_loss: 0.7394  loss_cls: 0.3792  loss_box_reg: 0.2393  loss_rpn_cls: 0.0165  loss_rpn_loc: 0.03946  time: 1.1016  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:08:30 d2.utils.events]: \u001b[0m eta: 3:37:40  iter: 2739  total_loss: 0.6969  loss_cls: 0.3641  loss_box_reg: 0.259  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.02636  time: 1.1017  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:08:52 d2.utils.events]: \u001b[0m eta: 3:37:12  iter: 2759  total_loss: 0.6513  loss_cls: 0.3849  loss_box_reg: 0.2662  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.017  time: 1.1018  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:09:14 d2.utils.events]: \u001b[0m eta: 3:36:51  iter: 2779  total_loss: 0.7697  loss_cls: 0.3764  loss_box_reg: 0.2949  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.02319  time: 1.1019  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:09:36 d2.utils.events]: \u001b[0m eta: 3:36:29  iter: 2799  total_loss: 0.6616  loss_cls: 0.3639  loss_box_reg: 0.2473  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.02088  time: 1.1019  data_time: 0.0135  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:09:58 d2.utils.events]: \u001b[0m eta: 3:36:05  iter: 2819  total_loss: 0.6503  loss_cls: 0.3327  loss_box_reg: 0.2493  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.0286  time: 1.1019  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:10:21 d2.utils.events]: \u001b[0m eta: 3:35:50  iter: 2839  total_loss: 0.583  loss_cls: 0.3245  loss_box_reg: 0.2271  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.01181  time: 1.1019  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:10:43 d2.utils.events]: \u001b[0m eta: 3:35:26  iter: 2859  total_loss: 0.8372  loss_cls: 0.4145  loss_box_reg: 0.3384  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.02403  time: 1.1020  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:11:05 d2.utils.events]: \u001b[0m eta: 3:34:59  iter: 2879  total_loss: 0.7949  loss_cls: 0.4079  loss_box_reg: 0.2883  loss_rpn_cls: 0.02238  loss_rpn_loc: 0.02568  time: 1.1019  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:11:26 d2.utils.events]: \u001b[0m eta: 3:34:28  iter: 2899  total_loss: 0.6877  loss_cls: 0.4023  loss_box_reg: 0.2621  loss_rpn_cls: 0.01841  loss_rpn_loc: 0.02712  time: 1.1018  data_time: 0.0157  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:11:49 d2.utils.events]: \u001b[0m eta: 3:34:06  iter: 2919  total_loss: 0.6939  loss_cls: 0.3919  loss_box_reg: 0.2836  loss_rpn_cls: 0.01729  loss_rpn_loc: 0.03115  time: 1.1019  data_time: 0.0151  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:12:11 d2.utils.events]: \u001b[0m eta: 3:33:43  iter: 2939  total_loss: 0.7013  loss_cls: 0.3793  loss_box_reg: 0.2403  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.03459  time: 1.1020  data_time: 0.0150  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:12:33 d2.utils.events]: \u001b[0m eta: 3:33:21  iter: 2959  total_loss: 0.7801  loss_cls: 0.4278  loss_box_reg: 0.3034  loss_rpn_cls: 0.01947  loss_rpn_loc: 0.02935  time: 1.1021  data_time: 0.0153  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:12:56 d2.utils.events]: \u001b[0m eta: 3:33:05  iter: 2979  total_loss: 0.8013  loss_cls: 0.445  loss_box_reg: 0.3047  loss_rpn_cls: 0.02418  loss_rpn_loc: 0.02854  time: 1.1021  data_time: 0.0137  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:13:18 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/test.json\n",
      "\u001b[32m[09/27 14:13:18 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[09/27 14:13:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 14:13:19 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 14:13:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.50 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/27 14:13:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/27 14:13:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/27 14:13:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0009 s/iter. Inference: 0.1133 s/iter. Eval: 0.0003 s/iter. Total: 0.1146 s/iter. ETA=0:09:16\n",
      "\u001b[32m[09/27 14:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 60/4871. Dataloading: 0.0013 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1042 s/iter. ETA=0:08:21\n",
      "\u001b[32m[09/27 14:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 106/4871. Dataloading: 0.0012 s/iter. Inference: 0.1050 s/iter. Eval: 0.0003 s/iter. Total: 0.1067 s/iter. ETA=0:08:28\n",
      "\u001b[32m[09/27 14:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 154/4871. Dataloading: 0.0012 s/iter. Inference: 0.1052 s/iter. Eval: 0.0003 s/iter. Total: 0.1068 s/iter. ETA=0:08:23\n",
      "\u001b[32m[09/27 14:13:40 d2.evaluation.evaluator]: \u001b[0mInference done 204/4871. Dataloading: 0.0012 s/iter. Inference: 0.1040 s/iter. Eval: 0.0003 s/iter. Total: 0.1056 s/iter. ETA=0:08:12\n",
      "\u001b[32m[09/27 14:13:46 d2.evaluation.evaluator]: \u001b[0mInference done 253/4871. Dataloading: 0.0012 s/iter. Inference: 0.1037 s/iter. Eval: 0.0003 s/iter. Total: 0.1053 s/iter. ETA=0:08:06\n",
      "\u001b[32m[09/27 14:13:51 d2.evaluation.evaluator]: \u001b[0mInference done 305/4871. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1041 s/iter. ETA=0:07:55\n",
      "\u001b[32m[09/27 14:13:56 d2.evaluation.evaluator]: \u001b[0mInference done 351/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0003 s/iter. Total: 0.1048 s/iter. ETA=0:07:53\n",
      "\u001b[32m[09/27 14:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 397/4871. Dataloading: 0.0012 s/iter. Inference: 0.1036 s/iter. Eval: 0.0006 s/iter. Total: 0.1055 s/iter. ETA=0:07:51\n",
      "\u001b[32m[09/27 14:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 444/4871. Dataloading: 0.0012 s/iter. Inference: 0.1038 s/iter. Eval: 0.0005 s/iter. Total: 0.1057 s/iter. ETA=0:07:47\n",
      "\u001b[32m[09/27 14:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 494/4871. Dataloading: 0.0012 s/iter. Inference: 0.1036 s/iter. Eval: 0.0005 s/iter. Total: 0.1054 s/iter. ETA=0:07:41\n",
      "\u001b[32m[09/27 14:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 545/4871. Dataloading: 0.0012 s/iter. Inference: 0.1030 s/iter. Eval: 0.0005 s/iter. Total: 0.1048 s/iter. ETA=0:07:33\n",
      "\u001b[32m[09/27 14:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 592/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0005 s/iter. Total: 0.1049 s/iter. ETA=0:07:29\n",
      "\u001b[32m[09/27 14:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 638/4871. Dataloading: 0.0012 s/iter. Inference: 0.1035 s/iter. Eval: 0.0005 s/iter. Total: 0.1053 s/iter. ETA=0:07:25\n",
      "\u001b[32m[09/27 14:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 688/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:07:18\n",
      "\u001b[32m[09/27 14:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 737/4871. Dataloading: 0.0012 s/iter. Inference: 0.1031 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:07:13\n",
      "\u001b[32m[09/27 14:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 787/4871. Dataloading: 0.0012 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:07:07\n",
      "\u001b[32m[09/27 14:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 833/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:07:03\n",
      "\u001b[32m[09/27 14:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 881/4871. Dataloading: 0.0012 s/iter. Inference: 0.1033 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:06:58\n",
      "\u001b[32m[09/27 14:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 930/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:06:53\n",
      "\u001b[32m[09/27 14:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 979/4871. Dataloading: 0.0012 s/iter. Inference: 0.1031 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:06:47\n",
      "\u001b[32m[09/27 14:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 1029/4871. Dataloading: 0.0012 s/iter. Inference: 0.1029 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:06:41\n",
      "\u001b[32m[09/27 14:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 1075/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:06:38\n",
      "\u001b[32m[09/27 14:15:17 d2.evaluation.evaluator]: \u001b[0mInference done 1123/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:06:33\n",
      "\u001b[32m[09/27 14:15:22 d2.evaluation.evaluator]: \u001b[0mInference done 1172/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:06:27\n",
      "\u001b[32m[09/27 14:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 1221/4871. Dataloading: 0.0012 s/iter. Inference: 0.1031 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:06:22\n",
      "\u001b[32m[09/27 14:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 1271/4871. Dataloading: 0.0012 s/iter. Inference: 0.1030 s/iter. Eval: 0.0004 s/iter. Total: 0.1046 s/iter. ETA=0:06:16\n",
      "\u001b[32m[09/27 14:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 1315/4871. Dataloading: 0.0012 s/iter. Inference: 0.1033 s/iter. Eval: 0.0004 s/iter. Total: 0.1050 s/iter. ETA=0:06:13\n",
      "\u001b[32m[09/27 14:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 1365/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:06:07\n",
      "\u001b[32m[09/27 14:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 1414/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:06:02\n",
      "\u001b[32m[09/27 14:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 1464/4871. Dataloading: 0.0012 s/iter. Inference: 0.1031 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:05:56\n",
      "\u001b[32m[09/27 14:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 1514/4871. Dataloading: 0.0012 s/iter. Inference: 0.1030 s/iter. Eval: 0.0004 s/iter. Total: 0.1047 s/iter. ETA=0:05:51\n",
      "\u001b[32m[09/27 14:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 1560/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:05:47\n",
      "\u001b[32m[09/27 14:16:08 d2.evaluation.evaluator]: \u001b[0mInference done 1608/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:05:42\n",
      "\u001b[32m[09/27 14:16:13 d2.evaluation.evaluator]: \u001b[0mInference done 1657/4871. Dataloading: 0.0012 s/iter. Inference: 0.1031 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:05:36\n",
      "\u001b[32m[09/27 14:16:18 d2.evaluation.evaluator]: \u001b[0mInference done 1704/4871. Dataloading: 0.0012 s/iter. Inference: 0.1032 s/iter. Eval: 0.0004 s/iter. Total: 0.1049 s/iter. ETA=0:05:32\n",
      "\u001b[32m[09/27 14:16:23 d2.evaluation.evaluator]: \u001b[0mInference done 1754/4871. Dataloading: 0.0012 s/iter. Inference: 0.1031 s/iter. Eval: 0.0004 s/iter. Total: 0.1048 s/iter. ETA=0:05:26\n",
      "\u001b[32m[09/27 14:16:28 d2.evaluation.evaluator]: \u001b[0mInference done 1807/4871. Dataloading: 0.0012 s/iter. Inference: 0.1028 s/iter. Eval: 0.0004 s/iter. Total: 0.1045 s/iter. ETA=0:05:20\n",
      "\u001b[32m[09/27 14:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 1872/4871. Dataloading: 0.0012 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:05:10\n",
      "\u001b[32m[09/27 14:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 1922/4871. Dataloading: 0.0012 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:05:05\n",
      "\u001b[32m[09/27 14:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 1974/4871. Dataloading: 0.0012 s/iter. Inference: 0.1017 s/iter. Eval: 0.0004 s/iter. Total: 0.1034 s/iter. ETA=0:04:59\n",
      "\u001b[32m[09/27 14:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 2020/4871. Dataloading: 0.0012 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:04:55\n",
      "\u001b[32m[09/27 14:16:53 d2.evaluation.evaluator]: \u001b[0mInference done 2069/4871. Dataloading: 0.0012 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:04:50\n",
      "\u001b[32m[09/27 14:16:58 d2.evaluation.evaluator]: \u001b[0mInference done 2119/4871. Dataloading: 0.0012 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:04:44\n",
      "\u001b[32m[09/27 14:17:03 d2.evaluation.evaluator]: \u001b[0mInference done 2167/4871. Dataloading: 0.0012 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:04:40\n",
      "\u001b[32m[09/27 14:17:08 d2.evaluation.evaluator]: \u001b[0mInference done 2218/4871. Dataloading: 0.0012 s/iter. Inference: 0.1018 s/iter. Eval: 0.0004 s/iter. Total: 0.1035 s/iter. ETA=0:04:34\n",
      "\u001b[32m[09/27 14:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 2264/4871. Dataloading: 0.0012 s/iter. Inference: 0.1019 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:04:30\n",
      "\u001b[32m[09/27 14:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 2312/4871. Dataloading: 0.0012 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:04:25\n",
      "\u001b[32m[09/27 14:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 2361/4871. Dataloading: 0.0012 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:04:20\n",
      "\u001b[32m[09/27 14:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 2410/4871. Dataloading: 0.0012 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:04:15\n",
      "\u001b[32m[09/27 14:17:34 d2.evaluation.evaluator]: \u001b[0mInference done 2459/4871. Dataloading: 0.0012 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1036 s/iter. ETA=0:04:09\n",
      "\u001b[32m[09/27 14:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 2505/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:04:05\n",
      "\u001b[32m[09/27 14:17:44 d2.evaluation.evaluator]: \u001b[0mInference done 2552/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:04:00\n",
      "\u001b[32m[09/27 14:17:49 d2.evaluation.evaluator]: \u001b[0mInference done 2601/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:03:55\n",
      "\u001b[32m[09/27 14:17:54 d2.evaluation.evaluator]: \u001b[0mInference done 2651/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:03:50\n",
      "\u001b[32m[09/27 14:17:59 d2.evaluation.evaluator]: \u001b[0mInference done 2701/4871. Dataloading: 0.0012 s/iter. Inference: 0.1020 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:03:45\n",
      "\u001b[32m[09/27 14:18:04 d2.evaluation.evaluator]: \u001b[0mInference done 2747/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:03:40\n",
      "\u001b[32m[09/27 14:18:09 d2.evaluation.evaluator]: \u001b[0mInference done 2798/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:03:35\n",
      "\u001b[32m[09/27 14:18:14 d2.evaluation.evaluator]: \u001b[0mInference done 2847/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:03:30\n",
      "\u001b[32m[09/27 14:18:19 d2.evaluation.evaluator]: \u001b[0mInference done 2897/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1037 s/iter. ETA=0:03:24\n",
      "\u001b[32m[09/27 14:18:25 d2.evaluation.evaluator]: \u001b[0mInference done 2945/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:03:19\n",
      "\u001b[32m[09/27 14:18:30 d2.evaluation.evaluator]: \u001b[0mInference done 2992/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:03:15\n",
      "\u001b[32m[09/27 14:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 3041/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:03:10\n",
      "\u001b[32m[09/27 14:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 3091/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:03:04\n",
      "\u001b[32m[09/27 14:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 3140/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:02:59\n",
      "\u001b[32m[09/27 14:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 3189/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:02:54\n",
      "\u001b[32m[09/27 14:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 3237/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:02:49\n",
      "\u001b[32m[09/27 14:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 3284/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:02:44\n",
      "\u001b[32m[09/27 14:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 3333/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:02:39\n",
      "\u001b[32m[09/27 14:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 3383/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:02:34\n",
      "\u001b[32m[09/27 14:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 3431/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:02:29\n",
      "\u001b[32m[09/27 14:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 3478/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:02:24\n",
      "\u001b[32m[09/27 14:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 3528/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/27 14:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 3577/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/27 14:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 3629/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:02:08\n",
      "\u001b[32m[09/27 14:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 3677/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/27 14:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 3725/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:01:58\n",
      "\u001b[32m[09/27 14:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 3774/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:01:53\n",
      "\u001b[32m[09/27 14:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 3823/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/27 14:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 3873/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:01:43\n",
      "\u001b[32m[09/27 14:20:06 d2.evaluation.evaluator]: \u001b[0mInference done 3919/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:01:38\n",
      "\u001b[32m[09/27 14:20:11 d2.evaluation.evaluator]: \u001b[0mInference done 3967/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:01:33\n",
      "\u001b[32m[09/27 14:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 4016/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:01:28\n",
      "\u001b[32m[09/27 14:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 4065/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:01:23\n",
      "\u001b[32m[09/27 14:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 4114/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1038 s/iter. ETA=0:01:18\n",
      "\u001b[32m[09/27 14:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 4161/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:01:13\n",
      "\u001b[32m[09/27 14:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 4210/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:01:08\n",
      "\u001b[32m[09/27 14:20:41 d2.evaluation.evaluator]: \u001b[0mInference done 4259/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:01:03\n",
      "\u001b[32m[09/27 14:20:46 d2.evaluation.evaluator]: \u001b[0mInference done 4308/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/27 14:20:51 d2.evaluation.evaluator]: \u001b[0mInference done 4353/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:53\n",
      "\u001b[32m[09/27 14:20:56 d2.evaluation.evaluator]: \u001b[0mInference done 4402/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:48\n",
      "\u001b[32m[09/27 14:21:01 d2.evaluation.evaluator]: \u001b[0mInference done 4451/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/27 14:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 4501/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/27 14:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 4551/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/27 14:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 4597/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/27 14:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 4646/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/27 14:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 4696/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:18\n",
      "\u001b[32m[09/27 14:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 4745/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/27 14:21:37 d2.evaluation.evaluator]: \u001b[0mInference done 4796/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/27 14:21:42 d2.evaluation.evaluator]: \u001b[0mInference done 4842/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0004 s/iter. Total: 0.1039 s/iter. ETA=0:00:03\n",
      "\u001b[32m[09/27 14:21:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:25.458806 (0.103876 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 14:21:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:17 (0.102206 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 14:21:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 14:21:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/27 14:21:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.65s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/27 14:21:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/27 14:21:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.57 seconds.\n",
      "\u001b[32m[09/27 14:21:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/27 14:21:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.31 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[09/27 14:21:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[09/27 14:21:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 14:21:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[09/27 14:21:51 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/27 14:21:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 14:21:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 14:21:51 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[09/27 14:21:51 d2.utils.events]: \u001b[0m eta: 3:32:53  iter: 2999  total_loss: 0.6457  loss_cls: 0.3539  loss_box_reg: 0.2401  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.02241  time: 1.1022  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:22:12 d2.utils.events]: \u001b[0m eta: 3:32:26  iter: 3019  total_loss: 0.8318  loss_cls: 0.4256  loss_box_reg: 0.3339  loss_rpn_cls: 0.02303  loss_rpn_loc: 0.03518  time: 1.1020  data_time: 0.0142  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:22:34 d2.utils.events]: \u001b[0m eta: 3:32:11  iter: 3039  total_loss: 0.6814  loss_cls: 0.3991  loss_box_reg: 0.2838  loss_rpn_cls: 0.03045  loss_rpn_loc: 0.0356  time: 1.1020  data_time: 0.0144  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:22:56 d2.utils.events]: \u001b[0m eta: 3:31:38  iter: 3059  total_loss: 0.6087  loss_cls: 0.3503  loss_box_reg: 0.2375  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.01982  time: 1.1021  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:23:19 d2.utils.events]: \u001b[0m eta: 3:31:19  iter: 3079  total_loss: 0.7187  loss_cls: 0.3973  loss_box_reg: 0.28  loss_rpn_cls: 0.01881  loss_rpn_loc: 0.01628  time: 1.1021  data_time: 0.0166  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:23:41 d2.utils.events]: \u001b[0m eta: 3:30:55  iter: 3099  total_loss: 0.7912  loss_cls: 0.456  loss_box_reg: 0.2936  loss_rpn_cls: 0.02  loss_rpn_loc: 0.03334  time: 1.1022  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:24:03 d2.utils.events]: \u001b[0m eta: 3:30:31  iter: 3119  total_loss: 0.6044  loss_cls: 0.3343  loss_box_reg: 0.2341  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.01264  time: 1.1023  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:24:25 d2.utils.events]: \u001b[0m eta: 3:30:12  iter: 3139  total_loss: 0.7592  loss_cls: 0.4104  loss_box_reg: 0.286  loss_rpn_cls: 0.02402  loss_rpn_loc: 0.03396  time: 1.1023  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:24:48 d2.utils.events]: \u001b[0m eta: 3:29:49  iter: 3159  total_loss: 0.6427  loss_cls: 0.3431  loss_box_reg: 0.2194  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.0249  time: 1.1024  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:25:10 d2.utils.events]: \u001b[0m eta: 3:29:27  iter: 3179  total_loss: 0.7991  loss_cls: 0.4677  loss_box_reg: 0.3017  loss_rpn_cls: 0.02039  loss_rpn_loc: 0.02456  time: 1.1024  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:25:32 d2.utils.events]: \u001b[0m eta: 3:29:06  iter: 3199  total_loss: 0.7852  loss_cls: 0.3997  loss_box_reg: 0.3171  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.02369  time: 1.1024  data_time: 0.0132  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:25:54 d2.utils.events]: \u001b[0m eta: 3:28:48  iter: 3219  total_loss: 0.626  loss_cls: 0.349  loss_box_reg: 0.2458  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.02104  time: 1.1024  data_time: 0.0151  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:26:15 d2.utils.events]: \u001b[0m eta: 3:28:24  iter: 3239  total_loss: 0.5972  loss_cls: 0.3226  loss_box_reg: 0.2105  loss_rpn_cls: 0.0193  loss_rpn_loc: 0.01907  time: 1.1022  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:26:36 d2.utils.events]: \u001b[0m eta: 3:28:01  iter: 3259  total_loss: 0.7112  loss_cls: 0.3807  loss_box_reg: 0.2697  loss_rpn_cls: 0.02058  loss_rpn_loc: 0.01926  time: 1.1016  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:26:57 d2.utils.events]: \u001b[0m eta: 3:27:40  iter: 3279  total_loss: 0.7846  loss_cls: 0.3915  loss_box_reg: 0.2917  loss_rpn_cls: 0.02893  loss_rpn_loc: 0.04136  time: 1.1015  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:27:19 d2.utils.events]: \u001b[0m eta: 3:27:18  iter: 3299  total_loss: 0.7168  loss_cls: 0.3612  loss_box_reg: 0.2671  loss_rpn_cls: 0.02585  loss_rpn_loc: 0.03029  time: 1.1015  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:27:41 d2.utils.events]: \u001b[0m eta: 3:26:56  iter: 3319  total_loss: 0.6774  loss_cls: 0.3647  loss_box_reg: 0.2534  loss_rpn_cls: 0.01825  loss_rpn_loc: 0.02645  time: 1.1016  data_time: 0.0164  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:28:03 d2.utils.events]: \u001b[0m eta: 3:26:32  iter: 3339  total_loss: 0.7535  loss_cls: 0.3598  loss_box_reg: 0.2994  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.02245  time: 1.1015  data_time: 0.0148  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:28:25 d2.utils.events]: \u001b[0m eta: 3:26:11  iter: 3359  total_loss: 0.642  loss_cls: 0.3617  loss_box_reg: 0.2351  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.02216  time: 1.1015  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:28:48 d2.utils.events]: \u001b[0m eta: 3:25:49  iter: 3379  total_loss: 0.615  loss_cls: 0.3417  loss_box_reg: 0.2216  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.02008  time: 1.1016  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:29:10 d2.utils.events]: \u001b[0m eta: 3:25:30  iter: 3399  total_loss: 0.7781  loss_cls: 0.4266  loss_box_reg: 0.2655  loss_rpn_cls: 0.03326  loss_rpn_loc: 0.02733  time: 1.1016  data_time: 0.0147  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:29:32 d2.utils.events]: \u001b[0m eta: 3:25:07  iter: 3419  total_loss: 0.7209  loss_cls: 0.3889  loss_box_reg: 0.2858  loss_rpn_cls: 0.01908  loss_rpn_loc: 0.02993  time: 1.1017  data_time: 0.0134  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:29:55 d2.utils.events]: \u001b[0m eta: 3:24:47  iter: 3439  total_loss: 0.7759  loss_cls: 0.4304  loss_box_reg: 0.2623  loss_rpn_cls: 0.02914  loss_rpn_loc: 0.02616  time: 1.1018  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:30:17 d2.utils.events]: \u001b[0m eta: 3:24:26  iter: 3459  total_loss: 0.6483  loss_cls: 0.3551  loss_box_reg: 0.2198  loss_rpn_cls: 0.0188  loss_rpn_loc: 0.0168  time: 1.1018  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:30:39 d2.utils.events]: \u001b[0m eta: 3:24:08  iter: 3479  total_loss: 0.6342  loss_cls: 0.3462  loss_box_reg: 0.2493  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.02156  time: 1.1019  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:31:00 d2.utils.events]: \u001b[0m eta: 3:23:45  iter: 3499  total_loss: 0.7824  loss_cls: 0.3859  loss_box_reg: 0.2925  loss_rpn_cls: 0.017  loss_rpn_loc: 0.02802  time: 1.1017  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:31:23 d2.utils.events]: \u001b[0m eta: 3:23:27  iter: 3519  total_loss: 0.7914  loss_cls: 0.4121  loss_box_reg: 0.3012  loss_rpn_cls: 0.02305  loss_rpn_loc: 0.02043  time: 1.1018  data_time: 0.0141  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:31:45 d2.utils.events]: \u001b[0m eta: 3:23:05  iter: 3539  total_loss: 0.7374  loss_cls: 0.3943  loss_box_reg: 0.278  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.01845  time: 1.1017  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:32:07 d2.utils.events]: \u001b[0m eta: 3:22:46  iter: 3559  total_loss: 0.6586  loss_cls: 0.3743  loss_box_reg: 0.2607  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.01947  time: 1.1018  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:32:29 d2.utils.events]: \u001b[0m eta: 3:22:27  iter: 3579  total_loss: 0.698  loss_cls: 0.3813  loss_box_reg: 0.2711  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.02523  time: 1.1019  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:32:51 d2.utils.events]: \u001b[0m eta: 3:22:19  iter: 3599  total_loss: 0.6937  loss_cls: 0.3513  loss_box_reg: 0.2353  loss_rpn_cls: 0.01993  loss_rpn_loc: 0.02103  time: 1.1018  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:33:13 d2.utils.events]: \u001b[0m eta: 3:21:58  iter: 3619  total_loss: 0.7476  loss_cls: 0.3899  loss_box_reg: 0.2686  loss_rpn_cls: 0.01518  loss_rpn_loc: 0.01633  time: 1.1018  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:33:35 d2.utils.events]: \u001b[0m eta: 3:21:41  iter: 3639  total_loss: 0.7319  loss_cls: 0.4024  loss_box_reg: 0.293  loss_rpn_cls: 0.02154  loss_rpn_loc: 0.02726  time: 1.1018  data_time: 0.0145  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:33:57 d2.utils.events]: \u001b[0m eta: 3:21:15  iter: 3659  total_loss: 0.818  loss_cls: 0.3722  loss_box_reg: 0.3391  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.01631  time: 1.1017  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:34:19 d2.utils.events]: \u001b[0m eta: 3:20:54  iter: 3679  total_loss: 0.6955  loss_cls: 0.4238  loss_box_reg: 0.2803  loss_rpn_cls: 0.01984  loss_rpn_loc: 0.03405  time: 1.1017  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:34:40 d2.utils.events]: \u001b[0m eta: 3:20:31  iter: 3699  total_loss: 0.6368  loss_cls: 0.3439  loss_box_reg: 0.2388  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.02208  time: 1.1016  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:35:03 d2.utils.events]: \u001b[0m eta: 3:20:10  iter: 3719  total_loss: 0.6398  loss_cls: 0.3449  loss_box_reg: 0.2161  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.01438  time: 1.1016  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:35:25 d2.utils.events]: \u001b[0m eta: 3:19:48  iter: 3739  total_loss: 0.6551  loss_cls: 0.3544  loss_box_reg: 0.258  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.02935  time: 1.1017  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:35:47 d2.utils.events]: \u001b[0m eta: 3:19:27  iter: 3759  total_loss: 0.6857  loss_cls: 0.3344  loss_box_reg: 0.263  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.02184  time: 1.1017  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:36:09 d2.utils.events]: \u001b[0m eta: 3:19:06  iter: 3779  total_loss: 0.6866  loss_cls: 0.391  loss_box_reg: 0.2524  loss_rpn_cls: 0.02285  loss_rpn_loc: 0.03776  time: 1.1018  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:36:32 d2.utils.events]: \u001b[0m eta: 3:18:46  iter: 3799  total_loss: 0.5707  loss_cls: 0.2957  loss_box_reg: 0.2196  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.0143  time: 1.1019  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:36:54 d2.utils.events]: \u001b[0m eta: 3:18:25  iter: 3819  total_loss: 0.7203  loss_cls: 0.3688  loss_box_reg: 0.3086  loss_rpn_cls: 0.01911  loss_rpn_loc: 0.02793  time: 1.1019  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:37:16 d2.utils.events]: \u001b[0m eta: 3:18:03  iter: 3839  total_loss: 0.59  loss_cls: 0.3332  loss_box_reg: 0.2239  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.02309  time: 1.1020  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:37:39 d2.utils.events]: \u001b[0m eta: 3:17:42  iter: 3859  total_loss: 0.6719  loss_cls: 0.3477  loss_box_reg: 0.2427  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.02625  time: 1.1020  data_time: 0.0140  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:38:01 d2.utils.events]: \u001b[0m eta: 3:17:21  iter: 3879  total_loss: 0.679  loss_cls: 0.3394  loss_box_reg: 0.2838  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.04125  time: 1.1021  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:38:22 d2.utils.events]: \u001b[0m eta: 3:17:02  iter: 3899  total_loss: 0.6536  loss_cls: 0.3103  loss_box_reg: 0.2848  loss_rpn_cls: 0.02305  loss_rpn_loc: 0.0193  time: 1.1018  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:38:43 d2.utils.events]: \u001b[0m eta: 3:16:39  iter: 3919  total_loss: 0.753  loss_cls: 0.4377  loss_box_reg: 0.2518  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.02028  time: 1.1017  data_time: 0.0134  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:39:05 d2.utils.events]: \u001b[0m eta: 3:16:17  iter: 3939  total_loss: 0.6031  loss_cls: 0.3347  loss_box_reg: 0.2235  loss_rpn_cls: 0.01741  loss_rpn_loc: 0.02294  time: 1.1017  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:39:27 d2.utils.events]: \u001b[0m eta: 3:15:56  iter: 3959  total_loss: 0.7538  loss_cls: 0.3553  loss_box_reg: 0.3072  loss_rpn_cls: 0.02286  loss_rpn_loc: 0.03353  time: 1.1017  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:39:49 d2.utils.events]: \u001b[0m eta: 3:15:34  iter: 3979  total_loss: 0.6295  loss_cls: 0.3704  loss_box_reg: 0.2695  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.01947  time: 1.1016  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:40:11 d2.utils.events]: \u001b[0m eta: 3:15:09  iter: 3999  total_loss: 0.6015  loss_cls: 0.3103  loss_box_reg: 0.2276  loss_rpn_cls: 0.009747  loss_rpn_loc: 0.01468  time: 1.1016  data_time: 0.0150  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:40:34 d2.utils.events]: \u001b[0m eta: 3:14:49  iter: 4019  total_loss: 0.6668  loss_cls: 0.3851  loss_box_reg: 0.2443  loss_rpn_cls: 0.0189  loss_rpn_loc: 0.02735  time: 1.1017  data_time: 0.0135  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:40:56 d2.utils.events]: \u001b[0m eta: 3:14:27  iter: 4039  total_loss: 0.6501  loss_cls: 0.3525  loss_box_reg: 0.2469  loss_rpn_cls: 0.01446  loss_rpn_loc: 0.02175  time: 1.1016  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:41:18 d2.utils.events]: \u001b[0m eta: 3:14:06  iter: 4059  total_loss: 0.6931  loss_cls: 0.4012  loss_box_reg: 0.2713  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.0213  time: 1.1017  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:41:40 d2.utils.events]: \u001b[0m eta: 3:13:40  iter: 4079  total_loss: 0.6315  loss_cls: 0.3205  loss_box_reg: 0.2537  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.02071  time: 1.1017  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:42:02 d2.utils.events]: \u001b[0m eta: 3:13:14  iter: 4099  total_loss: 0.5687  loss_cls: 0.3263  loss_box_reg: 0.2325  loss_rpn_cls: 0.01817  loss_rpn_loc: 0.01422  time: 1.1016  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:42:24 d2.utils.events]: \u001b[0m eta: 3:12:57  iter: 4119  total_loss: 0.7474  loss_cls: 0.3931  loss_box_reg: 0.2826  loss_rpn_cls: 0.02273  loss_rpn_loc: 0.03021  time: 1.1017  data_time: 0.0143  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:42:46 d2.utils.events]: \u001b[0m eta: 3:12:36  iter: 4139  total_loss: 0.633  loss_cls: 0.3233  loss_box_reg: 0.2354  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.02774  time: 1.1017  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:43:08 d2.utils.events]: \u001b[0m eta: 3:12:15  iter: 4159  total_loss: 0.6822  loss_cls: 0.3536  loss_box_reg: 0.2756  loss_rpn_cls: 0.02119  loss_rpn_loc: 0.03191  time: 1.1018  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:43:31 d2.utils.events]: \u001b[0m eta: 3:11:53  iter: 4179  total_loss: 0.7301  loss_cls: 0.3955  loss_box_reg: 0.2871  loss_rpn_cls: 0.02199  loss_rpn_loc: 0.0298  time: 1.1018  data_time: 0.0135  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:43:53 d2.utils.events]: \u001b[0m eta: 3:11:34  iter: 4199  total_loss: 0.588  loss_cls: 0.314  loss_box_reg: 0.2309  loss_rpn_cls: 0.009386  loss_rpn_loc: 0.01494  time: 1.1019  data_time: 0.0141  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:44:15 d2.utils.events]: \u001b[0m eta: 3:11:07  iter: 4219  total_loss: 0.6342  loss_cls: 0.3863  loss_box_reg: 0.2437  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.02126  time: 1.1019  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:44:37 d2.utils.events]: \u001b[0m eta: 3:10:48  iter: 4239  total_loss: 0.7488  loss_cls: 0.389  loss_box_reg: 0.2884  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.02387  time: 1.1020  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:45:00 d2.utils.events]: \u001b[0m eta: 3:10:33  iter: 4259  total_loss: 0.6961  loss_cls: 0.3761  loss_box_reg: 0.2791  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.03298  time: 1.1020  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:45:22 d2.utils.events]: \u001b[0m eta: 3:10:14  iter: 4279  total_loss: 0.7953  loss_cls: 0.3987  loss_box_reg: 0.2645  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.02046  time: 1.1021  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:45:44 d2.utils.events]: \u001b[0m eta: 3:09:56  iter: 4299  total_loss: 0.614  loss_cls: 0.334  loss_box_reg: 0.2486  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.0318  time: 1.1021  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:46:07 d2.utils.events]: \u001b[0m eta: 3:09:32  iter: 4319  total_loss: 0.6499  loss_cls: 0.3849  loss_box_reg: 0.2243  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.01659  time: 1.1022  data_time: 0.0141  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:46:28 d2.utils.events]: \u001b[0m eta: 3:09:21  iter: 4339  total_loss: 0.7402  loss_cls: 0.4052  loss_box_reg: 0.2747  loss_rpn_cls: 0.01972  loss_rpn_loc: 0.03295  time: 1.1022  data_time: 0.0115  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:46:54 d2.utils.events]: \u001b[0m eta: 3:09:24  iter: 4359  total_loss: 0.5832  loss_cls: 0.3022  loss_box_reg: 0.2135  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.01429  time: 1.1029  data_time: 0.0135  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:47:19 d2.utils.events]: \u001b[0m eta: 3:09:21  iter: 4379  total_loss: 0.6196  loss_cls: 0.3429  loss_box_reg: 0.2055  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.02206  time: 1.1036  data_time: 0.0136  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:47:46 d2.utils.events]: \u001b[0m eta: 3:15:49  iter: 4399  total_loss: 0.7253  loss_cls: 0.3776  loss_box_reg: 0.2919  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.02489  time: 1.1047  data_time: 0.0169  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:48:12 d2.utils.events]: \u001b[0m eta: 3:24:34  iter: 4419  total_loss: 0.5767  loss_cls: 0.3175  loss_box_reg: 0.238  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.02229  time: 1.1056  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:48:38 d2.utils.events]: \u001b[0m eta: 3:24:26  iter: 4439  total_loss: 0.7331  loss_cls: 0.3963  loss_box_reg: 0.2741  loss_rpn_cls: 0.02209  loss_rpn_loc: 0.0407  time: 1.1066  data_time: 0.0147  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:49:05 d2.utils.events]: \u001b[0m eta: 3:24:08  iter: 4459  total_loss: 0.6575  loss_cls: 0.3707  loss_box_reg: 0.2545  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.01518  time: 1.1076  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:49:31 d2.utils.events]: \u001b[0m eta: 3:23:51  iter: 4479  total_loss: 0.6302  loss_cls: 0.3099  loss_box_reg: 0.227  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.01832  time: 1.1085  data_time: 0.0162  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:49:58 d2.utils.events]: \u001b[0m eta: 3:23:34  iter: 4499  total_loss: 0.581  loss_cls: 0.317  loss_box_reg: 0.2073  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.0279  time: 1.1094  data_time: 0.0142  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:50:23 d2.utils.events]: \u001b[0m eta: 3:23:14  iter: 4519  total_loss: 0.6379  loss_cls: 0.3452  loss_box_reg: 0.2467  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.02074  time: 1.1101  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:50:48 d2.utils.events]: \u001b[0m eta: 3:22:56  iter: 4539  total_loss: 0.7708  loss_cls: 0.4354  loss_box_reg: 0.2867  loss_rpn_cls: 0.0185  loss_rpn_loc: 0.0234  time: 1.1108  data_time: 0.0167  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:51:15 d2.utils.events]: \u001b[0m eta: 3:22:36  iter: 4559  total_loss: 0.5972  loss_cls: 0.3339  loss_box_reg: 0.2313  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.02096  time: 1.1117  data_time: 0.0143  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:51:40 d2.utils.events]: \u001b[0m eta: 3:22:15  iter: 4579  total_loss: 0.6633  loss_cls: 0.3582  loss_box_reg: 0.2417  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.02712  time: 1.1125  data_time: 0.0136  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:52:07 d2.utils.events]: \u001b[0m eta: 3:21:56  iter: 4599  total_loss: 0.6419  loss_cls: 0.329  loss_box_reg: 0.2297  loss_rpn_cls: 0.02096  loss_rpn_loc: 0.02928  time: 1.1133  data_time: 0.0117  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:52:33 d2.utils.events]: \u001b[0m eta: 3:21:35  iter: 4619  total_loss: 0.655  loss_cls: 0.3314  loss_box_reg: 0.292  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.02572  time: 1.1142  data_time: 0.0117  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:52:58 d2.utils.events]: \u001b[0m eta: 3:21:14  iter: 4639  total_loss: 0.7541  loss_cls: 0.3575  loss_box_reg: 0.2644  loss_rpn_cls: 0.02374  loss_rpn_loc: 0.03116  time: 1.1148  data_time: 0.0112  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:53:24 d2.utils.events]: \u001b[0m eta: 3:20:53  iter: 4659  total_loss: 0.6074  loss_cls: 0.3444  loss_box_reg: 0.2316  loss_rpn_cls: 0.01541  loss_rpn_loc: 0.02019  time: 1.1156  data_time: 0.0134  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:53:50 d2.utils.events]: \u001b[0m eta: 3:20:30  iter: 4679  total_loss: 0.6645  loss_cls: 0.3261  loss_box_reg: 0.2586  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.04619  time: 1.1164  data_time: 0.0141  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:54:16 d2.utils.events]: \u001b[0m eta: 3:20:10  iter: 4699  total_loss: 0.7223  loss_cls: 0.3827  loss_box_reg: 0.2714  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.02171  time: 1.1171  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:54:41 d2.utils.events]: \u001b[0m eta: 3:19:48  iter: 4719  total_loss: 0.5843  loss_cls: 0.3126  loss_box_reg: 0.2044  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.01937  time: 1.1178  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:55:07 d2.utils.events]: \u001b[0m eta: 3:19:28  iter: 4739  total_loss: 0.6232  loss_cls: 0.33  loss_box_reg: 0.2371  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.0159  time: 1.1185  data_time: 0.0135  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:55:33 d2.utils.events]: \u001b[0m eta: 3:19:08  iter: 4759  total_loss: 0.704  loss_cls: 0.3726  loss_box_reg: 0.2832  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.02893  time: 1.1194  data_time: 0.0154  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:56:00 d2.utils.events]: \u001b[0m eta: 3:18:46  iter: 4779  total_loss: 0.8748  loss_cls: 0.4506  loss_box_reg: 0.3253  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.01801  time: 1.1203  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:56:26 d2.utils.events]: \u001b[0m eta: 3:18:25  iter: 4799  total_loss: 0.5399  loss_cls: 0.3031  loss_box_reg: 0.216  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.01464  time: 1.1210  data_time: 0.0145  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:56:52 d2.utils.events]: \u001b[0m eta: 3:18:02  iter: 4819  total_loss: 0.6575  loss_cls: 0.357  loss_box_reg: 0.2502  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.01543  time: 1.1218  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:57:18 d2.utils.events]: \u001b[0m eta: 3:17:45  iter: 4839  total_loss: 0.7571  loss_cls: 0.4106  loss_box_reg: 0.2857  loss_rpn_cls: 0.02353  loss_rpn_loc: 0.02621  time: 1.1225  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:57:45 d2.utils.events]: \u001b[0m eta: 3:17:27  iter: 4859  total_loss: 0.6949  loss_cls: 0.3717  loss_box_reg: 0.277  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.01943  time: 1.1233  data_time: 0.0138  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:58:11 d2.utils.events]: \u001b[0m eta: 3:17:10  iter: 4879  total_loss: 0.697  loss_cls: 0.37  loss_box_reg: 0.3056  loss_rpn_cls: 0.03087  loss_rpn_loc: 0.03329  time: 1.1240  data_time: 0.0159  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:58:37 d2.utils.events]: \u001b[0m eta: 3:16:56  iter: 4899  total_loss: 0.67  loss_cls: 0.3807  loss_box_reg: 0.2183  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.01783  time: 1.1248  data_time: 0.0137  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:59:03 d2.utils.events]: \u001b[0m eta: 3:17:20  iter: 4919  total_loss: 0.7323  loss_cls: 0.3672  loss_box_reg: 0.2921  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.02484  time: 1.1255  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:59:29 d2.utils.events]: \u001b[0m eta: 3:17:51  iter: 4939  total_loss: 0.6538  loss_cls: 0.3913  loss_box_reg: 0.2098  loss_rpn_cls: 0.01686  loss_rpn_loc: 0.02506  time: 1.1262  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 14:59:55 d2.utils.events]: \u001b[0m eta: 3:20:09  iter: 4959  total_loss: 0.6984  loss_cls: 0.3586  loss_box_reg: 0.2677  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.01841  time: 1.1270  data_time: 0.0148  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:00:22 d2.utils.events]: \u001b[0m eta: 3:21:34  iter: 4979  total_loss: 0.62  loss_cls: 0.3186  loss_box_reg: 0.2312  loss_rpn_cls: 0.01506  loss_rpn_loc: 0.03079  time: 1.1278  data_time: 0.0173  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:00:47 d2.utils.events]: \u001b[0m eta: 3:23:33  iter: 4999  total_loss: 0.6727  loss_cls: 0.3396  loss_box_reg: 0.2812  loss_rpn_cls: 0.0096  loss_rpn_loc: 0.01733  time: 1.1284  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:01:13 d2.utils.events]: \u001b[0m eta: 3:26:01  iter: 5019  total_loss: 0.5537  loss_cls: 0.2908  loss_box_reg: 0.1844  loss_rpn_cls: 0.009444  loss_rpn_loc: 0.01427  time: 1.1290  data_time: 0.0150  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:01:39 d2.utils.events]: \u001b[0m eta: 3:27:40  iter: 5039  total_loss: 0.6433  loss_cls: 0.3353  loss_box_reg: 0.2546  loss_rpn_cls: 0.01797  loss_rpn_loc: 0.03317  time: 1.1297  data_time: 0.0138  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:02:06 d2.utils.events]: \u001b[0m eta: 3:28:52  iter: 5059  total_loss: 0.796  loss_cls: 0.4164  loss_box_reg: 0.3124  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.01971  time: 1.1304  data_time: 0.0173  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:02:32 d2.utils.events]: \u001b[0m eta: 3:31:27  iter: 5079  total_loss: 0.5125  loss_cls: 0.2725  loss_box_reg: 0.2083  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01189  time: 1.1312  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:02:57 d2.utils.events]: \u001b[0m eta: 3:32:22  iter: 5099  total_loss: 0.6057  loss_cls: 0.3193  loss_box_reg: 0.2229  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.01374  time: 1.1317  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:03:23 d2.utils.events]: \u001b[0m eta: 3:32:46  iter: 5119  total_loss: 0.7019  loss_cls: 0.3794  loss_box_reg: 0.2725  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.03193  time: 1.1324  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:03:50 d2.utils.events]: \u001b[0m eta: 3:32:51  iter: 5139  total_loss: 0.7689  loss_cls: 0.3694  loss_box_reg: 0.2951  loss_rpn_cls: 0.01677  loss_rpn_loc: 0.02681  time: 1.1331  data_time: 0.0149  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:04:14 d2.utils.events]: \u001b[0m eta: 3:32:45  iter: 5159  total_loss: 0.6159  loss_cls: 0.325  loss_box_reg: 0.2065  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.0188  time: 1.1334  data_time: 0.0183  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:04:36 d2.utils.events]: \u001b[0m eta: 3:32:19  iter: 5179  total_loss: 0.6445  loss_cls: 0.3111  loss_box_reg: 0.247  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.02467  time: 1.1334  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:04:59 d2.utils.events]: \u001b[0m eta: 3:31:53  iter: 5199  total_loss: 0.657  loss_cls: 0.346  loss_box_reg: 0.2705  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.01595  time: 1.1333  data_time: 0.0169  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:05:19 d2.utils.events]: \u001b[0m eta: 3:31:27  iter: 5219  total_loss: 0.6234  loss_cls: 0.3186  loss_box_reg: 0.2191  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.02169  time: 1.1328  data_time: 0.0141  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:05:41 d2.utils.events]: \u001b[0m eta: 3:31:01  iter: 5239  total_loss: 0.6333  loss_cls: 0.3574  loss_box_reg: 0.2354  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.0424  time: 1.1327  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:06:03 d2.utils.events]: \u001b[0m eta: 3:30:35  iter: 5259  total_loss: 0.5838  loss_cls: 0.2896  loss_box_reg: 0.2539  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.02895  time: 1.1326  data_time: 0.0148  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:06:25 d2.utils.events]: \u001b[0m eta: 3:30:09  iter: 5279  total_loss: 0.4938  loss_cls: 0.2762  loss_box_reg: 0.226  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.01819  time: 1.1325  data_time: 0.0139  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:06:47 d2.utils.events]: \u001b[0m eta: 3:29:43  iter: 5299  total_loss: 0.7282  loss_cls: 0.3667  loss_box_reg: 0.2694  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.03374  time: 1.1323  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:07:09 d2.utils.events]: \u001b[0m eta: 3:29:17  iter: 5319  total_loss: 0.5998  loss_cls: 0.2911  loss_box_reg: 0.2418  loss_rpn_cls: 0.01652  loss_rpn_loc: 0.02668  time: 1.1323  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:07:32 d2.utils.events]: \u001b[0m eta: 3:28:52  iter: 5339  total_loss: 0.5836  loss_cls: 0.321  loss_box_reg: 0.2092  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.03109  time: 1.1322  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:07:54 d2.utils.events]: \u001b[0m eta: 3:27:56  iter: 5359  total_loss: 0.6294  loss_cls: 0.3544  loss_box_reg: 0.2541  loss_rpn_cls: 0.009552  loss_rpn_loc: 0.01483  time: 1.1321  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:08:16 d2.utils.events]: \u001b[0m eta: 3:27:08  iter: 5379  total_loss: 0.7253  loss_cls: 0.375  loss_box_reg: 0.2753  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.02621  time: 1.1320  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:08:38 d2.utils.events]: \u001b[0m eta: 3:25:39  iter: 5399  total_loss: 0.6246  loss_cls: 0.3154  loss_box_reg: 0.264  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.01573  time: 1.1319  data_time: 0.0134  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:09:00 d2.utils.events]: \u001b[0m eta: 3:23:35  iter: 5419  total_loss: 0.5863  loss_cls: 0.3056  loss_box_reg: 0.2519  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.02691  time: 1.1318  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:09:22 d2.utils.events]: \u001b[0m eta: 3:20:39  iter: 5439  total_loss: 0.6224  loss_cls: 0.2852  loss_box_reg: 0.2618  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.02385  time: 1.1317  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:09:44 d2.utils.events]: \u001b[0m eta: 3:18:01  iter: 5459  total_loss: 0.6008  loss_cls: 0.2972  loss_box_reg: 0.2344  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.02081  time: 1.1315  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:10:06 d2.utils.events]: \u001b[0m eta: 3:14:50  iter: 5479  total_loss: 0.6313  loss_cls: 0.354  loss_box_reg: 0.2377  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.02283  time: 1.1314  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:10:28 d2.utils.events]: \u001b[0m eta: 3:11:41  iter: 5499  total_loss: 0.7266  loss_cls: 0.3752  loss_box_reg: 0.2823  loss_rpn_cls: 0.02053  loss_rpn_loc: 0.0288  time: 1.1314  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:10:51 d2.utils.events]: \u001b[0m eta: 3:09:24  iter: 5519  total_loss: 0.728  loss_cls: 0.384  loss_box_reg: 0.2763  loss_rpn_cls: 0.0252  loss_rpn_loc: 0.03078  time: 1.1313  data_time: 0.0119  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:11:12 d2.utils.events]: \u001b[0m eta: 3:07:12  iter: 5539  total_loss: 0.5867  loss_cls: 0.3799  loss_box_reg: 0.2333  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.01834  time: 1.1311  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:11:34 d2.utils.events]: \u001b[0m eta: 3:05:08  iter: 5559  total_loss: 0.626  loss_cls: 0.362  loss_box_reg: 0.2033  loss_rpn_cls: 0.01845  loss_rpn_loc: 0.02707  time: 1.1310  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:11:56 d2.utils.events]: \u001b[0m eta: 3:03:58  iter: 5579  total_loss: 0.5782  loss_cls: 0.3365  loss_box_reg: 0.2413  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.02287  time: 1.1308  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:12:18 d2.utils.events]: \u001b[0m eta: 3:03:03  iter: 5599  total_loss: 0.5957  loss_cls: 0.3132  loss_box_reg: 0.2143  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.02337  time: 1.1307  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:12:39 d2.utils.events]: \u001b[0m eta: 3:02:31  iter: 5619  total_loss: 0.5301  loss_cls: 0.2808  loss_box_reg: 0.2032  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.02018  time: 1.1305  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:13:02 d2.utils.events]: \u001b[0m eta: 3:02:01  iter: 5639  total_loss: 0.6044  loss_cls: 0.3177  loss_box_reg: 0.233  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.01878  time: 1.1304  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:13:24 d2.utils.events]: \u001b[0m eta: 3:01:34  iter: 5659  total_loss: 0.4568  loss_cls: 0.2379  loss_box_reg: 0.1697  loss_rpn_cls: 0.009679  loss_rpn_loc: 0.009476  time: 1.1304  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:13:46 d2.utils.events]: \u001b[0m eta: 3:01:09  iter: 5679  total_loss: 0.6036  loss_cls: 0.3006  loss_box_reg: 0.2415  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.02355  time: 1.1303  data_time: 0.0132  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:14:08 d2.utils.events]: \u001b[0m eta: 3:00:41  iter: 5699  total_loss: 0.5726  loss_cls: 0.3057  loss_box_reg: 0.2596  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.02736  time: 1.1302  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:14:30 d2.utils.events]: \u001b[0m eta: 3:00:16  iter: 5719  total_loss: 0.6516  loss_cls: 0.3294  loss_box_reg: 0.2447  loss_rpn_cls: 0.02045  loss_rpn_loc: 0.02788  time: 1.1301  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:14:53 d2.utils.events]: \u001b[0m eta: 2:59:50  iter: 5739  total_loss: 0.6612  loss_cls: 0.3356  loss_box_reg: 0.2535  loss_rpn_cls: 0.02141  loss_rpn_loc: 0.02744  time: 1.1300  data_time: 0.0140  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:15:15 d2.utils.events]: \u001b[0m eta: 2:59:24  iter: 5759  total_loss: 0.6831  loss_cls: 0.382  loss_box_reg: 0.2611  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.02007  time: 1.1300  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:15:37 d2.utils.events]: \u001b[0m eta: 2:58:58  iter: 5779  total_loss: 0.7304  loss_cls: 0.3622  loss_box_reg: 0.3176  loss_rpn_cls: 0.02108  loss_rpn_loc: 0.03597  time: 1.1299  data_time: 0.0146  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:15:59 d2.utils.events]: \u001b[0m eta: 2:58:32  iter: 5799  total_loss: 0.615  loss_cls: 0.2844  loss_box_reg: 0.2491  loss_rpn_cls: 0.02067  loss_rpn_loc: 0.02157  time: 1.1298  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:16:22 d2.utils.events]: \u001b[0m eta: 2:58:05  iter: 5819  total_loss: 0.622  loss_cls: 0.2974  loss_box_reg: 0.233  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.0253  time: 1.1298  data_time: 0.0119  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:16:42 d2.utils.events]: \u001b[0m eta: 2:57:35  iter: 5839  total_loss: 0.642  loss_cls: 0.3306  loss_box_reg: 0.2235  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.03041  time: 1.1295  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:17:05 d2.utils.events]: \u001b[0m eta: 2:57:08  iter: 5859  total_loss: 0.5872  loss_cls: 0.3285  loss_box_reg: 0.2516  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.02459  time: 1.1294  data_time: 0.0174  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:17:27 d2.utils.events]: \u001b[0m eta: 2:56:43  iter: 5879  total_loss: 0.6351  loss_cls: 0.3472  loss_box_reg: 0.2433  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.0215  time: 1.1293  data_time: 0.0154  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:17:49 d2.utils.events]: \u001b[0m eta: 2:56:16  iter: 5899  total_loss: 0.6216  loss_cls: 0.3425  loss_box_reg: 0.2526  loss_rpn_cls: 0.02135  loss_rpn_loc: 0.03014  time: 1.1292  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:18:11 d2.utils.events]: \u001b[0m eta: 2:55:50  iter: 5919  total_loss: 0.6644  loss_cls: 0.3479  loss_box_reg: 0.2587  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.03687  time: 1.1292  data_time: 0.0164  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:18:33 d2.utils.events]: \u001b[0m eta: 2:55:24  iter: 5939  total_loss: 0.6955  loss_cls: 0.3779  loss_box_reg: 0.2626  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.02518  time: 1.1291  data_time: 0.0144  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:18:55 d2.utils.events]: \u001b[0m eta: 2:54:59  iter: 5959  total_loss: 0.6915  loss_cls: 0.3856  loss_box_reg: 0.247  loss_rpn_cls: 0.02092  loss_rpn_loc: 0.0355  time: 1.1290  data_time: 0.0138  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:19:18 d2.utils.events]: \u001b[0m eta: 2:54:32  iter: 5979  total_loss: 0.6482  loss_cls: 0.3212  loss_box_reg: 0.2827  loss_rpn_cls: 0.0181  loss_rpn_loc: 0.03127  time: 1.1290  data_time: 0.0144  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:19:40 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/test.json\n",
      "\u001b[32m[09/27 15:19:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 15:19:40 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 15:19:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.50 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/27 15:19:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/27 15:19:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/27 15:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0006 s/iter. Inference: 0.0517 s/iter. Eval: 0.0003 s/iter. Total: 0.0526 s/iter. ETA=0:04:15\n",
      "\u001b[32m[09/27 15:19:47 d2.evaluation.evaluator]: \u001b[0mInference done 57/4871. Dataloading: 0.0011 s/iter. Inference: 0.1028 s/iter. Eval: 0.0003 s/iter. Total: 0.1043 s/iter. ETA=0:08:22\n",
      "\u001b[32m[09/27 15:19:52 d2.evaluation.evaluator]: \u001b[0mInference done 108/4871. Dataloading: 0.0012 s/iter. Inference: 0.1010 s/iter. Eval: 0.0003 s/iter. Total: 0.1025 s/iter. ETA=0:08:08\n",
      "\u001b[32m[09/27 15:19:57 d2.evaluation.evaluator]: \u001b[0mInference done 156/4871. Dataloading: 0.0011 s/iter. Inference: 0.1015 s/iter. Eval: 0.0003 s/iter. Total: 0.1030 s/iter. ETA=0:08:05\n",
      "\u001b[32m[09/27 15:20:02 d2.evaluation.evaluator]: \u001b[0mInference done 206/4871. Dataloading: 0.0011 s/iter. Inference: 0.1011 s/iter. Eval: 0.0003 s/iter. Total: 0.1027 s/iter. ETA=0:07:58\n",
      "\u001b[32m[09/27 15:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 254/4871. Dataloading: 0.0011 s/iter. Inference: 0.1016 s/iter. Eval: 0.0003 s/iter. Total: 0.1031 s/iter. ETA=0:07:56\n",
      "\u001b[32m[09/27 15:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 301/4871. Dataloading: 0.0011 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:07:54\n",
      "\u001b[32m[09/27 15:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 351/4871. Dataloading: 0.0011 s/iter. Inference: 0.1018 s/iter. Eval: 0.0003 s/iter. Total: 0.1033 s/iter. ETA=0:07:47\n",
      "\u001b[32m[09/27 15:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 401/4871. Dataloading: 0.0011 s/iter. Inference: 0.1014 s/iter. Eval: 0.0003 s/iter. Total: 0.1029 s/iter. ETA=0:07:40\n",
      "\u001b[32m[09/27 15:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 449/4871. Dataloading: 0.0011 s/iter. Inference: 0.1016 s/iter. Eval: 0.0003 s/iter. Total: 0.1031 s/iter. ETA=0:07:36\n",
      "\u001b[32m[09/27 15:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 496/4871. Dataloading: 0.0011 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:07:33\n",
      "\u001b[32m[09/27 15:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 546/4871. Dataloading: 0.0011 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1035 s/iter. ETA=0:07:27\n",
      "\u001b[32m[09/27 15:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 596/4871. Dataloading: 0.0011 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1034 s/iter. ETA=0:07:22\n",
      "\u001b[32m[09/27 15:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 646/4871. Dataloading: 0.0011 s/iter. Inference: 0.1018 s/iter. Eval: 0.0003 s/iter. Total: 0.1033 s/iter. ETA=0:07:16\n",
      "\u001b[32m[09/27 15:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 694/4871. Dataloading: 0.0011 s/iter. Inference: 0.1019 s/iter. Eval: 0.0003 s/iter. Total: 0.1034 s/iter. ETA=0:07:11\n",
      "\u001b[32m[09/27 15:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 740/4871. Dataloading: 0.0011 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:07:09\n",
      "\u001b[32m[09/27 15:21:03 d2.evaluation.evaluator]: \u001b[0mInference done 790/4871. Dataloading: 0.0011 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:07:02\n",
      "\u001b[32m[09/27 15:21:08 d2.evaluation.evaluator]: \u001b[0mInference done 839/4871. Dataloading: 0.0011 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:06:58\n",
      "\u001b[32m[09/27 15:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 890/4871. Dataloading: 0.0011 s/iter. Inference: 0.1020 s/iter. Eval: 0.0003 s/iter. Total: 0.1035 s/iter. ETA=0:06:52\n",
      "\u001b[32m[09/27 15:21:18 d2.evaluation.evaluator]: \u001b[0mInference done 938/4871. Dataloading: 0.0011 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:06:47\n",
      "\u001b[32m[09/27 15:21:23 d2.evaluation.evaluator]: \u001b[0mInference done 984/4871. Dataloading: 0.0011 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:06:43\n",
      "\u001b[32m[09/27 15:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 1036/4871. Dataloading: 0.0011 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:06:37\n",
      "\u001b[32m[09/27 15:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 1086/4871. Dataloading: 0.0011 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:06:32\n",
      "\u001b[32m[09/27 15:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 1136/4871. Dataloading: 0.0011 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:06:26\n",
      "\u001b[32m[09/27 15:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 1185/4871. Dataloading: 0.0011 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:06:21\n",
      "\u001b[32m[09/27 15:21:49 d2.evaluation.evaluator]: \u001b[0mInference done 1231/4871. Dataloading: 0.0011 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:06:17\n",
      "\u001b[32m[09/27 15:21:54 d2.evaluation.evaluator]: \u001b[0mInference done 1282/4871. Dataloading: 0.0011 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:06:12\n",
      "\u001b[32m[09/27 15:21:59 d2.evaluation.evaluator]: \u001b[0mInference done 1330/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:06:07\n",
      "\u001b[32m[09/27 15:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 1382/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:06:01\n",
      "\u001b[32m[09/27 15:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 1430/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:05:56\n",
      "\u001b[32m[09/27 15:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 1475/4871. Dataloading: 0.0012 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:05:52\n",
      "\u001b[32m[09/27 15:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 1524/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:47\n",
      "\u001b[32m[09/27 15:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 1574/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:42\n",
      "\u001b[32m[09/27 15:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 1626/4871. Dataloading: 0.0012 s/iter. Inference: 0.1021 s/iter. Eval: 0.0003 s/iter. Total: 0.1036 s/iter. ETA=0:05:36\n",
      "\u001b[32m[09/27 15:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 1673/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:05:31\n",
      "\u001b[32m[09/27 15:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 1720/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:27\n",
      "\u001b[32m[09/27 15:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 1768/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:22\n",
      "\u001b[32m[09/27 15:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 1817/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:17\n",
      "\u001b[32m[09/27 15:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 1867/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:05:11\n",
      "\u001b[32m[09/27 15:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 1913/4871. Dataloading: 0.0012 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:05:07\n",
      "\u001b[32m[09/27 15:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 1961/4871. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:05:02\n",
      "\u001b[32m[09/27 15:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 2011/4871. Dataloading: 0.0012 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:04:57\n",
      "\u001b[32m[09/27 15:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 2061/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:04:51\n",
      "\u001b[32m[09/27 15:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 2111/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:04:46\n",
      "\u001b[32m[09/27 15:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 2156/4871. Dataloading: 0.0012 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:04:42\n",
      "\u001b[32m[09/27 15:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 2208/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:04:36\n",
      "\u001b[32m[09/27 15:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 2258/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:04:31\n",
      "\u001b[32m[09/27 15:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 2308/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:04:25\n",
      "\u001b[32m[09/27 15:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 2356/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:04:20\n",
      "\u001b[32m[09/27 15:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 2406/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:04:15\n",
      "\u001b[32m[09/27 15:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 2455/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:04:10\n",
      "\u001b[32m[09/27 15:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 2504/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:04:05\n",
      "\u001b[32m[09/27 15:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 2553/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1037 s/iter. ETA=0:04:00\n",
      "\u001b[32m[09/27 15:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 2600/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:03:55\n",
      "\u001b[32m[09/27 15:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 2648/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:03:50\n",
      "\u001b[32m[09/27 15:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 2697/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:03:45\n",
      "\u001b[32m[09/27 15:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 2747/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:03:40\n",
      "\u001b[32m[09/27 15:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 2794/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:03:35\n",
      "\u001b[32m[09/27 15:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 2840/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:03:31\n",
      "\u001b[32m[09/27 15:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 2890/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:03:25\n",
      "\u001b[32m[09/27 15:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 2939/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:03:20\n",
      "\u001b[32m[09/27 15:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 2989/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:03:15\n",
      "\u001b[32m[09/27 15:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 3038/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:03:10\n",
      "\u001b[32m[09/27 15:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 3085/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:03:05\n",
      "\u001b[32m[09/27 15:25:07 d2.evaluation.evaluator]: \u001b[0mInference done 3136/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:03:00\n",
      "\u001b[32m[09/27 15:25:12 d2.evaluation.evaluator]: \u001b[0mInference done 3184/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:02:55\n",
      "\u001b[32m[09/27 15:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 3234/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:02:50\n",
      "\u001b[32m[09/27 15:25:22 d2.evaluation.evaluator]: \u001b[0mInference done 3285/4871. Dataloading: 0.0012 s/iter. Inference: 0.1022 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:02:44\n",
      "\u001b[32m[09/27 15:25:27 d2.evaluation.evaluator]: \u001b[0mInference done 3330/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/27 15:25:32 d2.evaluation.evaluator]: \u001b[0mInference done 3380/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:02:34\n",
      "\u001b[32m[09/27 15:25:37 d2.evaluation.evaluator]: \u001b[0mInference done 3428/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:02:29\n",
      "\u001b[32m[09/27 15:25:42 d2.evaluation.evaluator]: \u001b[0mInference done 3478/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1039 s/iter. ETA=0:02:24\n",
      "\u001b[32m[09/27 15:25:47 d2.evaluation.evaluator]: \u001b[0mInference done 3527/4871. Dataloading: 0.0012 s/iter. Inference: 0.1023 s/iter. Eval: 0.0003 s/iter. Total: 0.1038 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/27 15:25:52 d2.evaluation.evaluator]: \u001b[0mInference done 3570/4871. Dataloading: 0.0012 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:02:15\n",
      "\u001b[32m[09/27 15:25:57 d2.evaluation.evaluator]: \u001b[0mInference done 3616/4871. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1041 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/27 15:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 3666/4871. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:02:05\n",
      "\u001b[32m[09/27 15:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 3716/4871. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:02:00\n",
      "\u001b[32m[09/27 15:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 3768/4871. Dataloading: 0.0012 s/iter. Inference: 0.1024 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:01:54\n",
      "\u001b[32m[09/27 15:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 3814/4871. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/27 15:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 3863/4871. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:01:44\n",
      "\u001b[32m[09/27 15:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 3912/4871. Dataloading: 0.0012 s/iter. Inference: 0.1025 s/iter. Eval: 0.0003 s/iter. Total: 0.1040 s/iter. ETA=0:01:39\n",
      "\u001b[32m[09/27 15:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 4019/4871. Dataloading: 0.0012 s/iter. Inference: 0.1009 s/iter. Eval: 0.0003 s/iter. Total: 0.1025 s/iter. ETA=0:01:27\n",
      "\u001b[32m[09/27 15:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 4127/4871. Dataloading: 0.0012 s/iter. Inference: 0.0994 s/iter. Eval: 0.0004 s/iter. Total: 0.1010 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/27 15:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 4236/4871. Dataloading: 0.0012 s/iter. Inference: 0.0980 s/iter. Eval: 0.0004 s/iter. Total: 0.0996 s/iter. ETA=0:01:03\n",
      "\u001b[32m[09/27 15:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 4348/4871. Dataloading: 0.0012 s/iter. Inference: 0.0966 s/iter. Eval: 0.0003 s/iter. Total: 0.0982 s/iter. ETA=0:00:51\n",
      "\u001b[32m[09/27 15:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 4460/4871. Dataloading: 0.0012 s/iter. Inference: 0.0953 s/iter. Eval: 0.0003 s/iter. Total: 0.0969 s/iter. ETA=0:00:39\n",
      "\u001b[32m[09/27 15:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 4572/4871. Dataloading: 0.0012 s/iter. Inference: 0.0940 s/iter. Eval: 0.0003 s/iter. Total: 0.0956 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/27 15:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 4683/4871. Dataloading: 0.0012 s/iter. Inference: 0.0928 s/iter. Eval: 0.0003 s/iter. Total: 0.0944 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/27 15:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 4795/4871. Dataloading: 0.0012 s/iter. Inference: 0.0917 s/iter. Eval: 0.0003 s/iter. Total: 0.0932 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/27 15:27:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:07:30.155488 (0.092510 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 15:27:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:07:22 (0.090933 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 15:27:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 15:27:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/27 15:27:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.57s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/27 15:27:14 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.11 seconds.\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.27 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[09/27 15:27:16 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 15:27:16 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[09/27 15:27:17 d2.utils.events]: \u001b[0m eta: 2:54:06  iter: 5999  total_loss: 0.5903  loss_cls: 0.303  loss_box_reg: 0.2297  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.01989  time: 1.1289  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:27:28 d2.utils.events]: \u001b[0m eta: 2:53:11  iter: 6019  total_loss: 0.5686  loss_cls: 0.2768  loss_box_reg: 0.2406  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.01587  time: 1.1270  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:27:39 d2.utils.events]: \u001b[0m eta: 2:49:50  iter: 6039  total_loss: 0.6758  loss_cls: 0.3528  loss_box_reg: 0.2294  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.02293  time: 1.1251  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:27:50 d2.utils.events]: \u001b[0m eta: 2:38:44  iter: 6059  total_loss: 0.5665  loss_cls: 0.2798  loss_box_reg: 0.2383  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.01951  time: 1.1232  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:28:01 d2.utils.events]: \u001b[0m eta: 2:38:04  iter: 6079  total_loss: 0.7112  loss_cls: 0.3743  loss_box_reg: 0.2579  loss_rpn_cls: 0.0165  loss_rpn_loc: 0.0264  time: 1.1213  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:28:12 d2.utils.events]: \u001b[0m eta: 2:37:28  iter: 6099  total_loss: 0.6428  loss_cls: 0.3303  loss_box_reg: 0.2695  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.02649  time: 1.1195  data_time: 0.0130  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:28:23 d2.utils.events]: \u001b[0m eta: 2:36:59  iter: 6119  total_loss: 0.5282  loss_cls: 0.3199  loss_box_reg: 0.187  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.01622  time: 1.1176  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:28:34 d2.utils.events]: \u001b[0m eta: 2:36:32  iter: 6139  total_loss: 0.5747  loss_cls: 0.309  loss_box_reg: 0.2477  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.03074  time: 1.1158  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:28:45 d2.utils.events]: \u001b[0m eta: 2:36:06  iter: 6159  total_loss: 0.6386  loss_cls: 0.2963  loss_box_reg: 0.2663  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.02458  time: 1.1139  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:28:56 d2.utils.events]: \u001b[0m eta: 2:35:42  iter: 6179  total_loss: 0.5801  loss_cls: 0.3455  loss_box_reg: 0.2196  loss_rpn_cls: 0.009664  loss_rpn_loc: 0.0229  time: 1.1121  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:29:07 d2.utils.events]: \u001b[0m eta: 2:35:17  iter: 6199  total_loss: 0.6383  loss_cls: 0.3193  loss_box_reg: 0.2298  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.02003  time: 1.1103  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:29:18 d2.utils.events]: \u001b[0m eta: 2:34:53  iter: 6219  total_loss: 0.5887  loss_cls: 0.2918  loss_box_reg: 0.2328  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.01698  time: 1.1085  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:29:29 d2.utils.events]: \u001b[0m eta: 2:34:28  iter: 6239  total_loss: 0.6192  loss_cls: 0.2934  loss_box_reg: 0.2703  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.0184  time: 1.1067  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:29:40 d2.utils.events]: \u001b[0m eta: 2:34:05  iter: 6259  total_loss: 0.5906  loss_cls: 0.3146  loss_box_reg: 0.249  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.02232  time: 1.1050  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:29:51 d2.utils.events]: \u001b[0m eta: 2:33:42  iter: 6279  total_loss: 0.6081  loss_cls: 0.3675  loss_box_reg: 0.2331  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.01398  time: 1.1032  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:30:02 d2.utils.events]: \u001b[0m eta: 2:33:17  iter: 6299  total_loss: 0.6277  loss_cls: 0.3503  loss_box_reg: 0.2307  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.01625  time: 1.1014  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:30:13 d2.utils.events]: \u001b[0m eta: 2:32:50  iter: 6319  total_loss: 0.7062  loss_cls: 0.3449  loss_box_reg: 0.3101  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.03128  time: 1.0997  data_time: 0.0119  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:30:24 d2.utils.events]: \u001b[0m eta: 2:32:25  iter: 6339  total_loss: 0.6097  loss_cls: 0.3357  loss_box_reg: 0.256  loss_rpn_cls: 0.02344  loss_rpn_loc: 0.0364  time: 1.0980  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:30:36 d2.utils.events]: \u001b[0m eta: 2:31:58  iter: 6359  total_loss: 0.514  loss_cls: 0.3068  loss_box_reg: 0.1715  loss_rpn_cls: 0.009271  loss_rpn_loc: 0.01223  time: 1.0963  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:30:47 d2.utils.events]: \u001b[0m eta: 2:31:32  iter: 6379  total_loss: 0.5755  loss_cls: 0.3136  loss_box_reg: 0.216  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.01942  time: 1.0945  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:30:58 d2.utils.events]: \u001b[0m eta: 2:31:04  iter: 6399  total_loss: 0.5509  loss_cls: 0.3004  loss_box_reg: 0.2481  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.01688  time: 1.0928  data_time: 0.0140  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:31:09 d2.utils.events]: \u001b[0m eta: 2:30:29  iter: 6419  total_loss: 0.4444  loss_cls: 0.2445  loss_box_reg: 0.1757  loss_rpn_cls: 0.005008  loss_rpn_loc: 0.01116  time: 1.0912  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:31:20 d2.utils.events]: \u001b[0m eta: 2:29:48  iter: 6439  total_loss: 0.5104  loss_cls: 0.305  loss_box_reg: 0.2135  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.01485  time: 1.0895  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:31:31 d2.utils.events]: \u001b[0m eta: 2:29:04  iter: 6459  total_loss: 0.626  loss_cls: 0.3442  loss_box_reg: 0.1983  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.02164  time: 1.0878  data_time: 0.0129  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:31:42 d2.utils.events]: \u001b[0m eta: 2:21:36  iter: 6479  total_loss: 0.6321  loss_cls: 0.352  loss_box_reg: 0.2538  loss_rpn_cls: 0.01688  loss_rpn_loc: 0.03753  time: 1.0862  data_time: 0.0138  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:31:53 d2.utils.events]: \u001b[0m eta: 1:23:26  iter: 6499  total_loss: 0.6031  loss_cls: 0.3484  loss_box_reg: 0.2332  loss_rpn_cls: 0.02229  loss_rpn_loc: 0.02327  time: 1.0845  data_time: 0.0140  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:32:04 d2.utils.events]: \u001b[0m eta: 1:19:26  iter: 6519  total_loss: 0.5796  loss_cls: 0.3196  loss_box_reg: 0.2418  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.02081  time: 1.0829  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:32:15 d2.utils.events]: \u001b[0m eta: 1:18:54  iter: 6539  total_loss: 0.5558  loss_cls: 0.2811  loss_box_reg: 0.248  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.02171  time: 1.0813  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:32:26 d2.utils.events]: \u001b[0m eta: 1:18:34  iter: 6559  total_loss: 0.4766  loss_cls: 0.2442  loss_box_reg: 0.202  loss_rpn_cls: 0.008655  loss_rpn_loc: 0.01883  time: 1.0797  data_time: 0.0137  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:32:37 d2.utils.events]: \u001b[0m eta: 1:18:14  iter: 6579  total_loss: 0.6175  loss_cls: 0.35  loss_box_reg: 0.2264  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.02365  time: 1.0781  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:32:48 d2.utils.events]: \u001b[0m eta: 1:17:56  iter: 6599  total_loss: 0.6636  loss_cls: 0.3395  loss_box_reg: 0.2483  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.0218  time: 1.0765  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:32:59 d2.utils.events]: \u001b[0m eta: 1:17:37  iter: 6619  total_loss: 0.6205  loss_cls: 0.334  loss_box_reg: 0.2102  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.01638  time: 1.0749  data_time: 0.0132  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:33:10 d2.utils.events]: \u001b[0m eta: 1:17:21  iter: 6639  total_loss: 0.5858  loss_cls: 0.2866  loss_box_reg: 0.2083  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.01771  time: 1.0733  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:33:21 d2.utils.events]: \u001b[0m eta: 1:17:07  iter: 6659  total_loss: 0.6604  loss_cls: 0.3235  loss_box_reg: 0.3037  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.02629  time: 1.0717  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:33:32 d2.utils.events]: \u001b[0m eta: 1:16:52  iter: 6679  total_loss: 0.6114  loss_cls: 0.3353  loss_box_reg: 0.2148  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.02377  time: 1.0702  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:33:44 d2.utils.events]: \u001b[0m eta: 1:16:38  iter: 6699  total_loss: 0.759  loss_cls: 0.3816  loss_box_reg: 0.3051  loss_rpn_cls: 0.02781  loss_rpn_loc: 0.04684  time: 1.0687  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:33:55 d2.utils.events]: \u001b[0m eta: 1:16:24  iter: 6719  total_loss: 0.5446  loss_cls: 0.317  loss_box_reg: 0.1929  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.02186  time: 1.0671  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:34:06 d2.utils.events]: \u001b[0m eta: 1:16:10  iter: 6739  total_loss: 0.4969  loss_cls: 0.284  loss_box_reg: 0.2085  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.0188  time: 1.0656  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:34:17 d2.utils.events]: \u001b[0m eta: 1:15:56  iter: 6759  total_loss: 0.5742  loss_cls: 0.3  loss_box_reg: 0.2439  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.02404  time: 1.0641  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:34:28 d2.utils.events]: \u001b[0m eta: 1:15:44  iter: 6779  total_loss: 0.6655  loss_cls: 0.3229  loss_box_reg: 0.259  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.0228  time: 1.0625  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:34:39 d2.utils.events]: \u001b[0m eta: 1:15:30  iter: 6799  total_loss: 0.6723  loss_cls: 0.3763  loss_box_reg: 0.272  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.03454  time: 1.0610  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:34:50 d2.utils.events]: \u001b[0m eta: 1:15:16  iter: 6819  total_loss: 0.6385  loss_cls: 0.314  loss_box_reg: 0.2503  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.03983  time: 1.0595  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:35:01 d2.utils.events]: \u001b[0m eta: 1:15:04  iter: 6839  total_loss: 0.7515  loss_cls: 0.3286  loss_box_reg: 0.294  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.02981  time: 1.0581  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:35:12 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 6859  total_loss: 0.5667  loss_cls: 0.3083  loss_box_reg: 0.2008  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01514  time: 1.0566  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:35:23 d2.utils.events]: \u001b[0m eta: 1:14:39  iter: 6879  total_loss: 0.6545  loss_cls: 0.3751  loss_box_reg: 0.266  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.01571  time: 1.0551  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:35:34 d2.utils.events]: \u001b[0m eta: 1:14:26  iter: 6899  total_loss: 0.6171  loss_cls: 0.3356  loss_box_reg: 0.2311  loss_rpn_cls: 0.02139  loss_rpn_loc: 0.02484  time: 1.0537  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:35:45 d2.utils.events]: \u001b[0m eta: 1:14:14  iter: 6919  total_loss: 0.6897  loss_cls: 0.3231  loss_box_reg: 0.3061  loss_rpn_cls: 0.01595  loss_rpn_loc: 0.02711  time: 1.0522  data_time: 0.0144  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:35:56 d2.utils.events]: \u001b[0m eta: 1:14:01  iter: 6939  total_loss: 0.5803  loss_cls: 0.3135  loss_box_reg: 0.2228  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.02303  time: 1.0508  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:36:07 d2.utils.events]: \u001b[0m eta: 1:13:49  iter: 6959  total_loss: 0.668  loss_cls: 0.3679  loss_box_reg: 0.2257  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.03216  time: 1.0493  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:36:18 d2.utils.events]: \u001b[0m eta: 1:13:36  iter: 6979  total_loss: 0.624  loss_cls: 0.3038  loss_box_reg: 0.253  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.03608  time: 1.0479  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:36:29 d2.utils.events]: \u001b[0m eta: 1:13:24  iter: 6999  total_loss: 0.6331  loss_cls: 0.3081  loss_box_reg: 0.2687  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.02781  time: 1.0465  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:36:40 d2.utils.events]: \u001b[0m eta: 1:13:13  iter: 7019  total_loss: 0.4731  loss_cls: 0.2684  loss_box_reg: 0.1931  loss_rpn_cls: 0.006081  loss_rpn_loc: 0.009508  time: 1.0451  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:36:51 d2.utils.events]: \u001b[0m eta: 1:13:02  iter: 7039  total_loss: 0.5348  loss_cls: 0.301  loss_box_reg: 0.2099  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.02071  time: 1.0437  data_time: 0.0118  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:37:02 d2.utils.events]: \u001b[0m eta: 1:12:51  iter: 7059  total_loss: 0.5107  loss_cls: 0.2751  loss_box_reg: 0.2099  loss_rpn_cls: 0.009546  loss_rpn_loc: 0.01476  time: 1.0423  data_time: 0.0119  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:37:13 d2.utils.events]: \u001b[0m eta: 1:12:40  iter: 7079  total_loss: 0.557  loss_cls: 0.278  loss_box_reg: 0.2292  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.02149  time: 1.0409  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:37:24 d2.utils.events]: \u001b[0m eta: 1:12:29  iter: 7099  total_loss: 0.5897  loss_cls: 0.2686  loss_box_reg: 0.2236  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.02285  time: 1.0395  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:37:35 d2.utils.events]: \u001b[0m eta: 1:12:18  iter: 7119  total_loss: 0.6188  loss_cls: 0.346  loss_box_reg: 0.2156  loss_rpn_cls: 0.01839  loss_rpn_loc: 0.02839  time: 1.0381  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:37:46 d2.utils.events]: \u001b[0m eta: 1:12:07  iter: 7139  total_loss: 0.669  loss_cls: 0.3393  loss_box_reg: 0.2608  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.01737  time: 1.0367  data_time: 0.0132  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:37:57 d2.utils.events]: \u001b[0m eta: 1:11:56  iter: 7159  total_loss: 0.7333  loss_cls: 0.3608  loss_box_reg: 0.2792  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.02912  time: 1.0354  data_time: 0.0118  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:38:08 d2.utils.events]: \u001b[0m eta: 1:11:45  iter: 7179  total_loss: 0.6774  loss_cls: 0.3082  loss_box_reg: 0.2502  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.03943  time: 1.0340  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:38:20 d2.utils.events]: \u001b[0m eta: 1:11:34  iter: 7199  total_loss: 0.6458  loss_cls: 0.3035  loss_box_reg: 0.2483  loss_rpn_cls: 0.01634  loss_rpn_loc: 0.03666  time: 1.0327  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:38:31 d2.utils.events]: \u001b[0m eta: 1:11:22  iter: 7219  total_loss: 0.617  loss_cls: 0.318  loss_box_reg: 0.2662  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.01665  time: 1.0314  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:38:42 d2.utils.events]: \u001b[0m eta: 1:11:11  iter: 7239  total_loss: 0.6  loss_cls: 0.3241  loss_box_reg: 0.2104  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.0134  time: 1.0300  data_time: 0.0117  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:38:53 d2.utils.events]: \u001b[0m eta: 1:10:59  iter: 7259  total_loss: 0.6124  loss_cls: 0.3121  loss_box_reg: 0.202  loss_rpn_cls: 0.01498  loss_rpn_loc: 0.02071  time: 1.0287  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:39:04 d2.utils.events]: \u001b[0m eta: 1:10:48  iter: 7279  total_loss: 0.6649  loss_cls: 0.3564  loss_box_reg: 0.2323  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.0291  time: 1.0274  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:39:15 d2.utils.events]: \u001b[0m eta: 1:10:37  iter: 7299  total_loss: 0.6054  loss_cls: 0.3212  loss_box_reg: 0.2375  loss_rpn_cls: 0.01804  loss_rpn_loc: 0.02986  time: 1.0261  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:39:26 d2.utils.events]: \u001b[0m eta: 1:10:26  iter: 7319  total_loss: 0.5427  loss_cls: 0.2877  loss_box_reg: 0.2214  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.01681  time: 1.0248  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:39:37 d2.utils.events]: \u001b[0m eta: 1:10:15  iter: 7339  total_loss: 0.4916  loss_cls: 0.2891  loss_box_reg: 0.1858  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.01783  time: 1.0235  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:39:48 d2.utils.events]: \u001b[0m eta: 1:10:04  iter: 7359  total_loss: 0.6335  loss_cls: 0.3142  loss_box_reg: 0.2682  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.02856  time: 1.0222  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:39:59 d2.utils.events]: \u001b[0m eta: 1:09:53  iter: 7379  total_loss: 0.5503  loss_cls: 0.2893  loss_box_reg: 0.2217  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.03136  time: 1.0209  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:40:10 d2.utils.events]: \u001b[0m eta: 1:09:42  iter: 7399  total_loss: 0.6182  loss_cls: 0.291  loss_box_reg: 0.2426  loss_rpn_cls: 0.01858  loss_rpn_loc: 0.02427  time: 1.0197  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:40:21 d2.utils.events]: \u001b[0m eta: 1:09:31  iter: 7419  total_loss: 0.527  loss_cls: 0.2644  loss_box_reg: 0.1958  loss_rpn_cls: 0.01024  loss_rpn_loc: 0.0247  time: 1.0184  data_time: 0.0154  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:40:32 d2.utils.events]: \u001b[0m eta: 1:09:20  iter: 7439  total_loss: 0.5781  loss_cls: 0.3184  loss_box_reg: 0.2027  loss_rpn_cls: 0.02069  loss_rpn_loc: 0.02324  time: 1.0172  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:40:43 d2.utils.events]: \u001b[0m eta: 1:09:09  iter: 7459  total_loss: 0.4952  loss_cls: 0.2908  loss_box_reg: 0.1676  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.02166  time: 1.0159  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:40:54 d2.utils.events]: \u001b[0m eta: 1:08:57  iter: 7479  total_loss: 0.626  loss_cls: 0.338  loss_box_reg: 0.2459  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.01666  time: 1.0147  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:41:05 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 7499  total_loss: 0.5682  loss_cls: 0.2809  loss_box_reg: 0.2209  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.03615  time: 1.0134  data_time: 0.0123  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:41:16 d2.utils.events]: \u001b[0m eta: 1:08:35  iter: 7519  total_loss: 0.5682  loss_cls: 0.3013  loss_box_reg: 0.23  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.01319  time: 1.0122  data_time: 0.0128  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:41:27 d2.utils.events]: \u001b[0m eta: 1:08:24  iter: 7539  total_loss: 0.7028  loss_cls: 0.3525  loss_box_reg: 0.287  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.0262  time: 1.0110  data_time: 0.0136  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:41:38 d2.utils.events]: \u001b[0m eta: 1:08:13  iter: 7559  total_loss: 0.5622  loss_cls: 0.2922  loss_box_reg: 0.2498  loss_rpn_cls: 0.009796  loss_rpn_loc: 0.016  time: 1.0098  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:41:49 d2.utils.events]: \u001b[0m eta: 1:08:01  iter: 7579  total_loss: 0.624  loss_cls: 0.3032  loss_box_reg: 0.2374  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.02171  time: 1.0086  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:42:00 d2.utils.events]: \u001b[0m eta: 1:07:49  iter: 7599  total_loss: 0.4972  loss_cls: 0.2561  loss_box_reg: 0.1999  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.01555  time: 1.0074  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:42:11 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 7619  total_loss: 0.5917  loss_cls: 0.326  loss_box_reg: 0.228  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.02202  time: 1.0061  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:42:22 d2.utils.events]: \u001b[0m eta: 1:07:27  iter: 7639  total_loss: 0.4921  loss_cls: 0.2748  loss_box_reg: 0.1927  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.02089  time: 1.0050  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:42:33 d2.utils.events]: \u001b[0m eta: 1:07:16  iter: 7659  total_loss: 0.552  loss_cls: 0.2811  loss_box_reg: 0.2277  loss_rpn_cls: 0.009251  loss_rpn_loc: 0.02254  time: 1.0038  data_time: 0.0134  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:42:44 d2.utils.events]: \u001b[0m eta: 1:07:06  iter: 7679  total_loss: 0.5058  loss_cls: 0.2389  loss_box_reg: 0.1877  loss_rpn_cls: 0.008944  loss_rpn_loc: 0.02362  time: 1.0026  data_time: 0.0137  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:42:55 d2.utils.events]: \u001b[0m eta: 1:06:54  iter: 7699  total_loss: 0.6779  loss_cls: 0.372  loss_box_reg: 0.2435  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.02096  time: 1.0014  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:43:07 d2.utils.events]: \u001b[0m eta: 1:06:44  iter: 7719  total_loss: 0.546  loss_cls: 0.3167  loss_box_reg: 0.1967  loss_rpn_cls: 0.006449  loss_rpn_loc: 0.01405  time: 1.0003  data_time: 0.0140  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:43:18 d2.utils.events]: \u001b[0m eta: 1:06:33  iter: 7739  total_loss: 0.5399  loss_cls: 0.3133  loss_box_reg: 0.2379  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.01534  time: 0.9991  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:43:29 d2.utils.events]: \u001b[0m eta: 1:06:22  iter: 7759  total_loss: 0.5359  loss_cls: 0.274  loss_box_reg: 0.2141  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.01767  time: 0.9979  data_time: 0.0126  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:43:40 d2.utils.events]: \u001b[0m eta: 1:06:11  iter: 7779  total_loss: 0.4705  loss_cls: 0.2344  loss_box_reg: 0.1948  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.01402  time: 0.9968  data_time: 0.0131  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:43:51 d2.utils.events]: \u001b[0m eta: 1:06:00  iter: 7799  total_loss: 0.6751  loss_cls: 0.3078  loss_box_reg: 0.263  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.02405  time: 0.9957  data_time: 0.0122  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:44:02 d2.utils.events]: \u001b[0m eta: 1:05:49  iter: 7819  total_loss: 0.6166  loss_cls: 0.3201  loss_box_reg: 0.2509  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.02776  time: 0.9945  data_time: 0.0120  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:44:13 d2.utils.events]: \u001b[0m eta: 1:05:38  iter: 7839  total_loss: 0.5111  loss_cls: 0.2756  loss_box_reg: 0.2095  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.0138  time: 0.9934  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:44:24 d2.utils.events]: \u001b[0m eta: 1:05:27  iter: 7859  total_loss: 0.5637  loss_cls: 0.3393  loss_box_reg: 0.2223  loss_rpn_cls: 0.01058  loss_rpn_loc: 0.009913  time: 0.9922  data_time: 0.0127  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:44:35 d2.utils.events]: \u001b[0m eta: 1:05:15  iter: 7879  total_loss: 0.5283  loss_cls: 0.3095  loss_box_reg: 0.1818  loss_rpn_cls: 0.008908  loss_rpn_loc: 0.01924  time: 0.9911  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:44:46 d2.utils.events]: \u001b[0m eta: 1:05:04  iter: 7899  total_loss: 0.5668  loss_cls: 0.2903  loss_box_reg: 0.2341  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.02106  time: 0.9900  data_time: 0.0135  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:44:57 d2.utils.events]: \u001b[0m eta: 1:04:53  iter: 7919  total_loss: 0.5166  loss_cls: 0.279  loss_box_reg: 0.2307  loss_rpn_cls: 0.01369  loss_rpn_loc: 0.01633  time: 0.9889  data_time: 0.0133  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:45:08 d2.utils.events]: \u001b[0m eta: 1:04:41  iter: 7939  total_loss: 0.6374  loss_cls: 0.3165  loss_box_reg: 0.252  loss_rpn_cls: 0.01975  loss_rpn_loc: 0.0322  time: 0.9878  data_time: 0.0124  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:45:19 d2.utils.events]: \u001b[0m eta: 1:04:31  iter: 7959  total_loss: 0.5429  loss_cls: 0.3072  loss_box_reg: 0.211  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.01749  time: 0.9867  data_time: 0.0132  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:45:30 d2.utils.events]: \u001b[0m eta: 1:04:20  iter: 7979  total_loss: 0.6851  loss_cls: 0.332  loss_box_reg: 0.2969  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.03427  time: 0.9856  data_time: 0.0125  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:45:41 d2.utils.events]: \u001b[0m eta: 1:04:09  iter: 7999  total_loss: 0.664  loss_cls: 0.3289  loss_box_reg: 0.2662  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.02949  time: 0.9845  data_time: 0.0121  lr: 0.001  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:45:52 d2.utils.events]: \u001b[0m eta: 1:03:58  iter: 8019  total_loss: 0.7258  loss_cls: 0.3404  loss_box_reg: 0.2948  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.03081  time: 0.9834  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:46:03 d2.utils.events]: \u001b[0m eta: 1:03:47  iter: 8039  total_loss: 0.5242  loss_cls: 0.2687  loss_box_reg: 0.2376  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.01752  time: 0.9824  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:46:14 d2.utils.events]: \u001b[0m eta: 1:03:36  iter: 8059  total_loss: 0.5558  loss_cls: 0.2689  loss_box_reg: 0.2414  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.01406  time: 0.9813  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:46:25 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 8079  total_loss: 0.5685  loss_cls: 0.3078  loss_box_reg: 0.2096  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.03058  time: 0.9802  data_time: 0.0128  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:46:36 d2.utils.events]: \u001b[0m eta: 1:03:15  iter: 8099  total_loss: 0.6469  loss_cls: 0.3064  loss_box_reg: 0.2903  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.03117  time: 0.9792  data_time: 0.0134  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:46:47 d2.utils.events]: \u001b[0m eta: 1:03:04  iter: 8119  total_loss: 0.6801  loss_cls: 0.3287  loss_box_reg: 0.263  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.02422  time: 0.9781  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:46:58 d2.utils.events]: \u001b[0m eta: 1:02:53  iter: 8139  total_loss: 0.5765  loss_cls: 0.325  loss_box_reg: 0.2355  loss_rpn_cls: 0.0152  loss_rpn_loc: 0.03525  time: 0.9771  data_time: 0.0137  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:47:09 d2.utils.events]: \u001b[0m eta: 1:02:43  iter: 8159  total_loss: 0.6483  loss_cls: 0.3074  loss_box_reg: 0.2792  loss_rpn_cls: 0.0194  loss_rpn_loc: 0.01994  time: 0.9760  data_time: 0.0132  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:47:20 d2.utils.events]: \u001b[0m eta: 1:02:32  iter: 8179  total_loss: 0.5762  loss_cls: 0.2803  loss_box_reg: 0.1972  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.0232  time: 0.9750  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:47:32 d2.utils.events]: \u001b[0m eta: 1:02:21  iter: 8199  total_loss: 0.5144  loss_cls: 0.3018  loss_box_reg: 0.2026  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.02418  time: 0.9740  data_time: 0.0135  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:47:43 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 8219  total_loss: 0.7082  loss_cls: 0.3371  loss_box_reg: 0.253  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.02773  time: 0.9730  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:47:54 d2.utils.events]: \u001b[0m eta: 1:01:59  iter: 8239  total_loss: 0.6214  loss_cls: 0.3516  loss_box_reg: 0.2427  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.01787  time: 0.9719  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:48:05 d2.utils.events]: \u001b[0m eta: 1:01:49  iter: 8259  total_loss: 0.592  loss_cls: 0.31  loss_box_reg: 0.2131  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.01366  time: 0.9709  data_time: 0.0134  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:48:16 d2.utils.events]: \u001b[0m eta: 1:01:38  iter: 8279  total_loss: 0.4827  loss_cls: 0.268  loss_box_reg: 0.1878  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.01462  time: 0.9699  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:48:27 d2.utils.events]: \u001b[0m eta: 1:01:27  iter: 8299  total_loss: 0.587  loss_cls: 0.308  loss_box_reg: 0.2412  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.02122  time: 0.9689  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:48:38 d2.utils.events]: \u001b[0m eta: 1:01:16  iter: 8319  total_loss: 0.5958  loss_cls: 0.2926  loss_box_reg: 0.2236  loss_rpn_cls: 0.01482  loss_rpn_loc: 0.02556  time: 0.9679  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:48:49 d2.utils.events]: \u001b[0m eta: 1:01:05  iter: 8339  total_loss: 0.4918  loss_cls: 0.2607  loss_box_reg: 0.189  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.01797  time: 0.9669  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:49:00 d2.utils.events]: \u001b[0m eta: 1:00:54  iter: 8359  total_loss: 0.6096  loss_cls: 0.3251  loss_box_reg: 0.1892  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.01513  time: 0.9659  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:49:11 d2.utils.events]: \u001b[0m eta: 1:00:43  iter: 8379  total_loss: 0.5478  loss_cls: 0.2797  loss_box_reg: 0.2058  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.01438  time: 0.9649  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:49:22 d2.utils.events]: \u001b[0m eta: 1:00:32  iter: 8399  total_loss: 0.5516  loss_cls: 0.2971  loss_box_reg: 0.2103  loss_rpn_cls: 0.01595  loss_rpn_loc: 0.01311  time: 0.9639  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:49:33 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 8419  total_loss: 0.632  loss_cls: 0.3404  loss_box_reg: 0.2629  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.02792  time: 0.9630  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:49:44 d2.utils.events]: \u001b[0m eta: 1:00:11  iter: 8439  total_loss: 0.6028  loss_cls: 0.333  loss_box_reg: 0.23  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.0248  time: 0.9620  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:49:55 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 8459  total_loss: 0.5773  loss_cls: 0.2991  loss_box_reg: 0.2349  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.01739  time: 0.9610  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:50:06 d2.utils.events]: \u001b[0m eta: 0:59:50  iter: 8479  total_loss: 0.5215  loss_cls: 0.2864  loss_box_reg: 0.2492  loss_rpn_cls: 0.01426  loss_rpn_loc: 0.02499  time: 0.9601  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:50:18 d2.utils.events]: \u001b[0m eta: 0:59:39  iter: 8499  total_loss: 0.4772  loss_cls: 0.2587  loss_box_reg: 0.1791  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.01774  time: 0.9591  data_time: 0.0131  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:50:29 d2.utils.events]: \u001b[0m eta: 0:59:28  iter: 8519  total_loss: 0.533  loss_cls: 0.3009  loss_box_reg: 0.2265  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.01429  time: 0.9581  data_time: 0.0136  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:50:40 d2.utils.events]: \u001b[0m eta: 0:59:17  iter: 8539  total_loss: 0.5252  loss_cls: 0.2779  loss_box_reg: 0.1995  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.01842  time: 0.9572  data_time: 0.0132  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:50:51 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 8559  total_loss: 0.4393  loss_cls: 0.2496  loss_box_reg: 0.2037  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.01461  time: 0.9562  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:51:02 d2.utils.events]: \u001b[0m eta: 0:58:55  iter: 8579  total_loss: 0.6059  loss_cls: 0.2823  loss_box_reg: 0.2754  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.01844  time: 0.9553  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:51:13 d2.utils.events]: \u001b[0m eta: 0:58:44  iter: 8599  total_loss: 0.5545  loss_cls: 0.2457  loss_box_reg: 0.2345  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.03047  time: 0.9544  data_time: 0.0139  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:51:24 d2.utils.events]: \u001b[0m eta: 0:58:34  iter: 8619  total_loss: 0.5703  loss_cls: 0.2668  loss_box_reg: 0.2327  loss_rpn_cls: 0.014  loss_rpn_loc: 0.02206  time: 0.9534  data_time: 0.0135  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:51:35 d2.utils.events]: \u001b[0m eta: 0:58:24  iter: 8639  total_loss: 0.5316  loss_cls: 0.248  loss_box_reg: 0.2282  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.01686  time: 0.9525  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:51:46 d2.utils.events]: \u001b[0m eta: 0:58:13  iter: 8659  total_loss: 0.5921  loss_cls: 0.3156  loss_box_reg: 0.2549  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.0356  time: 0.9516  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:51:57 d2.utils.events]: \u001b[0m eta: 0:58:02  iter: 8679  total_loss: 0.5613  loss_cls: 0.3207  loss_box_reg: 0.251  loss_rpn_cls: 0.01345  loss_rpn_loc: 0.0199  time: 0.9507  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:52:08 d2.utils.events]: \u001b[0m eta: 0:57:51  iter: 8699  total_loss: 0.609  loss_cls: 0.2907  loss_box_reg: 0.2227  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.03322  time: 0.9497  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:52:19 d2.utils.events]: \u001b[0m eta: 0:57:40  iter: 8719  total_loss: 0.4607  loss_cls: 0.2195  loss_box_reg: 0.202  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.02434  time: 0.9488  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:52:30 d2.utils.events]: \u001b[0m eta: 0:57:29  iter: 8739  total_loss: 0.4796  loss_cls: 0.2517  loss_box_reg: 0.1912  loss_rpn_cls: 0.00853  loss_rpn_loc: 0.01783  time: 0.9479  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:52:41 d2.utils.events]: \u001b[0m eta: 0:57:19  iter: 8759  total_loss: 0.4615  loss_cls: 0.2349  loss_box_reg: 0.1812  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.01153  time: 0.9470  data_time: 0.0133  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:52:52 d2.utils.events]: \u001b[0m eta: 0:57:07  iter: 8779  total_loss: 0.4455  loss_cls: 0.2256  loss_box_reg: 0.1846  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.01881  time: 0.9461  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:53:03 d2.utils.events]: \u001b[0m eta: 0:56:57  iter: 8799  total_loss: 0.558  loss_cls: 0.288  loss_box_reg: 0.1825  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.01892  time: 0.9452  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:53:14 d2.utils.events]: \u001b[0m eta: 0:56:46  iter: 8819  total_loss: 0.4976  loss_cls: 0.2991  loss_box_reg: 0.1885  loss_rpn_cls: 0.008867  loss_rpn_loc: 0.0144  time: 0.9443  data_time: 0.0131  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:53:25 d2.utils.events]: \u001b[0m eta: 0:56:35  iter: 8839  total_loss: 0.4672  loss_cls: 0.2509  loss_box_reg: 0.1965  loss_rpn_cls: 0.009693  loss_rpn_loc: 0.01348  time: 0.9434  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:53:36 d2.utils.events]: \u001b[0m eta: 0:56:24  iter: 8859  total_loss: 0.5345  loss_cls: 0.2643  loss_box_reg: 0.2134  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.02114  time: 0.9426  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:53:47 d2.utils.events]: \u001b[0m eta: 0:56:13  iter: 8879  total_loss: 0.5555  loss_cls: 0.2602  loss_box_reg: 0.2343  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.01861  time: 0.9417  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:53:58 d2.utils.events]: \u001b[0m eta: 0:56:02  iter: 8899  total_loss: 0.5404  loss_cls: 0.2698  loss_box_reg: 0.2384  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01787  time: 0.9408  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:54:09 d2.utils.events]: \u001b[0m eta: 0:55:50  iter: 8919  total_loss: 0.5939  loss_cls: 0.2968  loss_box_reg: 0.2397  loss_rpn_cls: 0.01874  loss_rpn_loc: 0.02293  time: 0.9399  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:54:21 d2.utils.events]: \u001b[0m eta: 0:55:39  iter: 8939  total_loss: 0.55  loss_cls: 0.2791  loss_box_reg: 0.2355  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.02207  time: 0.9390  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:54:32 d2.utils.events]: \u001b[0m eta: 0:55:28  iter: 8959  total_loss: 0.5549  loss_cls: 0.2985  loss_box_reg: 0.2319  loss_rpn_cls: 0.009665  loss_rpn_loc: 0.01626  time: 0.9382  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:54:43 d2.utils.events]: \u001b[0m eta: 0:55:17  iter: 8979  total_loss: 0.5918  loss_cls: 0.2952  loss_box_reg: 0.279  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.02754  time: 0.9373  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:54:54 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/test.json\n",
      "\u001b[32m[09/27 15:54:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 15:54:54 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 15:54:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.50 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/27 15:54:54 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/27 15:54:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/27 15:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0007 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0456 s/iter. ETA=0:03:41\n",
      "\u001b[32m[09/27 15:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 117/4871. Dataloading: 0.0012 s/iter. Inference: 0.0459 s/iter. Eval: 0.0003 s/iter. Total: 0.0474 s/iter. ETA=0:03:45\n",
      "\u001b[32m[09/27 15:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 226/4871. Dataloading: 0.0012 s/iter. Inference: 0.0453 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:03:37\n",
      "\u001b[32m[09/27 15:55:10 d2.evaluation.evaluator]: \u001b[0mInference done 336/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:03:30\n",
      "\u001b[32m[09/27 15:55:15 d2.evaluation.evaluator]: \u001b[0mInference done 446/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:03:24\n",
      "\u001b[32m[09/27 15:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 556/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:03:19\n",
      "\u001b[32m[09/27 15:55:25 d2.evaluation.evaluator]: \u001b[0mInference done 665/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:03:14\n",
      "\u001b[32m[09/27 15:55:30 d2.evaluation.evaluator]: \u001b[0mInference done 774/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:03:09\n",
      "\u001b[32m[09/27 15:55:35 d2.evaluation.evaluator]: \u001b[0mInference done 882/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:03:04\n",
      "\u001b[32m[09/27 15:55:40 d2.evaluation.evaluator]: \u001b[0mInference done 991/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:02:59\n",
      "\u001b[32m[09/27 15:55:45 d2.evaluation.evaluator]: \u001b[0mInference done 1100/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:02:54\n",
      "\u001b[32m[09/27 15:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 1209/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:02:49\n",
      "\u001b[32m[09/27 15:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 1318/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:02:43\n",
      "\u001b[32m[09/27 15:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 1427/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:02:38\n",
      "\u001b[32m[09/27 15:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 1536/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:02:33\n",
      "\u001b[32m[09/27 15:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 1636/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/27 15:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 1742/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/27 15:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 1851/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:02:20\n",
      "\u001b[32m[09/27 15:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 1959/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:02:15\n",
      "\u001b[32m[09/27 15:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 2068/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/27 15:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 2173/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:02:05\n",
      "\u001b[32m[09/27 15:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 2281/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:02:00\n",
      "\u001b[32m[09/27 15:56:46 d2.evaluation.evaluator]: \u001b[0mInference done 2390/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0465 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/27 15:56:51 d2.evaluation.evaluator]: \u001b[0mInference done 2499/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:50\n",
      "\u001b[32m[09/27 15:56:56 d2.evaluation.evaluator]: \u001b[0mInference done 2609/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:44\n",
      "\u001b[32m[09/27 15:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 2719/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:39\n",
      "\u001b[32m[09/27 15:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 2828/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:34\n",
      "\u001b[32m[09/27 15:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 2935/4871. Dataloading: 0.0012 s/iter. Inference: 0.0449 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:29\n",
      "\u001b[32m[09/27 15:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 3044/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:01:24\n",
      "\u001b[32m[09/27 15:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 3154/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:01:19\n",
      "\u001b[32m[09/27 15:57:26 d2.evaluation.evaluator]: \u001b[0mInference done 3264/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:01:14\n",
      "\u001b[32m[09/27 15:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 3371/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:01:09\n",
      "\u001b[32m[09/27 15:57:36 d2.evaluation.evaluator]: \u001b[0mInference done 3481/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:01:04\n",
      "\u001b[32m[09/27 15:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 3591/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:00:59\n",
      "\u001b[32m[09/27 15:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 3701/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/27 15:57:51 d2.evaluation.evaluator]: \u001b[0mInference done 3812/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:00:48\n",
      "\u001b[32m[09/27 15:57:56 d2.evaluation.evaluator]: \u001b[0mInference done 3923/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/27 15:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 4034/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/27 15:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 4144/4871. Dataloading: 0.0012 s/iter. Inference: 0.0447 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/27 15:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 4255/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/27 15:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 4365/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/27 15:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 4475/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:00:18\n",
      "\u001b[32m[09/27 15:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 4585/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/27 15:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 4695/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:00:08\n",
      "\u001b[32m[09/27 15:58:36 d2.evaluation.evaluator]: \u001b[0mInference done 4807/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/27 15:58:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:44.308921 (0.046097 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 15:58:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:36 (0.044578 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 15:58:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 15:58:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/27 15:58:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.59s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/27 15:58:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/27 15:58:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.06 seconds.\n",
      "\u001b[32m[09/27 15:58:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/27 15:58:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.25 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[09/27 15:58:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[09/27 15:58:44 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 15:58:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[09/27 15:58:44 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/27 15:58:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 15:58:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 15:58:44 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[09/27 15:58:44 d2.utils.events]: \u001b[0m eta: 0:55:06  iter: 8999  total_loss: 0.4932  loss_cls: 0.2767  loss_box_reg: 0.2285  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.01794  time: 0.9365  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:58:55 d2.utils.events]: \u001b[0m eta: 0:54:55  iter: 9019  total_loss: 0.4535  loss_cls: 0.2675  loss_box_reg: 0.187  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.0172  time: 0.9356  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:59:06 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 9039  total_loss: 0.4902  loss_cls: 0.2326  loss_box_reg: 0.2021  loss_rpn_cls: 0.008718  loss_rpn_loc: 0.02009  time: 0.9347  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:59:17 d2.utils.events]: \u001b[0m eta: 0:54:33  iter: 9059  total_loss: 0.5765  loss_cls: 0.2993  loss_box_reg: 0.2085  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.0451  time: 0.9339  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:59:28 d2.utils.events]: \u001b[0m eta: 0:54:22  iter: 9079  total_loss: 0.5744  loss_cls: 0.2972  loss_box_reg: 0.2228  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.02064  time: 0.9330  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:59:39 d2.utils.events]: \u001b[0m eta: 0:54:10  iter: 9099  total_loss: 0.449  loss_cls: 0.265  loss_box_reg: 0.1586  loss_rpn_cls: 0.008486  loss_rpn_loc: 0.01865  time: 0.9322  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 15:59:50 d2.utils.events]: \u001b[0m eta: 0:53:59  iter: 9119  total_loss: 0.6064  loss_cls: 0.2977  loss_box_reg: 0.2332  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.02253  time: 0.9314  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:00:01 d2.utils.events]: \u001b[0m eta: 0:53:48  iter: 9139  total_loss: 0.4745  loss_cls: 0.2624  loss_box_reg: 0.1657  loss_rpn_cls: 0.009712  loss_rpn_loc: 0.01959  time: 0.9305  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:00:12 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 9159  total_loss: 0.632  loss_cls: 0.3078  loss_box_reg: 0.2573  loss_rpn_cls: 0.01066  loss_rpn_loc: 0.02398  time: 0.9297  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:00:23 d2.utils.events]: \u001b[0m eta: 0:53:25  iter: 9179  total_loss: 0.6494  loss_cls: 0.3238  loss_box_reg: 0.2242  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.031  time: 0.9289  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:00:34 d2.utils.events]: \u001b[0m eta: 0:53:13  iter: 9199  total_loss: 0.482  loss_cls: 0.2616  loss_box_reg: 0.1766  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.01262  time: 0.9281  data_time: 0.0133  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:00:45 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 9219  total_loss: 0.552  loss_cls: 0.2722  loss_box_reg: 0.2316  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.01797  time: 0.9272  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:00:56 d2.utils.events]: \u001b[0m eta: 0:52:51  iter: 9239  total_loss: 0.5742  loss_cls: 0.307  loss_box_reg: 0.2268  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.02142  time: 0.9264  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:01:07 d2.utils.events]: \u001b[0m eta: 0:52:40  iter: 9259  total_loss: 0.406  loss_cls: 0.2244  loss_box_reg: 0.1654  loss_rpn_cls: 0.009457  loss_rpn_loc: 0.0133  time: 0.9256  data_time: 0.0128  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:01:18 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 9279  total_loss: 0.6362  loss_cls: 0.3082  loss_box_reg: 0.2313  loss_rpn_cls: 0.01857  loss_rpn_loc: 0.0259  time: 0.9248  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:01:29 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 9299  total_loss: 0.5455  loss_cls: 0.2498  loss_box_reg: 0.2059  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.01933  time: 0.9240  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:01:41 d2.utils.events]: \u001b[0m eta: 0:52:07  iter: 9319  total_loss: 0.5469  loss_cls: 0.2798  loss_box_reg: 0.2366  loss_rpn_cls: 0.0147  loss_rpn_loc: 0.01607  time: 0.9232  data_time: 0.0137  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:01:52 d2.utils.events]: \u001b[0m eta: 0:51:56  iter: 9339  total_loss: 0.5681  loss_cls: 0.2738  loss_box_reg: 0.2048  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.02152  time: 0.9224  data_time: 0.0134  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:02:03 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 9359  total_loss: 0.6346  loss_cls: 0.3023  loss_box_reg: 0.2018  loss_rpn_cls: 0.008975  loss_rpn_loc: 0.01911  time: 0.9216  data_time: 0.0128  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:02:14 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 9379  total_loss: 0.4465  loss_cls: 0.2211  loss_box_reg: 0.1944  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.01941  time: 0.9208  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:02:25 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 9399  total_loss: 0.3705  loss_cls: 0.2015  loss_box_reg: 0.1673  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.01428  time: 0.9200  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:02:36 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 9419  total_loss: 0.5112  loss_cls: 0.2594  loss_box_reg: 0.1931  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.01552  time: 0.9193  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:02:47 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 9439  total_loss: 0.5844  loss_cls: 0.3067  loss_box_reg: 0.2027  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.0225  time: 0.9185  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:02:58 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 9459  total_loss: 0.6037  loss_cls: 0.2892  loss_box_reg: 0.2583  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.0218  time: 0.9177  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:03:09 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 9479  total_loss: 0.519  loss_cls: 0.2397  loss_box_reg: 0.198  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.02731  time: 0.9169  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:03:20 d2.utils.events]: \u001b[0m eta: 0:50:26  iter: 9499  total_loss: 0.5023  loss_cls: 0.2745  loss_box_reg: 0.2176  loss_rpn_cls: 0.01212  loss_rpn_loc: 0.02776  time: 0.9162  data_time: 0.0118  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:03:31 d2.utils.events]: \u001b[0m eta: 0:50:15  iter: 9519  total_loss: 0.5028  loss_cls: 0.2757  loss_box_reg: 0.176  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.01796  time: 0.9154  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:03:42 d2.utils.events]: \u001b[0m eta: 0:50:04  iter: 9539  total_loss: 0.4994  loss_cls: 0.2599  loss_box_reg: 0.198  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.01998  time: 0.9146  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:03:53 d2.utils.events]: \u001b[0m eta: 0:49:54  iter: 9559  total_loss: 0.469  loss_cls: 0.2714  loss_box_reg: 0.1718  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.0226  time: 0.9139  data_time: 0.0145  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:04:04 d2.utils.events]: \u001b[0m eta: 0:49:43  iter: 9579  total_loss: 0.5906  loss_cls: 0.3167  loss_box_reg: 0.2498  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.02047  time: 0.9131  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:04:15 d2.utils.events]: \u001b[0m eta: 0:49:32  iter: 9599  total_loss: 0.6371  loss_cls: 0.3474  loss_box_reg: 0.2404  loss_rpn_cls: 0.01547  loss_rpn_loc: 0.02516  time: 0.9124  data_time: 0.0135  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:04:26 d2.utils.events]: \u001b[0m eta: 0:49:21  iter: 9619  total_loss: 0.4972  loss_cls: 0.2484  loss_box_reg: 0.2179  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.01863  time: 0.9116  data_time: 0.0141  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:04:38 d2.utils.events]: \u001b[0m eta: 0:49:10  iter: 9639  total_loss: 0.4509  loss_cls: 0.2316  loss_box_reg: 0.1678  loss_rpn_cls: 0.007066  loss_rpn_loc: 0.01461  time: 0.9109  data_time: 0.0142  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:04:49 d2.utils.events]: \u001b[0m eta: 0:48:59  iter: 9659  total_loss: 0.465  loss_cls: 0.2339  loss_box_reg: 0.1887  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.02227  time: 0.9102  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:05:00 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 9679  total_loss: 0.6475  loss_cls: 0.3306  loss_box_reg: 0.2721  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.03691  time: 0.9094  data_time: 0.0142  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:05:11 d2.utils.events]: \u001b[0m eta: 0:48:37  iter: 9699  total_loss: 0.4189  loss_cls: 0.2105  loss_box_reg: 0.1637  loss_rpn_cls: 0.007454  loss_rpn_loc: 0.01009  time: 0.9087  data_time: 0.0118  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:05:22 d2.utils.events]: \u001b[0m eta: 0:48:26  iter: 9719  total_loss: 0.4598  loss_cls: 0.2162  loss_box_reg: 0.2053  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.0293  time: 0.9080  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:05:33 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 9739  total_loss: 0.4287  loss_cls: 0.2268  loss_box_reg: 0.1948  loss_rpn_cls: 0.01352  loss_rpn_loc: 0.0157  time: 0.9072  data_time: 0.0136  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:05:44 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 9759  total_loss: 0.4296  loss_cls: 0.2042  loss_box_reg: 0.1594  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.01371  time: 0.9065  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:05:55 d2.utils.events]: \u001b[0m eta: 0:47:53  iter: 9779  total_loss: 0.504  loss_cls: 0.267  loss_box_reg: 0.2098  loss_rpn_cls: 0.01389  loss_rpn_loc: 0.0247  time: 0.9058  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:06:06 d2.utils.events]: \u001b[0m eta: 0:47:42  iter: 9799  total_loss: 0.5675  loss_cls: 0.2499  loss_box_reg: 0.224  loss_rpn_cls: 0.009535  loss_rpn_loc: 0.01884  time: 0.9051  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:06:17 d2.utils.events]: \u001b[0m eta: 0:47:31  iter: 9819  total_loss: 0.452  loss_cls: 0.2465  loss_box_reg: 0.1584  loss_rpn_cls: 0.009286  loss_rpn_loc: 0.0143  time: 0.9043  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:06:28 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 9839  total_loss: 0.5186  loss_cls: 0.265  loss_box_reg: 0.1912  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.03054  time: 0.9036  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:06:39 d2.utils.events]: \u001b[0m eta: 0:47:09  iter: 9859  total_loss: 0.4998  loss_cls: 0.2552  loss_box_reg: 0.1988  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.02637  time: 0.9029  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:06:50 d2.utils.events]: \u001b[0m eta: 0:46:58  iter: 9879  total_loss: 0.4513  loss_cls: 0.2314  loss_box_reg: 0.1748  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.01558  time: 0.9022  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:07:01 d2.utils.events]: \u001b[0m eta: 0:46:47  iter: 9899  total_loss: 0.537  loss_cls: 0.2808  loss_box_reg: 0.2299  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.01741  time: 0.9015  data_time: 0.0118  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:07:12 d2.utils.events]: \u001b[0m eta: 0:46:36  iter: 9919  total_loss: 0.5058  loss_cls: 0.2812  loss_box_reg: 0.1968  loss_rpn_cls: 0.01077  loss_rpn_loc: 0.0128  time: 0.9008  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:07:23 d2.utils.events]: \u001b[0m eta: 0:46:25  iter: 9939  total_loss: 0.4609  loss_cls: 0.2277  loss_box_reg: 0.1849  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.01395  time: 0.9001  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:07:34 d2.utils.events]: \u001b[0m eta: 0:46:14  iter: 9959  total_loss: 0.5412  loss_cls: 0.262  loss_box_reg: 0.2387  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.01999  time: 0.8994  data_time: 0.0137  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:07:45 d2.utils.events]: \u001b[0m eta: 0:46:04  iter: 9979  total_loss: 0.5702  loss_cls: 0.2844  loss_box_reg: 0.2059  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.03311  time: 0.8987  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:07:57 d2.utils.events]: \u001b[0m eta: 0:45:53  iter: 9999  total_loss: 0.5208  loss_cls: 0.2546  loss_box_reg: 0.2044  loss_rpn_cls: 0.007398  loss_rpn_loc: 0.02025  time: 0.8980  data_time: 0.0137  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:08:08 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 10019  total_loss: 0.4832  loss_cls: 0.2519  loss_box_reg: 0.1995  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.01555  time: 0.8973  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:08:19 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 10039  total_loss: 0.4801  loss_cls: 0.243  loss_box_reg: 0.2196  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.01156  time: 0.8966  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:08:30 d2.utils.events]: \u001b[0m eta: 0:45:20  iter: 10059  total_loss: 0.4206  loss_cls: 0.2389  loss_box_reg: 0.1681  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.02292  time: 0.8959  data_time: 0.0132  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:08:41 d2.utils.events]: \u001b[0m eta: 0:45:10  iter: 10079  total_loss: 0.5786  loss_cls: 0.2907  loss_box_reg: 0.2432  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.02935  time: 0.8952  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:08:52 d2.utils.events]: \u001b[0m eta: 0:44:58  iter: 10099  total_loss: 0.4642  loss_cls: 0.2373  loss_box_reg: 0.1942  loss_rpn_cls: 0.01021  loss_rpn_loc: 0.01468  time: 0.8946  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:09:03 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 10119  total_loss: 0.4094  loss_cls: 0.2015  loss_box_reg: 0.1655  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.02836  time: 0.8939  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:09:14 d2.utils.events]: \u001b[0m eta: 0:44:36  iter: 10139  total_loss: 0.6179  loss_cls: 0.2828  loss_box_reg: 0.2719  loss_rpn_cls: 0.01653  loss_rpn_loc: 0.03857  time: 0.8932  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:09:25 d2.utils.events]: \u001b[0m eta: 0:44:26  iter: 10159  total_loss: 0.5255  loss_cls: 0.2477  loss_box_reg: 0.2218  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01951  time: 0.8925  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:09:36 d2.utils.events]: \u001b[0m eta: 0:44:15  iter: 10179  total_loss: 0.4878  loss_cls: 0.2468  loss_box_reg: 0.1821  loss_rpn_cls: 0.009383  loss_rpn_loc: 0.02331  time: 0.8919  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:09:47 d2.utils.events]: \u001b[0m eta: 0:44:04  iter: 10199  total_loss: 0.6404  loss_cls: 0.3016  loss_box_reg: 0.2356  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.0441  time: 0.8912  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:09:58 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 10219  total_loss: 0.4508  loss_cls: 0.2467  loss_box_reg: 0.1671  loss_rpn_cls: 0.01009  loss_rpn_loc: 0.01154  time: 0.8905  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:10:09 d2.utils.events]: \u001b[0m eta: 0:43:41  iter: 10239  total_loss: 0.5526  loss_cls: 0.2851  loss_box_reg: 0.2073  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.01465  time: 0.8899  data_time: 0.0128  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:10:20 d2.utils.events]: \u001b[0m eta: 0:43:30  iter: 10259  total_loss: 0.6445  loss_cls: 0.3365  loss_box_reg: 0.2197  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.03119  time: 0.8892  data_time: 0.0142  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:10:31 d2.utils.events]: \u001b[0m eta: 0:43:20  iter: 10279  total_loss: 0.4609  loss_cls: 0.2576  loss_box_reg: 0.1879  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.02728  time: 0.8886  data_time: 0.0142  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:10:42 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 10299  total_loss: 0.5124  loss_cls: 0.2626  loss_box_reg: 0.2002  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.01543  time: 0.8879  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:10:53 d2.utils.events]: \u001b[0m eta: 0:42:57  iter: 10319  total_loss: 0.5645  loss_cls: 0.2472  loss_box_reg: 0.2097  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.01978  time: 0.8873  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:11:04 d2.utils.events]: \u001b[0m eta: 0:42:46  iter: 10339  total_loss: 0.4875  loss_cls: 0.2522  loss_box_reg: 0.1876  loss_rpn_cls: 0.009463  loss_rpn_loc: 0.01708  time: 0.8866  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:11:15 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 10359  total_loss: 0.5182  loss_cls: 0.2334  loss_box_reg: 0.2364  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.03647  time: 0.8860  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:11:26 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 10379  total_loss: 0.5526  loss_cls: 0.2797  loss_box_reg: 0.2252  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.02356  time: 0.8853  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:11:37 d2.utils.events]: \u001b[0m eta: 0:42:13  iter: 10399  total_loss: 0.3653  loss_cls: 0.2248  loss_box_reg: 0.1516  loss_rpn_cls: 0.007737  loss_rpn_loc: 0.008955  time: 0.8847  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:11:48 d2.utils.events]: \u001b[0m eta: 0:42:02  iter: 10419  total_loss: 0.533  loss_cls: 0.2614  loss_box_reg: 0.2278  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.02405  time: 0.8840  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:11:59 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 10439  total_loss: 0.527  loss_cls: 0.2569  loss_box_reg: 0.2434  loss_rpn_cls: 0.01961  loss_rpn_loc: 0.02781  time: 0.8834  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:12:10 d2.utils.events]: \u001b[0m eta: 0:41:39  iter: 10459  total_loss: 0.4687  loss_cls: 0.2307  loss_box_reg: 0.1945  loss_rpn_cls: 0.01022  loss_rpn_loc: 0.01638  time: 0.8827  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:12:21 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 10479  total_loss: 0.5686  loss_cls: 0.2902  loss_box_reg: 0.2277  loss_rpn_cls: 0.02334  loss_rpn_loc: 0.03053  time: 0.8821  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:12:33 d2.utils.events]: \u001b[0m eta: 0:41:17  iter: 10499  total_loss: 0.6925  loss_cls: 0.3453  loss_box_reg: 0.2591  loss_rpn_cls: 0.01885  loss_rpn_loc: 0.02911  time: 0.8815  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:12:44 d2.utils.events]: \u001b[0m eta: 0:41:07  iter: 10519  total_loss: 0.4958  loss_cls: 0.2699  loss_box_reg: 0.196  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.02039  time: 0.8809  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:12:55 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 10539  total_loss: 0.5283  loss_cls: 0.2575  loss_box_reg: 0.2141  loss_rpn_cls: 0.01022  loss_rpn_loc: 0.01231  time: 0.8802  data_time: 0.0134  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:13:06 d2.utils.events]: \u001b[0m eta: 0:40:45  iter: 10559  total_loss: 0.5244  loss_cls: 0.2617  loss_box_reg: 0.2268  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.0187  time: 0.8796  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:13:17 d2.utils.events]: \u001b[0m eta: 0:40:34  iter: 10579  total_loss: 0.597  loss_cls: 0.303  loss_box_reg: 0.2423  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.03106  time: 0.8790  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:13:28 d2.utils.events]: \u001b[0m eta: 0:40:22  iter: 10599  total_loss: 0.4798  loss_cls: 0.2438  loss_box_reg: 0.1969  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.02063  time: 0.8784  data_time: 0.0119  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:13:39 d2.utils.events]: \u001b[0m eta: 0:40:11  iter: 10619  total_loss: 0.5312  loss_cls: 0.2781  loss_box_reg: 0.2004  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.02272  time: 0.8778  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:13:50 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 10639  total_loss: 0.6187  loss_cls: 0.3136  loss_box_reg: 0.26  loss_rpn_cls: 0.02011  loss_rpn_loc: 0.03521  time: 0.8772  data_time: 0.0138  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:14:01 d2.utils.events]: \u001b[0m eta: 0:39:48  iter: 10659  total_loss: 0.512  loss_cls: 0.2465  loss_box_reg: 0.2364  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.01901  time: 0.8765  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:14:12 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 10679  total_loss: 0.4835  loss_cls: 0.2842  loss_box_reg: 0.1951  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.01703  time: 0.8759  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:14:23 d2.utils.events]: \u001b[0m eta: 0:39:26  iter: 10699  total_loss: 0.4892  loss_cls: 0.2195  loss_box_reg: 0.1937  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.01602  time: 0.8753  data_time: 0.0135  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:14:34 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 10719  total_loss: 0.5122  loss_cls: 0.2552  loss_box_reg: 0.2291  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.025  time: 0.8747  data_time: 0.0135  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:14:45 d2.utils.events]: \u001b[0m eta: 0:39:04  iter: 10739  total_loss: 0.4526  loss_cls: 0.2111  loss_box_reg: 0.198  loss_rpn_cls: 0.009179  loss_rpn_loc: 0.0182  time: 0.8741  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:14:56 d2.utils.events]: \u001b[0m eta: 0:38:53  iter: 10759  total_loss: 0.442  loss_cls: 0.2255  loss_box_reg: 0.1855  loss_rpn_cls: 0.008009  loss_rpn_loc: 0.02195  time: 0.8735  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:15:08 d2.utils.events]: \u001b[0m eta: 0:38:42  iter: 10779  total_loss: 0.6071  loss_cls: 0.2799  loss_box_reg: 0.2298  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.02933  time: 0.8729  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:15:19 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 10799  total_loss: 0.6344  loss_cls: 0.3068  loss_box_reg: 0.24  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.02224  time: 0.8723  data_time: 0.0119  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:15:30 d2.utils.events]: \u001b[0m eta: 0:38:20  iter: 10819  total_loss: 0.6057  loss_cls: 0.2827  loss_box_reg: 0.2272  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.0276  time: 0.8717  data_time: 0.0137  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:15:41 d2.utils.events]: \u001b[0m eta: 0:38:09  iter: 10839  total_loss: 0.4114  loss_cls: 0.2084  loss_box_reg: 0.1732  loss_rpn_cls: 0.009821  loss_rpn_loc: 0.02582  time: 0.8712  data_time: 0.0133  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:15:52 d2.utils.events]: \u001b[0m eta: 0:37:58  iter: 10859  total_loss: 0.539  loss_cls: 0.2796  loss_box_reg: 0.2212  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.0244  time: 0.8706  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:16:03 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 10879  total_loss: 0.504  loss_cls: 0.2282  loss_box_reg: 0.1955  loss_rpn_cls: 0.007898  loss_rpn_loc: 0.01943  time: 0.8700  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:16:14 d2.utils.events]: \u001b[0m eta: 0:37:37  iter: 10899  total_loss: 0.4495  loss_cls: 0.2389  loss_box_reg: 0.1976  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.01632  time: 0.8694  data_time: 0.0131  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:16:25 d2.utils.events]: \u001b[0m eta: 0:37:26  iter: 10919  total_loss: 0.4475  loss_cls: 0.2413  loss_box_reg: 0.1859  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.02312  time: 0.8688  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:16:36 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 10939  total_loss: 0.5126  loss_cls: 0.2597  loss_box_reg: 0.1938  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.03122  time: 0.8683  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:16:47 d2.utils.events]: \u001b[0m eta: 0:37:04  iter: 10959  total_loss: 0.575  loss_cls: 0.2942  loss_box_reg: 0.2401  loss_rpn_cls: 0.01547  loss_rpn_loc: 0.02075  time: 0.8677  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:16:58 d2.utils.events]: \u001b[0m eta: 0:36:53  iter: 10979  total_loss: 0.4807  loss_cls: 0.2414  loss_box_reg: 0.1874  loss_rpn_cls: 0.009344  loss_rpn_loc: 0.01352  time: 0.8671  data_time: 0.0120  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:17:09 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 10999  total_loss: 0.6001  loss_cls: 0.275  loss_box_reg: 0.2367  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.02859  time: 0.8665  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:17:20 d2.utils.events]: \u001b[0m eta: 0:36:31  iter: 11019  total_loss: 0.5206  loss_cls: 0.2692  loss_box_reg: 0.1861  loss_rpn_cls: 0.009943  loss_rpn_loc: 0.02565  time: 0.8660  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:17:31 d2.utils.events]: \u001b[0m eta: 0:36:20  iter: 11039  total_loss: 0.4995  loss_cls: 0.2595  loss_box_reg: 0.191  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.01631  time: 0.8654  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:17:42 d2.utils.events]: \u001b[0m eta: 0:36:09  iter: 11059  total_loss: 0.4305  loss_cls: 0.2354  loss_box_reg: 0.1567  loss_rpn_cls: 0.009463  loss_rpn_loc: 0.0181  time: 0.8648  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:17:54 d2.utils.events]: \u001b[0m eta: 0:35:58  iter: 11079  total_loss: 0.471  loss_cls: 0.2716  loss_box_reg: 0.1877  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.02676  time: 0.8643  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:18:05 d2.utils.events]: \u001b[0m eta: 0:35:47  iter: 11099  total_loss: 0.56  loss_cls: 0.2745  loss_box_reg: 0.2324  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.01693  time: 0.8637  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:18:16 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 11119  total_loss: 0.4903  loss_cls: 0.2632  loss_box_reg: 0.1904  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.0204  time: 0.8631  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:18:27 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 11139  total_loss: 0.6345  loss_cls: 0.2863  loss_box_reg: 0.2493  loss_rpn_cls: 0.01885  loss_rpn_loc: 0.02242  time: 0.8626  data_time: 0.0128  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:18:38 d2.utils.events]: \u001b[0m eta: 0:35:15  iter: 11159  total_loss: 0.4716  loss_cls: 0.2314  loss_box_reg: 0.1976  loss_rpn_cls: 0.009426  loss_rpn_loc: 0.02308  time: 0.8620  data_time: 0.0131  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:18:49 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 11179  total_loss: 0.5123  loss_cls: 0.253  loss_box_reg: 0.1912  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01633  time: 0.8615  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:19:00 d2.utils.events]: \u001b[0m eta: 0:34:53  iter: 11199  total_loss: 0.4681  loss_cls: 0.2355  loss_box_reg: 0.1438  loss_rpn_cls: 0.007401  loss_rpn_loc: 0.01098  time: 0.8609  data_time: 0.0128  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:19:11 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 11219  total_loss: 0.4658  loss_cls: 0.258  loss_box_reg: 0.1859  loss_rpn_cls: 0.01547  loss_rpn_loc: 0.01539  time: 0.8604  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:19:22 d2.utils.events]: \u001b[0m eta: 0:34:31  iter: 11239  total_loss: 0.5434  loss_cls: 0.2715  loss_box_reg: 0.2279  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.0341  time: 0.8598  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:19:33 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 11259  total_loss: 0.5993  loss_cls: 0.3028  loss_box_reg: 0.2546  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.01883  time: 0.8593  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:19:44 d2.utils.events]: \u001b[0m eta: 0:34:08  iter: 11279  total_loss: 0.4461  loss_cls: 0.2319  loss_box_reg: 0.1856  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.0127  time: 0.8587  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:19:55 d2.utils.events]: \u001b[0m eta: 0:33:57  iter: 11299  total_loss: 0.4861  loss_cls: 0.2386  loss_box_reg: 0.2083  loss_rpn_cls: 0.01398  loss_rpn_loc: 0.0242  time: 0.8582  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:20:06 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 11319  total_loss: 0.6719  loss_cls: 0.3385  loss_box_reg: 0.2564  loss_rpn_cls: 0.01879  loss_rpn_loc: 0.02824  time: 0.8576  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:20:17 d2.utils.events]: \u001b[0m eta: 0:33:35  iter: 11339  total_loss: 0.5381  loss_cls: 0.2499  loss_box_reg: 0.2183  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.02272  time: 0.8571  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:20:28 d2.utils.events]: \u001b[0m eta: 0:33:24  iter: 11359  total_loss: 0.449  loss_cls: 0.2175  loss_box_reg: 0.1944  loss_rpn_cls: 0.01018  loss_rpn_loc: 0.02084  time: 0.8566  data_time: 0.0131  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:20:39 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 11379  total_loss: 0.5545  loss_cls: 0.2876  loss_box_reg: 0.2403  loss_rpn_cls: 0.01899  loss_rpn_loc: 0.02487  time: 0.8560  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:20:50 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 11399  total_loss: 0.5479  loss_cls: 0.2625  loss_box_reg: 0.242  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.02515  time: 0.8555  data_time: 0.0133  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:21:01 d2.utils.events]: \u001b[0m eta: 0:32:51  iter: 11419  total_loss: 0.5379  loss_cls: 0.2232  loss_box_reg: 0.2094  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.01973  time: 0.8550  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:21:12 d2.utils.events]: \u001b[0m eta: 0:32:41  iter: 11439  total_loss: 0.566  loss_cls: 0.2749  loss_box_reg: 0.2232  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.02439  time: 0.8544  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:21:23 d2.utils.events]: \u001b[0m eta: 0:32:29  iter: 11459  total_loss: 0.4774  loss_cls: 0.238  loss_box_reg: 0.219  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.02148  time: 0.8539  data_time: 0.0123  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:21:34 d2.utils.events]: \u001b[0m eta: 0:32:18  iter: 11479  total_loss: 0.5325  loss_cls: 0.2826  loss_box_reg: 0.1813  loss_rpn_cls: 0.0105  loss_rpn_loc: 0.02432  time: 0.8534  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:21:45 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 11499  total_loss: 0.5018  loss_cls: 0.2648  loss_box_reg: 0.2021  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.01812  time: 0.8528  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:21:56 d2.utils.events]: \u001b[0m eta: 0:31:56  iter: 11519  total_loss: 0.4722  loss_cls: 0.2267  loss_box_reg: 0.2112  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.02388  time: 0.8523  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:22:07 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 11539  total_loss: 0.4666  loss_cls: 0.2484  loss_box_reg: 0.2106  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.02477  time: 0.8518  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:22:18 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 11559  total_loss: 0.6156  loss_cls: 0.3197  loss_box_reg: 0.2363  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.02666  time: 0.8513  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:22:30 d2.utils.events]: \u001b[0m eta: 0:31:22  iter: 11579  total_loss: 0.422  loss_cls: 0.2198  loss_box_reg: 0.1515  loss_rpn_cls: 0.008813  loss_rpn_loc: 0.02653  time: 0.8507  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:22:41 d2.utils.events]: \u001b[0m eta: 0:31:11  iter: 11599  total_loss: 0.5688  loss_cls: 0.2587  loss_box_reg: 0.2427  loss_rpn_cls: 0.008762  loss_rpn_loc: 0.03527  time: 0.8502  data_time: 0.0122  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:22:52 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 11619  total_loss: 0.4825  loss_cls: 0.2568  loss_box_reg: 0.2045  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.02062  time: 0.8497  data_time: 0.0133  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:23:03 d2.utils.events]: \u001b[0m eta: 0:30:50  iter: 11639  total_loss: 0.5552  loss_cls: 0.2854  loss_box_reg: 0.2435  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.03624  time: 0.8492  data_time: 0.0134  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:23:14 d2.utils.events]: \u001b[0m eta: 0:30:39  iter: 11659  total_loss: 0.6311  loss_cls: 0.3245  loss_box_reg: 0.2376  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.02329  time: 0.8487  data_time: 0.0136  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:23:25 d2.utils.events]: \u001b[0m eta: 0:30:28  iter: 11679  total_loss: 0.4263  loss_cls: 0.2242  loss_box_reg: 0.1982  loss_rpn_cls: 0.00812  loss_rpn_loc: 0.0217  time: 0.8482  data_time: 0.0145  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:23:36 d2.utils.events]: \u001b[0m eta: 0:30:17  iter: 11699  total_loss: 0.5317  loss_cls: 0.3095  loss_box_reg: 0.1955  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.0227  time: 0.8477  data_time: 0.0129  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:23:47 d2.utils.events]: \u001b[0m eta: 0:30:06  iter: 11719  total_loss: 0.6121  loss_cls: 0.287  loss_box_reg: 0.2202  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.01484  time: 0.8472  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:23:58 d2.utils.events]: \u001b[0m eta: 0:29:55  iter: 11739  total_loss: 0.4776  loss_cls: 0.2554  loss_box_reg: 0.1861  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.01819  time: 0.8467  data_time: 0.0127  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:24:09 d2.utils.events]: \u001b[0m eta: 0:29:44  iter: 11759  total_loss: 0.3765  loss_cls: 0.2282  loss_box_reg: 0.1448  loss_rpn_cls: 0.008297  loss_rpn_loc: 0.01086  time: 0.8462  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:24:20 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 11779  total_loss: 0.4894  loss_cls: 0.2372  loss_box_reg: 0.174  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.02001  time: 0.8457  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:24:31 d2.utils.events]: \u001b[0m eta: 0:29:23  iter: 11799  total_loss: 0.5411  loss_cls: 0.2831  loss_box_reg: 0.2167  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.01664  time: 0.8452  data_time: 0.0130  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:24:42 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 11819  total_loss: 0.5796  loss_cls: 0.2695  loss_box_reg: 0.2585  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.02513  time: 0.8447  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:24:54 d2.utils.events]: \u001b[0m eta: 0:29:00  iter: 11839  total_loss: 0.6028  loss_cls: 0.3127  loss_box_reg: 0.2044  loss_rpn_cls: 0.01903  loss_rpn_loc: 0.02436  time: 0.8442  data_time: 0.0132  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:25:05 d2.utils.events]: \u001b[0m eta: 0:28:49  iter: 11859  total_loss: 0.6172  loss_cls: 0.2426  loss_box_reg: 0.2381  loss_rpn_cls: 0.01868  loss_rpn_loc: 0.02705  time: 0.8437  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:25:16 d2.utils.events]: \u001b[0m eta: 0:28:38  iter: 11879  total_loss: 0.518  loss_cls: 0.2651  loss_box_reg: 0.2134  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01951  time: 0.8432  data_time: 0.0121  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:25:27 d2.utils.events]: \u001b[0m eta: 0:28:27  iter: 11899  total_loss: 0.5499  loss_cls: 0.279  loss_box_reg: 0.2214  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.03617  time: 0.8427  data_time: 0.0125  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:25:38 d2.utils.events]: \u001b[0m eta: 0:28:16  iter: 11919  total_loss: 0.4853  loss_cls: 0.2211  loss_box_reg: 0.2003  loss_rpn_cls: 0.006609  loss_rpn_loc: 0.02315  time: 0.8422  data_time: 0.0137  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:25:49 d2.utils.events]: \u001b[0m eta: 0:28:05  iter: 11939  total_loss: 0.4631  loss_cls: 0.2531  loss_box_reg: 0.1798  loss_rpn_cls: 0.009175  loss_rpn_loc: 0.02214  time: 0.8418  data_time: 0.0128  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:26:00 d2.utils.events]: \u001b[0m eta: 0:27:54  iter: 11959  total_loss: 0.5156  loss_cls: 0.2746  loss_box_reg: 0.196  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.01852  time: 0.8413  data_time: 0.0128  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:26:11 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 11979  total_loss: 0.5036  loss_cls: 0.2593  loss_box_reg: 0.1959  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.02387  time: 0.8408  data_time: 0.0124  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:26:22 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/test.json\n",
      "\u001b[32m[09/27 16:26:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/27 16:26:23 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/27 16:26:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.50 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/27 16:26:23 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/27 16:26:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/27 16:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0010 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0457 s/iter. ETA=0:03:42\n",
      "\u001b[32m[09/27 16:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 120/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:03:39\n",
      "\u001b[32m[09/27 16:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 228/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:03:35\n",
      "\u001b[32m[09/27 16:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 337/4871. Dataloading: 0.0012 s/iter. Inference: 0.0448 s/iter. Eval: 0.0003 s/iter. Total: 0.0463 s/iter. ETA=0:03:29\n",
      "\u001b[32m[09/27 16:26:44 d2.evaluation.evaluator]: \u001b[0mInference done 447/4871. Dataloading: 0.0012 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:03:24\n",
      "\u001b[32m[09/27 16:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 557/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0461 s/iter. ETA=0:03:18\n",
      "\u001b[32m[09/27 16:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 668/4871. Dataloading: 0.0012 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:03:13\n",
      "\u001b[32m[09/27 16:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 779/4871. Dataloading: 0.0012 s/iter. Inference: 0.0443 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:03:07\n",
      "\u001b[32m[09/27 16:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 888/4871. Dataloading: 0.0012 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:03:02\n",
      "\u001b[32m[09/27 16:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 998/4871. Dataloading: 0.0012 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:02:57\n",
      "\u001b[32m[09/27 16:27:14 d2.evaluation.evaluator]: \u001b[0mInference done 1110/4871. Dataloading: 0.0012 s/iter. Inference: 0.0443 s/iter. Eval: 0.0003 s/iter. Total: 0.0458 s/iter. ETA=0:02:52\n",
      "\u001b[32m[09/27 16:27:19 d2.evaluation.evaluator]: \u001b[0mInference done 1222/4871. Dataloading: 0.0012 s/iter. Inference: 0.0442 s/iter. Eval: 0.0003 s/iter. Total: 0.0457 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/27 16:27:24 d2.evaluation.evaluator]: \u001b[0mInference done 1334/4871. Dataloading: 0.0012 s/iter. Inference: 0.0442 s/iter. Eval: 0.0003 s/iter. Total: 0.0456 s/iter. ETA=0:02:41\n",
      "\u001b[32m[09/27 16:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 1444/4871. Dataloading: 0.0012 s/iter. Inference: 0.0442 s/iter. Eval: 0.0003 s/iter. Total: 0.0456 s/iter. ETA=0:02:36\n",
      "\u001b[32m[09/27 16:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 1543/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:02:33\n",
      "\u001b[32m[09/27 16:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 1652/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/27 16:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 1761/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:02:23\n",
      "\u001b[32m[09/27 16:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 1871/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:02:17\n",
      "\u001b[32m[09/27 16:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 1980/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:02:12\n",
      "\u001b[32m[09/27 16:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 2090/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:02:07\n",
      "\u001b[32m[09/27 16:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 2200/4871. Dataloading: 0.0012 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:02:02\n",
      "\u001b[32m[09/27 16:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 2310/4871. Dataloading: 0.0012 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:01:57\n",
      "\u001b[32m[09/27 16:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 2418/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:52\n",
      "\u001b[32m[09/27 16:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 2524/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/27 16:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 2634/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:42\n",
      "\u001b[32m[09/27 16:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 2744/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/27 16:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 2853/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:32\n",
      "\u001b[32m[09/27 16:28:39 d2.evaluation.evaluator]: \u001b[0mInference done 2960/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:27\n",
      "\u001b[32m[09/27 16:28:44 d2.evaluation.evaluator]: \u001b[0mInference done 3069/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:22\n",
      "\u001b[32m[09/27 16:28:49 d2.evaluation.evaluator]: \u001b[0mInference done 3179/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:17\n",
      "\u001b[32m[09/27 16:28:54 d2.evaluation.evaluator]: \u001b[0mInference done 3289/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:12\n",
      "\u001b[32m[09/27 16:28:59 d2.evaluation.evaluator]: \u001b[0mInference done 3399/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:07\n",
      "\u001b[32m[09/27 16:29:04 d2.evaluation.evaluator]: \u001b[0mInference done 3509/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:01:02\n",
      "\u001b[32m[09/27 16:29:09 d2.evaluation.evaluator]: \u001b[0mInference done 3619/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:57\n",
      "\u001b[32m[09/27 16:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 3729/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:52\n",
      "\u001b[32m[09/27 16:29:19 d2.evaluation.evaluator]: \u001b[0mInference done 3839/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:47\n",
      "\u001b[32m[09/27 16:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 3948/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:42\n",
      "\u001b[32m[09/27 16:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 4056/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/27 16:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 4167/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/27 16:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 4273/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/27 16:29:44 d2.evaluation.evaluator]: \u001b[0mInference done 4383/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/27 16:29:50 d2.evaluation.evaluator]: \u001b[0mInference done 4494/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/27 16:29:55 d2.evaluation.evaluator]: \u001b[0mInference done 4605/4871. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/27 16:30:00 d2.evaluation.evaluator]: \u001b[0mInference done 4716/4871. Dataloading: 0.0012 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/27 16:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 4827/4871. Dataloading: 0.0012 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/27 16:30:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:43.526553 (0.045936 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 16:30:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:36 (0.044415 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/27 16:30:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/27 16:30:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/27 16:30:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/27 16:30:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.99 seconds.\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.24 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[09/27 16:30:11 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/27 16:30:11 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[09/27 16:30:11 d2.utils.events]: \u001b[0m eta: 0:27:32  iter: 11999  total_loss: 0.4986  loss_cls: 0.2477  loss_box_reg: 0.2023  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.0193  time: 0.8403  data_time: 0.0126  lr: 5e-06  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:30:22 d2.utils.events]: \u001b[0m eta: 0:27:21  iter: 12019  total_loss: 0.5837  loss_cls: 0.3079  loss_box_reg: 0.2267  loss_rpn_cls: 0.02027  loss_rpn_loc: 0.03874  time: 0.8398  data_time: 0.0139  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:30:33 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 12039  total_loss: 0.5553  loss_cls: 0.2578  loss_box_reg: 0.2152  loss_rpn_cls: 0.01613  loss_rpn_loc: 0.03059  time: 0.8394  data_time: 0.0135  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:30:44 d2.utils.events]: \u001b[0m eta: 0:26:59  iter: 12059  total_loss: 0.5485  loss_cls: 0.2833  loss_box_reg: 0.1971  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.02191  time: 0.8389  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:30:55 d2.utils.events]: \u001b[0m eta: 0:26:48  iter: 12079  total_loss: 0.4955  loss_cls: 0.245  loss_box_reg: 0.2118  loss_rpn_cls: 0.008753  loss_rpn_loc: 0.01336  time: 0.8384  data_time: 0.0122  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:31:06 d2.utils.events]: \u001b[0m eta: 0:26:37  iter: 12099  total_loss: 0.5459  loss_cls: 0.2833  loss_box_reg: 0.2343  loss_rpn_cls: 0.01416  loss_rpn_loc: 0.01614  time: 0.8379  data_time: 0.0124  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:31:17 d2.utils.events]: \u001b[0m eta: 0:26:26  iter: 12119  total_loss: 0.4592  loss_cls: 0.2118  loss_box_reg: 0.2159  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.01193  time: 0.8375  data_time: 0.0125  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:31:29 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 12139  total_loss: 0.5337  loss_cls: 0.2703  loss_box_reg: 0.2273  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.01816  time: 0.8370  data_time: 0.0130  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:31:40 d2.utils.events]: \u001b[0m eta: 0:26:04  iter: 12159  total_loss: 0.5375  loss_cls: 0.2609  loss_box_reg: 0.2281  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.0282  time: 0.8365  data_time: 0.0139  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:31:51 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 12179  total_loss: 0.612  loss_cls: 0.3132  loss_box_reg: 0.2295  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.02767  time: 0.8360  data_time: 0.0130  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:32:02 d2.utils.events]: \u001b[0m eta: 0:25:42  iter: 12199  total_loss: 0.4577  loss_cls: 0.2389  loss_box_reg: 0.2013  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.01941  time: 0.8356  data_time: 0.0119  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:32:13 d2.utils.events]: \u001b[0m eta: 0:25:31  iter: 12219  total_loss: 0.4908  loss_cls: 0.2395  loss_box_reg: 0.1997  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01588  time: 0.8351  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:32:24 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 12239  total_loss: 0.5767  loss_cls: 0.2857  loss_box_reg: 0.2367  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.02825  time: 0.8347  data_time: 0.0133  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:32:35 d2.utils.events]: \u001b[0m eta: 0:25:09  iter: 12259  total_loss: 0.465  loss_cls: 0.2363  loss_box_reg: 0.2288  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.01676  time: 0.8342  data_time: 0.0141  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:32:46 d2.utils.events]: \u001b[0m eta: 0:24:58  iter: 12279  total_loss: 0.6085  loss_cls: 0.3162  loss_box_reg: 0.2239  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.02919  time: 0.8337  data_time: 0.0131  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:32:57 d2.utils.events]: \u001b[0m eta: 0:24:47  iter: 12299  total_loss: 0.4197  loss_cls: 0.2166  loss_box_reg: 0.1555  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.01638  time: 0.8333  data_time: 0.0125  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:33:08 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 12319  total_loss: 0.5247  loss_cls: 0.2768  loss_box_reg: 0.2058  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.02018  time: 0.8328  data_time: 0.0130  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:33:19 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 12339  total_loss: 0.485  loss_cls: 0.2418  loss_box_reg: 0.2068  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.0212  time: 0.8324  data_time: 0.0170  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:33:30 d2.utils.events]: \u001b[0m eta: 0:24:14  iter: 12359  total_loss: 0.5263  loss_cls: 0.2717  loss_box_reg: 0.2309  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.02435  time: 0.8319  data_time: 0.0127  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:33:42 d2.utils.events]: \u001b[0m eta: 0:24:04  iter: 12379  total_loss: 0.4779  loss_cls: 0.257  loss_box_reg: 0.1936  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.02312  time: 0.8315  data_time: 0.0130  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:33:53 d2.utils.events]: \u001b[0m eta: 0:23:53  iter: 12399  total_loss: 0.5317  loss_cls: 0.2676  loss_box_reg: 0.2294  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.02538  time: 0.8310  data_time: 0.0133  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:34:04 d2.utils.events]: \u001b[0m eta: 0:23:42  iter: 12419  total_loss: 0.5027  loss_cls: 0.2513  loss_box_reg: 0.194  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.02386  time: 0.8306  data_time: 0.0139  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:34:15 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 12439  total_loss: 0.4714  loss_cls: 0.2193  loss_box_reg: 0.2065  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.01768  time: 0.8302  data_time: 0.0134  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:34:26 d2.utils.events]: \u001b[0m eta: 0:23:20  iter: 12459  total_loss: 0.5456  loss_cls: 0.2982  loss_box_reg: 0.1985  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.02479  time: 0.8297  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:34:37 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 12479  total_loss: 0.4553  loss_cls: 0.23  loss_box_reg: 0.145  loss_rpn_cls: 0.008056  loss_rpn_loc: 0.01773  time: 0.8293  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:34:48 d2.utils.events]: \u001b[0m eta: 0:22:58  iter: 12499  total_loss: 0.4536  loss_cls: 0.2405  loss_box_reg: 0.1787  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.0153  time: 0.8288  data_time: 0.0130  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:34:59 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 12519  total_loss: 0.3784  loss_cls: 0.2022  loss_box_reg: 0.1433  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.01291  time: 0.8284  data_time: 0.0127  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:35:10 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 12539  total_loss: 0.5013  loss_cls: 0.2732  loss_box_reg: 0.1915  loss_rpn_cls: 0.01074  loss_rpn_loc: 0.02599  time: 0.8279  data_time: 0.0130  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:35:21 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 12559  total_loss: 0.5116  loss_cls: 0.2571  loss_box_reg: 0.2113  loss_rpn_cls: 0.0146  loss_rpn_loc: 0.02565  time: 0.8275  data_time: 0.0130  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:35:32 d2.utils.events]: \u001b[0m eta: 0:22:14  iter: 12579  total_loss: 0.4912  loss_cls: 0.2506  loss_box_reg: 0.1969  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.02109  time: 0.8271  data_time: 0.0127  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:35:43 d2.utils.events]: \u001b[0m eta: 0:22:03  iter: 12599  total_loss: 0.4504  loss_cls: 0.2225  loss_box_reg: 0.2083  loss_rpn_cls: 0.009983  loss_rpn_loc: 0.01697  time: 0.8266  data_time: 0.0127  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:35:54 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 12619  total_loss: 0.5959  loss_cls: 0.292  loss_box_reg: 0.2563  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.02971  time: 0.8262  data_time: 0.0135  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:36:05 d2.utils.events]: \u001b[0m eta: 0:21:41  iter: 12639  total_loss: 0.4731  loss_cls: 0.2965  loss_box_reg: 0.1811  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.02009  time: 0.8258  data_time: 0.0129  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:36:17 d2.utils.events]: \u001b[0m eta: 0:21:30  iter: 12659  total_loss: 0.4887  loss_cls: 0.2193  loss_box_reg: 0.2309  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.02687  time: 0.8253  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:36:28 d2.utils.events]: \u001b[0m eta: 0:21:19  iter: 12679  total_loss: 0.4983  loss_cls: 0.2425  loss_box_reg: 0.2255  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.0173  time: 0.8249  data_time: 0.0124  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:36:39 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 12699  total_loss: 0.4609  loss_cls: 0.2992  loss_box_reg: 0.1847  loss_rpn_cls: 0.009146  loss_rpn_loc: 0.01964  time: 0.8245  data_time: 0.0125  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:36:50 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 12719  total_loss: 0.5205  loss_cls: 0.2751  loss_box_reg: 0.181  loss_rpn_cls: 0.01673  loss_rpn_loc: 0.01906  time: 0.8240  data_time: 0.0127  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:37:01 d2.utils.events]: \u001b[0m eta: 0:20:46  iter: 12739  total_loss: 0.484  loss_cls: 0.2439  loss_box_reg: 0.2257  loss_rpn_cls: 0.008735  loss_rpn_loc: 0.01689  time: 0.8236  data_time: 0.0129  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:37:12 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 12759  total_loss: 0.6223  loss_cls: 0.2761  loss_box_reg: 0.2548  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.03102  time: 0.8232  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:37:23 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 12779  total_loss: 0.4973  loss_cls: 0.25  loss_box_reg: 0.1887  loss_rpn_cls: 0.009384  loss_rpn_loc: 0.01172  time: 0.8228  data_time: 0.0122  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:37:34 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 12799  total_loss: 0.5431  loss_cls: 0.2908  loss_box_reg: 0.2307  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.01668  time: 0.8223  data_time: 0.0128  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:37:45 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 12819  total_loss: 0.5722  loss_cls: 0.2734  loss_box_reg: 0.1822  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.03197  time: 0.8219  data_time: 0.0133  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:37:56 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 12839  total_loss: 0.4377  loss_cls: 0.1942  loss_box_reg: 0.2048  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.009554  time: 0.8215  data_time: 0.0127  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:38:07 d2.utils.events]: \u001b[0m eta: 0:19:40  iter: 12859  total_loss: 0.5487  loss_cls: 0.2753  loss_box_reg: 0.219  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.01302  time: 0.8211  data_time: 0.0131  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:38:18 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 12879  total_loss: 0.5292  loss_cls: 0.2793  loss_box_reg: 0.2001  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.02286  time: 0.8207  data_time: 0.0132  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:38:29 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 12899  total_loss: 0.4322  loss_cls: 0.2325  loss_box_reg: 0.1655  loss_rpn_cls: 0.009305  loss_rpn_loc: 0.01682  time: 0.8202  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:38:40 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 12919  total_loss: 0.5308  loss_cls: 0.2332  loss_box_reg: 0.2212  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.02175  time: 0.8198  data_time: 0.0155  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:38:51 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 12939  total_loss: 0.5444  loss_cls: 0.2764  loss_box_reg: 0.1815  loss_rpn_cls: 0.009374  loss_rpn_loc: 0.01479  time: 0.8194  data_time: 0.0132  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:39:03 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 12959  total_loss: 0.5494  loss_cls: 0.2707  loss_box_reg: 0.2611  loss_rpn_cls: 0.01972  loss_rpn_loc: 0.03074  time: 0.8190  data_time: 0.0133  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:39:14 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 12979  total_loss: 0.4421  loss_cls: 0.274  loss_box_reg: 0.1856  loss_rpn_cls: 0.01529  loss_rpn_loc: 0.03441  time: 0.8186  data_time: 0.0122  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:39:25 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 12999  total_loss: 0.5539  loss_cls: 0.263  loss_box_reg: 0.2334  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.01905  time: 0.8182  data_time: 0.0128  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:39:36 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 13019  total_loss: 0.5363  loss_cls: 0.2748  loss_box_reg: 0.202  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.02735  time: 0.8178  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:39:47 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 13039  total_loss: 0.6096  loss_cls: 0.3084  loss_box_reg: 0.2388  loss_rpn_cls: 0.0148  loss_rpn_loc: 0.03028  time: 0.8174  data_time: 0.0129  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:39:58 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 13059  total_loss: 0.4223  loss_cls: 0.2462  loss_box_reg: 0.168  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.01677  time: 0.8170  data_time: 0.0124  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:40:09 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 13079  total_loss: 0.4416  loss_cls: 0.2393  loss_box_reg: 0.1795  loss_rpn_cls: 0.008906  loss_rpn_loc: 0.02099  time: 0.8166  data_time: 0.0124  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:40:20 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 13099  total_loss: 0.4354  loss_cls: 0.2396  loss_box_reg: 0.1601  loss_rpn_cls: 0.00705  loss_rpn_loc: 0.01131  time: 0.8162  data_time: 0.0118  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:40:31 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 13119  total_loss: 0.584  loss_cls: 0.2997  loss_box_reg: 0.2402  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.0292  time: 0.8158  data_time: 0.0118  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:40:42 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 13139  total_loss: 0.4397  loss_cls: 0.2469  loss_box_reg: 0.1704  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.01573  time: 0.8154  data_time: 0.0133  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:40:53 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 13159  total_loss: 0.4768  loss_cls: 0.2449  loss_box_reg: 0.191  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.02741  time: 0.8150  data_time: 0.0121  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:41:04 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 13179  total_loss: 0.5017  loss_cls: 0.2889  loss_box_reg: 0.21  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.01606  time: 0.8146  data_time: 0.0118  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:41:15 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 13199  total_loss: 0.4656  loss_cls: 0.2182  loss_box_reg: 0.2117  loss_rpn_cls: 0.01011  loss_rpn_loc: 0.01709  time: 0.8142  data_time: 0.0121  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:41:26 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 13219  total_loss: 0.5057  loss_cls: 0.2649  loss_box_reg: 0.195  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.02521  time: 0.8138  data_time: 0.0118  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:41:37 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 13239  total_loss: 0.5012  loss_cls: 0.2664  loss_box_reg: 0.2072  loss_rpn_cls: 0.009746  loss_rpn_loc: 0.01664  time: 0.8134  data_time: 0.0142  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:41:49 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 13259  total_loss: 0.4511  loss_cls: 0.2134  loss_box_reg: 0.1825  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.02153  time: 0.8130  data_time: 0.0126  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:42:00 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 13279  total_loss: 0.4613  loss_cls: 0.2426  loss_box_reg: 0.1836  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.02356  time: 0.8126  data_time: 0.0121  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:42:11 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 13299  total_loss: 0.5406  loss_cls: 0.2615  loss_box_reg: 0.2397  loss_rpn_cls: 0.01986  loss_rpn_loc: 0.02875  time: 0.8122  data_time: 0.0120  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:42:22 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 13319  total_loss: 0.4928  loss_cls: 0.2582  loss_box_reg: 0.1978  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.02136  time: 0.8118  data_time: 0.0122  lr: 2.5e-08  max_mem: 6309M\n",
      "\u001b[32m[09/27 16:42:33 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 13339  total_loss: 0.5488  loss_cls: 0.2833  loss_box_reg: 0.2051  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.01601  time: 0.8115  data_time: 0.0138  lr: 2.5e-08  max_mem: 6309M\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

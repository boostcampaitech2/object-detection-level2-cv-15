{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'coco_trash_train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2011849/695547419.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Register Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coco_trash_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../dataset/train.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../dataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'coco_trash_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../dataset/private.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../dataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
      "\u001b[0;32m~/detectron2/detectron2/data/datasets/coco.py\u001b[0m in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;31m# 1. register a function which returns dicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0mDatasetCatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_coco_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;31m# 2. Optionally, add metadata about this dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/detectron2/detectron2/data/catalog.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[1;32m     36\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You must register a function with `DatasetCatalog.register`!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Dataset '{}' is already registered!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'coco_trash_train' is already registered!"
     ]
    }
   ],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('coco_trash_train', {}, '../dataset/train.json', '../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    register_coco_instances('coco_trash_test', {}, '../dataset/test.json', '../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3)\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:34:22 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:34:22 d2.data.datasets.coco]: \u001b[0mLoaded 4883 images in COCO format from ../dataset/train.json\n",
      "\u001b[32m[09/09 14:34:22 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4883 images left.\n",
      "\u001b[32m[09/09 14:34:22 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/09 14:34:22 d2.data.common]: \u001b[0mSerializing 4883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 14:34:22 d2.data.common]: \u001b[0mSerialized dataset takes 2.17 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:34:22 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[09/09 14:34:31 d2.utils.events]: \u001b[0m eta: 1:43:54  iter: 19  total_loss: 3.213  loss_cls: 2.374  loss_box_reg: 0.7005  loss_rpn_cls: 0.08706  loss_rpn_loc: 0.03057  time: 0.4260  data_time: 0.0213  lr: 1.9981e-05  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:34:40 d2.utils.events]: \u001b[0m eta: 1:43:43  iter: 39  total_loss: 2.848  loss_cls: 1.979  loss_box_reg: 0.7271  loss_rpn_cls: 0.05476  loss_rpn_loc: 0.0231  time: 0.4259  data_time: 0.0089  lr: 3.9961e-05  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:34:48 d2.utils.events]: \u001b[0m eta: 1:43:47  iter: 59  total_loss: 1.934  loss_cls: 1.136  loss_box_reg: 0.6385  loss_rpn_cls: 0.05433  loss_rpn_loc: 0.02773  time: 0.4270  data_time: 0.0093  lr: 5.9941e-05  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:34:57 d2.utils.events]: \u001b[0m eta: 1:43:53  iter: 79  total_loss: 1.624  loss_cls: 0.796  loss_box_reg: 0.6767  loss_rpn_cls: 0.06196  loss_rpn_loc: 0.03174  time: 0.4276  data_time: 0.0090  lr: 7.9921e-05  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:35:05 d2.utils.events]: \u001b[0m eta: 1:43:49  iter: 99  total_loss: 1.593  loss_cls: 0.7318  loss_box_reg: 0.7145  loss_rpn_cls: 0.05086  loss_rpn_loc: 0.02878  time: 0.4279  data_time: 0.0083  lr: 9.9901e-05  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:35:14 d2.utils.events]: \u001b[0m eta: 1:43:43  iter: 119  total_loss: 1.671  loss_cls: 0.7708  loss_box_reg: 0.7497  loss_rpn_cls: 0.06226  loss_rpn_loc: 0.0398  time: 0.4282  data_time: 0.0088  lr: 0.00011988  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:35:23 d2.utils.events]: \u001b[0m eta: 1:43:41  iter: 139  total_loss: 1.591  loss_cls: 0.7367  loss_box_reg: 0.7748  loss_rpn_cls: 0.04221  loss_rpn_loc: 0.03725  time: 0.4286  data_time: 0.0100  lr: 0.00013986  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:35:31 d2.utils.events]: \u001b[0m eta: 1:43:41  iter: 159  total_loss: 1.507  loss_cls: 0.7153  loss_box_reg: 0.7201  loss_rpn_cls: 0.03741  loss_rpn_loc: 0.03475  time: 0.4292  data_time: 0.0107  lr: 0.00015984  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:35:40 d2.utils.events]: \u001b[0m eta: 1:43:35  iter: 179  total_loss: 1.489  loss_cls: 0.6818  loss_box_reg: 0.7231  loss_rpn_cls: 0.03629  loss_rpn_loc: 0.03068  time: 0.4295  data_time: 0.0106  lr: 0.00017982  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:35:49 d2.utils.events]: \u001b[0m eta: 1:43:29  iter: 199  total_loss: 1.443  loss_cls: 0.6882  loss_box_reg: 0.7113  loss_rpn_cls: 0.04456  loss_rpn_loc: 0.04061  time: 0.4297  data_time: 0.0099  lr: 0.0001998  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:35:57 d2.utils.events]: \u001b[0m eta: 1:43:21  iter: 219  total_loss: 1.331  loss_cls: 0.5981  loss_box_reg: 0.6793  loss_rpn_cls: 0.02628  loss_rpn_loc: 0.01887  time: 0.4298  data_time: 0.0097  lr: 0.00021978  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:36:06 d2.utils.events]: \u001b[0m eta: 1:43:17  iter: 239  total_loss: 1.255  loss_cls: 0.5644  loss_box_reg: 0.6346  loss_rpn_cls: 0.02041  loss_rpn_loc: 0.0211  time: 0.4300  data_time: 0.0105  lr: 0.00023976  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:36:15 d2.utils.events]: \u001b[0m eta: 1:43:10  iter: 259  total_loss: 1.442  loss_cls: 0.6432  loss_box_reg: 0.6905  loss_rpn_cls: 0.03673  loss_rpn_loc: 0.02109  time: 0.4302  data_time: 0.0108  lr: 0.00025974  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:36:23 d2.utils.events]: \u001b[0m eta: 1:43:05  iter: 279  total_loss: 1.417  loss_cls: 0.616  loss_box_reg: 0.708  loss_rpn_cls: 0.04504  loss_rpn_loc: 0.04105  time: 0.4305  data_time: 0.0105  lr: 0.00027972  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:36:32 d2.utils.events]: \u001b[0m eta: 1:42:56  iter: 299  total_loss: 1.318  loss_cls: 0.5951  loss_box_reg: 0.6463  loss_rpn_cls: 0.03467  loss_rpn_loc: 0.03122  time: 0.4305  data_time: 0.0097  lr: 0.0002997  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:36:41 d2.utils.events]: \u001b[0m eta: 1:42:48  iter: 319  total_loss: 1.161  loss_cls: 0.5241  loss_box_reg: 0.5852  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.0176  time: 0.4306  data_time: 0.0099  lr: 0.00031968  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:36:49 d2.utils.events]: \u001b[0m eta: 1:42:44  iter: 339  total_loss: 1.236  loss_cls: 0.61  loss_box_reg: 0.5634  loss_rpn_cls: 0.02369  loss_rpn_loc: 0.02138  time: 0.4307  data_time: 0.0106  lr: 0.00033966  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:36:58 d2.utils.events]: \u001b[0m eta: 1:42:40  iter: 359  total_loss: 1.159  loss_cls: 0.5336  loss_box_reg: 0.5042  loss_rpn_cls: 0.02787  loss_rpn_loc: 0.02823  time: 0.4309  data_time: 0.0110  lr: 0.00035964  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:37:07 d2.utils.events]: \u001b[0m eta: 1:42:32  iter: 379  total_loss: 0.9879  loss_cls: 0.5004  loss_box_reg: 0.4386  loss_rpn_cls: 0.0305  loss_rpn_loc: 0.02517  time: 0.4310  data_time: 0.0108  lr: 0.00037962  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:37:15 d2.utils.events]: \u001b[0m eta: 1:42:23  iter: 399  total_loss: 1.077  loss_cls: 0.5361  loss_box_reg: 0.4471  loss_rpn_cls: 0.04528  loss_rpn_loc: 0.04699  time: 0.4310  data_time: 0.0097  lr: 0.0003996  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:37:24 d2.utils.events]: \u001b[0m eta: 1:42:14  iter: 419  total_loss: 0.9552  loss_cls: 0.4591  loss_box_reg: 0.3983  loss_rpn_cls: 0.03044  loss_rpn_loc: 0.04885  time: 0.4310  data_time: 0.0100  lr: 0.00041958  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:37:33 d2.utils.events]: \u001b[0m eta: 1:42:07  iter: 439  total_loss: 1.144  loss_cls: 0.5364  loss_box_reg: 0.4574  loss_rpn_cls: 0.02846  loss_rpn_loc: 0.03523  time: 0.4311  data_time: 0.0111  lr: 0.00043956  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:37:41 d2.utils.events]: \u001b[0m eta: 1:42:00  iter: 459  total_loss: 1.04  loss_cls: 0.5241  loss_box_reg: 0.3984  loss_rpn_cls: 0.03793  loss_rpn_loc: 0.04064  time: 0.4312  data_time: 0.0107  lr: 0.00045954  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:37:50 d2.utils.events]: \u001b[0m eta: 1:41:53  iter: 479  total_loss: 1.066  loss_cls: 0.5493  loss_box_reg: 0.4388  loss_rpn_cls: 0.03466  loss_rpn_loc: 0.03296  time: 0.4313  data_time: 0.0104  lr: 0.00047952  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:37:59 d2.utils.events]: \u001b[0m eta: 1:41:45  iter: 499  total_loss: 0.9661  loss_cls: 0.5045  loss_box_reg: 0.3792  loss_rpn_cls: 0.04174  loss_rpn_loc: 0.03223  time: 0.4314  data_time: 0.0100  lr: 0.0004995  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:38:07 d2.utils.events]: \u001b[0m eta: 1:41:36  iter: 519  total_loss: 0.913  loss_cls: 0.4697  loss_box_reg: 0.4032  loss_rpn_cls: 0.02076  loss_rpn_loc: 0.02322  time: 0.4314  data_time: 0.0094  lr: 0.00051948  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:38:16 d2.utils.events]: \u001b[0m eta: 1:41:29  iter: 539  total_loss: 1.053  loss_cls: 0.5444  loss_box_reg: 0.4435  loss_rpn_cls: 0.03558  loss_rpn_loc: 0.0364  time: 0.4315  data_time: 0.0108  lr: 0.00053946  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:38:25 d2.utils.events]: \u001b[0m eta: 1:41:22  iter: 559  total_loss: 0.9575  loss_cls: 0.4775  loss_box_reg: 0.351  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.03135  time: 0.4316  data_time: 0.0109  lr: 0.00055944  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:38:34 d2.utils.events]: \u001b[0m eta: 1:41:16  iter: 579  total_loss: 0.8654  loss_cls: 0.4858  loss_box_reg: 0.3156  loss_rpn_cls: 0.03372  loss_rpn_loc: 0.02339  time: 0.4316  data_time: 0.0106  lr: 0.00057942  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:38:42 d2.utils.events]: \u001b[0m eta: 1:41:07  iter: 599  total_loss: 0.9516  loss_cls: 0.4811  loss_box_reg: 0.3502  loss_rpn_cls: 0.03332  loss_rpn_loc: 0.02778  time: 0.4317  data_time: 0.0101  lr: 0.0005994  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:38:51 d2.utils.events]: \u001b[0m eta: 1:40:59  iter: 619  total_loss: 0.8669  loss_cls: 0.4898  loss_box_reg: 0.3302  loss_rpn_cls: 0.02803  loss_rpn_loc: 0.02519  time: 0.4317  data_time: 0.0093  lr: 0.00061938  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:39:00 d2.utils.events]: \u001b[0m eta: 1:40:50  iter: 639  total_loss: 0.968  loss_cls: 0.5262  loss_box_reg: 0.3551  loss_rpn_cls: 0.03631  loss_rpn_loc: 0.02402  time: 0.4317  data_time: 0.0104  lr: 0.00063936  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:39:08 d2.utils.events]: \u001b[0m eta: 1:40:43  iter: 659  total_loss: 0.8599  loss_cls: 0.4895  loss_box_reg: 0.3032  loss_rpn_cls: 0.0244  loss_rpn_loc: 0.02422  time: 0.4318  data_time: 0.0111  lr: 0.00065934  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:39:17 d2.utils.events]: \u001b[0m eta: 1:40:34  iter: 679  total_loss: 0.9764  loss_cls: 0.4871  loss_box_reg: 0.352  loss_rpn_cls: 0.02773  loss_rpn_loc: 0.02813  time: 0.4318  data_time: 0.0107  lr: 0.00067932  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:39:26 d2.utils.events]: \u001b[0m eta: 1:40:26  iter: 699  total_loss: 0.9832  loss_cls: 0.5051  loss_box_reg: 0.3972  loss_rpn_cls: 0.03407  loss_rpn_loc: 0.0311  time: 0.4318  data_time: 0.0102  lr: 0.0006993  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:39:34 d2.utils.events]: \u001b[0m eta: 1:40:16  iter: 719  total_loss: 0.869  loss_cls: 0.5011  loss_box_reg: 0.3268  loss_rpn_cls: 0.03275  loss_rpn_loc: 0.032  time: 0.4318  data_time: 0.0092  lr: 0.00071928  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:39:43 d2.utils.events]: \u001b[0m eta: 1:40:08  iter: 739  total_loss: 0.7721  loss_cls: 0.4305  loss_box_reg: 0.2667  loss_rpn_cls: 0.01757  loss_rpn_loc: 0.01816  time: 0.4318  data_time: 0.0102  lr: 0.00073926  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:39:52 d2.utils.events]: \u001b[0m eta: 1:39:59  iter: 759  total_loss: 0.8692  loss_cls: 0.5235  loss_box_reg: 0.3394  loss_rpn_cls: 0.02172  loss_rpn_loc: 0.02589  time: 0.4319  data_time: 0.0104  lr: 0.00075924  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:40:00 d2.utils.events]: \u001b[0m eta: 1:39:50  iter: 779  total_loss: 0.794  loss_cls: 0.4765  loss_box_reg: 0.2862  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.02025  time: 0.4319  data_time: 0.0102  lr: 0.00077922  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:40:09 d2.utils.events]: \u001b[0m eta: 1:39:42  iter: 799  total_loss: 0.8913  loss_cls: 0.4791  loss_box_reg: 0.3139  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.02018  time: 0.4321  data_time: 0.0094  lr: 0.0007992  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:40:18 d2.utils.events]: \u001b[0m eta: 1:39:32  iter: 819  total_loss: 0.8703  loss_cls: 0.4632  loss_box_reg: 0.2836  loss_rpn_cls: 0.03963  loss_rpn_loc: 0.04051  time: 0.4320  data_time: 0.0091  lr: 0.00081918  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:40:26 d2.utils.events]: \u001b[0m eta: 1:39:23  iter: 839  total_loss: 0.918  loss_cls: 0.5004  loss_box_reg: 0.3738  loss_rpn_cls: 0.02465  loss_rpn_loc: 0.02603  time: 0.4320  data_time: 0.0101  lr: 0.00083916  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:40:35 d2.utils.events]: \u001b[0m eta: 1:39:16  iter: 859  total_loss: 0.8714  loss_cls: 0.4907  loss_box_reg: 0.3246  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.02047  time: 0.4321  data_time: 0.0108  lr: 0.00085914  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:40:44 d2.utils.events]: \u001b[0m eta: 1:39:07  iter: 879  total_loss: 0.8924  loss_cls: 0.501  loss_box_reg: 0.3355  loss_rpn_cls: 0.02581  loss_rpn_loc: 0.03883  time: 0.4321  data_time: 0.0109  lr: 0.00087912  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:40:52 d2.utils.events]: \u001b[0m eta: 1:38:58  iter: 899  total_loss: 0.8134  loss_cls: 0.4549  loss_box_reg: 0.2917  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.02367  time: 0.4321  data_time: 0.0102  lr: 0.0008991  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:41:01 d2.utils.events]: \u001b[0m eta: 1:38:49  iter: 919  total_loss: 0.8063  loss_cls: 0.4508  loss_box_reg: 0.3069  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.02274  time: 0.4321  data_time: 0.0095  lr: 0.00091908  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:41:10 d2.utils.events]: \u001b[0m eta: 1:38:41  iter: 939  total_loss: 0.8895  loss_cls: 0.5114  loss_box_reg: 0.3338  loss_rpn_cls: 0.02405  loss_rpn_loc: 0.02416  time: 0.4321  data_time: 0.0105  lr: 0.00093906  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:41:19 d2.utils.events]: \u001b[0m eta: 1:38:33  iter: 959  total_loss: 0.8314  loss_cls: 0.4855  loss_box_reg: 0.3038  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.02098  time: 0.4321  data_time: 0.0110  lr: 0.00095904  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:41:27 d2.utils.events]: \u001b[0m eta: 1:38:25  iter: 979  total_loss: 0.7443  loss_cls: 0.4409  loss_box_reg: 0.2765  loss_rpn_cls: 0.02241  loss_rpn_loc: 0.01466  time: 0.4322  data_time: 0.0107  lr: 0.00097902  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:41:36 d2.utils.events]: \u001b[0m eta: 1:38:17  iter: 999  total_loss: 0.8718  loss_cls: 0.4588  loss_box_reg: 0.3173  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.03961  time: 0.4322  data_time: 0.0100  lr: 0.000999  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:41:45 d2.utils.events]: \u001b[0m eta: 1:38:09  iter: 1019  total_loss: 0.8048  loss_cls: 0.4503  loss_box_reg: 0.2825  loss_rpn_cls: 0.02867  loss_rpn_loc: 0.03593  time: 0.4322  data_time: 0.0099  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:41:53 d2.utils.events]: \u001b[0m eta: 1:38:01  iter: 1039  total_loss: 0.9024  loss_cls: 0.4815  loss_box_reg: 0.2975  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.02124  time: 0.4322  data_time: 0.0098  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:42:02 d2.utils.events]: \u001b[0m eta: 1:37:54  iter: 1059  total_loss: 0.8044  loss_cls: 0.4432  loss_box_reg: 0.3255  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.01625  time: 0.4322  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:42:11 d2.utils.events]: \u001b[0m eta: 1:37:46  iter: 1079  total_loss: 0.8715  loss_cls: 0.4833  loss_box_reg: 0.3311  loss_rpn_cls: 0.02755  loss_rpn_loc: 0.03058  time: 0.4322  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:42:19 d2.utils.events]: \u001b[0m eta: 1:37:37  iter: 1099  total_loss: 0.7122  loss_cls: 0.4417  loss_box_reg: 0.2338  loss_rpn_cls: 0.01834  loss_rpn_loc: 0.01622  time: 0.4322  data_time: 0.0099  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:42:28 d2.utils.events]: \u001b[0m eta: 1:37:29  iter: 1119  total_loss: 0.7851  loss_cls: 0.4525  loss_box_reg: 0.2786  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.01947  time: 0.4322  data_time: 0.0097  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:42:37 d2.utils.events]: \u001b[0m eta: 1:37:20  iter: 1139  total_loss: 0.7876  loss_cls: 0.4301  loss_box_reg: 0.2946  loss_rpn_cls: 0.02989  loss_rpn_loc: 0.02878  time: 0.4322  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:42:45 d2.utils.events]: \u001b[0m eta: 1:37:12  iter: 1159  total_loss: 0.885  loss_cls: 0.4107  loss_box_reg: 0.3511  loss_rpn_cls: 0.02949  loss_rpn_loc: 0.04065  time: 0.4322  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:42:54 d2.utils.events]: \u001b[0m eta: 1:37:04  iter: 1179  total_loss: 0.874  loss_cls: 0.5079  loss_box_reg: 0.3412  loss_rpn_cls: 0.01913  loss_rpn_loc: 0.0263  time: 0.4322  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:43:03 d2.utils.events]: \u001b[0m eta: 1:36:55  iter: 1199  total_loss: 0.8137  loss_cls: 0.434  loss_box_reg: 0.3023  loss_rpn_cls: 0.02099  loss_rpn_loc: 0.02134  time: 0.4322  data_time: 0.0098  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:43:11 d2.utils.events]: \u001b[0m eta: 1:36:47  iter: 1219  total_loss: 0.8782  loss_cls: 0.4547  loss_box_reg: 0.3247  loss_rpn_cls: 0.02628  loss_rpn_loc: 0.03291  time: 0.4322  data_time: 0.0101  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:43:12 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/private.json\n",
      "\u001b[32m[09/09 14:43:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 14:43:12 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 14:43:12 d2.data.common]: \u001b[0mSerialized dataset takes 2.16 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 14:43:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 14:43:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/09 14:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0007 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:03:17\n",
      "\u001b[32m[09/09 14:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 136/4871. Dataloading: 0.0009 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:03:10\n",
      "\u001b[32m[09/09 14:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 261/4871. Dataloading: 0.0009 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:03:05\n",
      "\u001b[32m[09/09 14:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 386/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:03:00\n",
      "\u001b[32m[09/09 14:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 511/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:55\n",
      "\u001b[32m[09/09 14:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 636/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:50\n",
      "\u001b[32m[09/09 14:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 761/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:43:48 d2.evaluation.evaluator]: \u001b[0mInference done 886/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/09 14:43:53 d2.evaluation.evaluator]: \u001b[0mInference done 1011/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:35\n",
      "\u001b[32m[09/09 14:43:58 d2.evaluation.evaluator]: \u001b[0mInference done 1136/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/09 14:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 1261/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/09 14:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 1384/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:20\n",
      "\u001b[32m[09/09 14:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 1509/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:15\n",
      "\u001b[32m[09/09 14:44:19 d2.evaluation.evaluator]: \u001b[0mInference done 1634/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/09 14:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 1758/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:05\n",
      "\u001b[32m[09/09 14:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 1882/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:00\n",
      "\u001b[32m[09/09 14:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 2007/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/09 14:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 2132/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:50\n",
      "\u001b[32m[09/09 14:44:44 d2.evaluation.evaluator]: \u001b[0mInference done 2256/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:45\n",
      "\u001b[32m[09/09 14:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 2381/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:40\n",
      "\u001b[32m[09/09 14:44:54 d2.evaluation.evaluator]: \u001b[0mInference done 2506/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:35\n",
      "\u001b[32m[09/09 14:44:59 d2.evaluation.evaluator]: \u001b[0mInference done 2631/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:30\n",
      "\u001b[32m[09/09 14:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 2756/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/09 14:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 2878/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:20\n",
      "\u001b[32m[09/09 14:45:14 d2.evaluation.evaluator]: \u001b[0mInference done 3002/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/09 14:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 3126/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:10\n",
      "\u001b[32m[09/09 14:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 3251/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/09 14:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 3376/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:00\n",
      "\u001b[32m[09/09 14:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 3501/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:55\n",
      "\u001b[32m[09/09 14:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 3626/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/09 14:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 3750/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:45\n",
      "\u001b[32m[09/09 14:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 3875/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:40\n",
      "\u001b[32m[09/09 14:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 3999/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/09 14:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 4124/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/09 14:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 4249/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:25\n",
      "\u001b[32m[09/09 14:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 4373/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:20\n",
      "\u001b[32m[09/09 14:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 4494/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:15\n",
      "\u001b[32m[09/09 14:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 4618/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/09 14:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 4742/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:05\n",
      "\u001b[32m[09/09 14:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 4867/4871. Dataloading: 0.0011 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/09 14:46:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:16.375068 (0.040357 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 14:46:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:09 (0.038987 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 14:46:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 14:46:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/09 14:46:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.49s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 14:46:31 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 14:46:33 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.02 seconds.\n",
      "\u001b[32m[09/09 14:46:33 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 14:46:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.35 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.236\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.259\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
      "\u001b[32m[09/09 14:46:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 21.352 | 30.961 | 23.558 | 0.244 | 4.547 | 25.916 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:46:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 10.201 | Paper       | 20.480 | Paper pack | 22.337 |\n",
      "| Metal         | 22.702 | Glass       | 23.800 | Plastic    | 15.475 |\n",
      "| Styrofoam     | 14.767 | Plastic bag | 43.894 | Battery    | 17.832 |\n",
      "| Clothing      | 22.029 |             |        |            |        |\n",
      "\u001b[32m[09/09 14:46:34 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/09 14:46:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 14:46:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 14:46:34 d2.evaluation.testing]: \u001b[0mcopypaste: 21.3518,30.9606,23.5582,0.2440,4.5475,25.9156\n",
      "\u001b[32m[09/09 14:46:42 d2.utils.events]: \u001b[0m eta: 1:36:38  iter: 1239  total_loss: 0.897  loss_cls: 0.5002  loss_box_reg: 0.3224  loss_rpn_cls: 0.0254  loss_rpn_loc: 0.03515  time: 0.4322  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:46:51 d2.utils.events]: \u001b[0m eta: 1:36:30  iter: 1259  total_loss: 0.6758  loss_cls: 0.4221  loss_box_reg: 0.2316  loss_rpn_cls: 0.02199  loss_rpn_loc: 0.02675  time: 0.4322  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:46:59 d2.utils.events]: \u001b[0m eta: 1:36:21  iter: 1279  total_loss: 0.9765  loss_cls: 0.5095  loss_box_reg: 0.3544  loss_rpn_cls: 0.03391  loss_rpn_loc: 0.03173  time: 0.4322  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:47:08 d2.utils.events]: \u001b[0m eta: 1:36:12  iter: 1299  total_loss: 0.7753  loss_cls: 0.4631  loss_box_reg: 0.2566  loss_rpn_cls: 0.02033  loss_rpn_loc: 0.03213  time: 0.4322  data_time: 0.0097  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:47:17 d2.utils.events]: \u001b[0m eta: 1:36:03  iter: 1319  total_loss: 0.8748  loss_cls: 0.4401  loss_box_reg: 0.3404  loss_rpn_cls: 0.03359  loss_rpn_loc: 0.02464  time: 0.4322  data_time: 0.0099  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:47:25 d2.utils.events]: \u001b[0m eta: 1:35:55  iter: 1339  total_loss: 0.8398  loss_cls: 0.4676  loss_box_reg: 0.2936  loss_rpn_cls: 0.03418  loss_rpn_loc: 0.03086  time: 0.4322  data_time: 0.0101  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:47:34 d2.utils.events]: \u001b[0m eta: 1:35:46  iter: 1359  total_loss: 0.7602  loss_cls: 0.4031  loss_box_reg: 0.3265  loss_rpn_cls: 0.02369  loss_rpn_loc: 0.0374  time: 0.4322  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:47:44 d2.utils.events]: \u001b[0m eta: 1:35:37  iter: 1379  total_loss: 0.9293  loss_cls: 0.4487  loss_box_reg: 0.3245  loss_rpn_cls: 0.03736  loss_rpn_loc: 0.03807  time: 0.4331  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:47:53 d2.utils.events]: \u001b[0m eta: 1:35:29  iter: 1399  total_loss: 0.7727  loss_cls: 0.4143  loss_box_reg: 0.2862  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.03085  time: 0.4331  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:48:01 d2.utils.events]: \u001b[0m eta: 1:35:21  iter: 1419  total_loss: 0.8662  loss_cls: 0.4748  loss_box_reg: 0.3104  loss_rpn_cls: 0.02608  loss_rpn_loc: 0.03058  time: 0.4331  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:48:10 d2.utils.events]: \u001b[0m eta: 1:35:11  iter: 1439  total_loss: 0.824  loss_cls: 0.4861  loss_box_reg: 0.3087  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.0216  time: 0.4331  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:48:19 d2.utils.events]: \u001b[0m eta: 1:35:02  iter: 1459  total_loss: 0.7164  loss_cls: 0.4049  loss_box_reg: 0.2419  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.01549  time: 0.4331  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:48:27 d2.utils.events]: \u001b[0m eta: 1:34:54  iter: 1479  total_loss: 0.7658  loss_cls: 0.4257  loss_box_reg: 0.2679  loss_rpn_cls: 0.01765  loss_rpn_loc: 0.02119  time: 0.4331  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:48:36 d2.utils.events]: \u001b[0m eta: 1:34:44  iter: 1499  total_loss: 0.7039  loss_cls: 0.417  loss_box_reg: 0.2439  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.02213  time: 0.4330  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:48:45 d2.utils.events]: \u001b[0m eta: 1:34:36  iter: 1519  total_loss: 0.7391  loss_cls: 0.4255  loss_box_reg: 0.2525  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.02102  time: 0.4330  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:48:53 d2.utils.events]: \u001b[0m eta: 1:34:27  iter: 1539  total_loss: 0.9033  loss_cls: 0.4369  loss_box_reg: 0.3796  loss_rpn_cls: 0.01852  loss_rpn_loc: 0.03756  time: 0.4330  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:49:02 d2.utils.events]: \u001b[0m eta: 1:34:18  iter: 1559  total_loss: 0.6697  loss_cls: 0.37  loss_box_reg: 0.2618  loss_rpn_cls: 0.02553  loss_rpn_loc: 0.01998  time: 0.4331  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:49:11 d2.utils.events]: \u001b[0m eta: 1:34:09  iter: 1579  total_loss: 0.7791  loss_cls: 0.4214  loss_box_reg: 0.2868  loss_rpn_cls: 0.02758  loss_rpn_loc: 0.03656  time: 0.4331  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:49:19 d2.utils.events]: \u001b[0m eta: 1:34:00  iter: 1599  total_loss: 0.8963  loss_cls: 0.4666  loss_box_reg: 0.344  loss_rpn_cls: 0.02961  loss_rpn_loc: 0.03322  time: 0.4330  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:49:28 d2.utils.events]: \u001b[0m eta: 1:33:52  iter: 1619  total_loss: 0.8563  loss_cls: 0.4372  loss_box_reg: 0.3246  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.03415  time: 0.4330  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:49:37 d2.utils.events]: \u001b[0m eta: 1:33:44  iter: 1639  total_loss: 0.6851  loss_cls: 0.3912  loss_box_reg: 0.2908  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.02165  time: 0.4330  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:49:45 d2.utils.events]: \u001b[0m eta: 1:33:35  iter: 1659  total_loss: 0.8043  loss_cls: 0.4465  loss_box_reg: 0.2678  loss_rpn_cls: 0.02313  loss_rpn_loc: 0.02169  time: 0.4330  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:49:54 d2.utils.events]: \u001b[0m eta: 1:33:26  iter: 1679  total_loss: 0.7523  loss_cls: 0.4298  loss_box_reg: 0.2949  loss_rpn_cls: 0.02382  loss_rpn_loc: 0.02614  time: 0.4330  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:50:03 d2.utils.events]: \u001b[0m eta: 1:33:17  iter: 1699  total_loss: 0.7808  loss_cls: 0.4041  loss_box_reg: 0.3275  loss_rpn_cls: 0.016  loss_rpn_loc: 0.02184  time: 0.4330  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:50:11 d2.utils.events]: \u001b[0m eta: 1:33:09  iter: 1719  total_loss: 0.8682  loss_cls: 0.4794  loss_box_reg: 0.2925  loss_rpn_cls: 0.02503  loss_rpn_loc: 0.03158  time: 0.4330  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:50:20 d2.utils.events]: \u001b[0m eta: 1:33:01  iter: 1739  total_loss: 0.8251  loss_cls: 0.4522  loss_box_reg: 0.3211  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.02739  time: 0.4330  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:50:29 d2.utils.events]: \u001b[0m eta: 1:32:52  iter: 1759  total_loss: 0.6717  loss_cls: 0.3872  loss_box_reg: 0.2414  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.0182  time: 0.4330  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:50:37 d2.utils.events]: \u001b[0m eta: 1:32:44  iter: 1779  total_loss: 0.7781  loss_cls: 0.4033  loss_box_reg: 0.2906  loss_rpn_cls: 0.02528  loss_rpn_loc: 0.03412  time: 0.4330  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:50:46 d2.utils.events]: \u001b[0m eta: 1:32:35  iter: 1799  total_loss: 0.8874  loss_cls: 0.4521  loss_box_reg: 0.3551  loss_rpn_cls: 0.02513  loss_rpn_loc: 0.02305  time: 0.4330  data_time: 0.0099  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:50:55 d2.utils.events]: \u001b[0m eta: 1:32:27  iter: 1819  total_loss: 0.8581  loss_cls: 0.4619  loss_box_reg: 0.3211  loss_rpn_cls: 0.03363  loss_rpn_loc: 0.03461  time: 0.4330  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:51:03 d2.utils.events]: \u001b[0m eta: 1:32:19  iter: 1839  total_loss: 0.7316  loss_cls: 0.402  loss_box_reg: 0.2929  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.01773  time: 0.4330  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:51:12 d2.utils.events]: \u001b[0m eta: 1:32:10  iter: 1859  total_loss: 0.7469  loss_cls: 0.3941  loss_box_reg: 0.2839  loss_rpn_cls: 0.02119  loss_rpn_loc: 0.02287  time: 0.4330  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:51:21 d2.utils.events]: \u001b[0m eta: 1:32:02  iter: 1879  total_loss: 0.7753  loss_cls: 0.4272  loss_box_reg: 0.3066  loss_rpn_cls: 0.02465  loss_rpn_loc: 0.03272  time: 0.4330  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:51:30 d2.utils.events]: \u001b[0m eta: 1:31:54  iter: 1899  total_loss: 0.8305  loss_cls: 0.4477  loss_box_reg: 0.287  loss_rpn_cls: 0.02144  loss_rpn_loc: 0.02659  time: 0.4330  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:51:38 d2.utils.events]: \u001b[0m eta: 1:31:46  iter: 1919  total_loss: 0.7794  loss_cls: 0.3892  loss_box_reg: 0.2829  loss_rpn_cls: 0.02657  loss_rpn_loc: 0.03776  time: 0.4330  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:51:47 d2.utils.events]: \u001b[0m eta: 1:31:37  iter: 1939  total_loss: 0.8256  loss_cls: 0.4624  loss_box_reg: 0.2903  loss_rpn_cls: 0.02636  loss_rpn_loc: 0.0354  time: 0.4330  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:51:56 d2.utils.events]: \u001b[0m eta: 1:31:28  iter: 1959  total_loss: 0.7174  loss_cls: 0.4281  loss_box_reg: 0.2623  loss_rpn_cls: 0.02694  loss_rpn_loc: 0.01996  time: 0.4330  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:52:04 d2.utils.events]: \u001b[0m eta: 1:31:19  iter: 1979  total_loss: 0.7254  loss_cls: 0.4098  loss_box_reg: 0.2329  loss_rpn_cls: 0.012  loss_rpn_loc: 0.0153  time: 0.4330  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:52:13 d2.utils.events]: \u001b[0m eta: 1:31:10  iter: 1999  total_loss: 0.8282  loss_cls: 0.4074  loss_box_reg: 0.3187  loss_rpn_cls: 0.01799  loss_rpn_loc: 0.02358  time: 0.4330  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:52:22 d2.utils.events]: \u001b[0m eta: 1:31:01  iter: 2019  total_loss: 0.798  loss_cls: 0.4532  loss_box_reg: 0.3399  loss_rpn_cls: 0.02869  loss_rpn_loc: 0.03138  time: 0.4330  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:52:30 d2.utils.events]: \u001b[0m eta: 1:30:53  iter: 2039  total_loss: 0.7617  loss_cls: 0.3998  loss_box_reg: 0.2448  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.02168  time: 0.4330  data_time: 0.0100  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:52:39 d2.utils.events]: \u001b[0m eta: 1:30:44  iter: 2059  total_loss: 0.8397  loss_cls: 0.4246  loss_box_reg: 0.2834  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.03143  time: 0.4330  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:52:48 d2.utils.events]: \u001b[0m eta: 1:30:36  iter: 2079  total_loss: 0.6479  loss_cls: 0.3464  loss_box_reg: 0.24  loss_rpn_cls: 0.01544  loss_rpn_loc: 0.02101  time: 0.4330  data_time: 0.0101  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:52:56 d2.utils.events]: \u001b[0m eta: 1:30:28  iter: 2099  total_loss: 0.6761  loss_cls: 0.3646  loss_box_reg: 0.2613  loss_rpn_cls: 0.01983  loss_rpn_loc: 0.02092  time: 0.4330  data_time: 0.0098  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:53:05 d2.utils.events]: \u001b[0m eta: 1:30:19  iter: 2119  total_loss: 0.7277  loss_cls: 0.4014  loss_box_reg: 0.2698  loss_rpn_cls: 0.02089  loss_rpn_loc: 0.02454  time: 0.4330  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:53:14 d2.utils.events]: \u001b[0m eta: 1:30:11  iter: 2139  total_loss: 0.8563  loss_cls: 0.4467  loss_box_reg: 0.3279  loss_rpn_cls: 0.02644  loss_rpn_loc: 0.03171  time: 0.4330  data_time: 0.0113  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:53:22 d2.utils.events]: \u001b[0m eta: 1:30:03  iter: 2159  total_loss: 0.8153  loss_cls: 0.4432  loss_box_reg: 0.343  loss_rpn_cls: 0.02631  loss_rpn_loc: 0.03066  time: 0.4330  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:53:31 d2.utils.events]: \u001b[0m eta: 1:29:54  iter: 2179  total_loss: 0.7413  loss_cls: 0.3837  loss_box_reg: 0.3082  loss_rpn_cls: 0.01971  loss_rpn_loc: 0.02718  time: 0.4330  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:53:40 d2.utils.events]: \u001b[0m eta: 1:29:46  iter: 2199  total_loss: 0.7368  loss_cls: 0.4629  loss_box_reg: 0.2404  loss_rpn_cls: 0.02543  loss_rpn_loc: 0.02158  time: 0.4330  data_time: 0.0100  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:53:49 d2.utils.events]: \u001b[0m eta: 1:29:37  iter: 2219  total_loss: 0.6513  loss_cls: 0.346  loss_box_reg: 0.2269  loss_rpn_cls: 0.01896  loss_rpn_loc: 0.0178  time: 0.4330  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:53:57 d2.utils.events]: \u001b[0m eta: 1:29:29  iter: 2239  total_loss: 0.7007  loss_cls: 0.4079  loss_box_reg: 0.2506  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.01852  time: 0.4330  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:54:06 d2.utils.events]: \u001b[0m eta: 1:29:20  iter: 2259  total_loss: 0.7292  loss_cls: 0.356  loss_box_reg: 0.2914  loss_rpn_cls: 0.02441  loss_rpn_loc: 0.01314  time: 0.4330  data_time: 0.0113  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:54:15 d2.utils.events]: \u001b[0m eta: 1:29:12  iter: 2279  total_loss: 0.702  loss_cls: 0.4083  loss_box_reg: 0.2879  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.02589  time: 0.4330  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:54:23 d2.utils.events]: \u001b[0m eta: 1:29:04  iter: 2299  total_loss: 0.6946  loss_cls: 0.4047  loss_box_reg: 0.2716  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.02549  time: 0.4330  data_time: 0.0100  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:54:32 d2.utils.events]: \u001b[0m eta: 1:28:55  iter: 2319  total_loss: 0.7345  loss_cls: 0.4024  loss_box_reg: 0.2925  loss_rpn_cls: 0.02333  loss_rpn_loc: 0.0268  time: 0.4330  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:54:41 d2.utils.events]: \u001b[0m eta: 1:28:47  iter: 2339  total_loss: 0.7179  loss_cls: 0.422  loss_box_reg: 0.2546  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.01492  time: 0.4330  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:54:49 d2.utils.events]: \u001b[0m eta: 1:28:39  iter: 2359  total_loss: 0.7533  loss_cls: 0.3987  loss_box_reg: 0.2743  loss_rpn_cls: 0.01735  loss_rpn_loc: 0.01813  time: 0.4330  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:54:58 d2.utils.events]: \u001b[0m eta: 1:28:30  iter: 2379  total_loss: 0.6034  loss_cls: 0.3718  loss_box_reg: 0.2182  loss_rpn_cls: 0.01882  loss_rpn_loc: 0.01508  time: 0.4330  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:55:07 d2.utils.events]: \u001b[0m eta: 1:28:21  iter: 2399  total_loss: 0.697  loss_cls: 0.3804  loss_box_reg: 0.2676  loss_rpn_cls: 0.02238  loss_rpn_loc: 0.02736  time: 0.4332  data_time: 0.0100  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:55:16 d2.utils.events]: \u001b[0m eta: 1:28:13  iter: 2419  total_loss: 0.7089  loss_cls: 0.3658  loss_box_reg: 0.2586  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.02049  time: 0.4332  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:55:24 d2.utils.events]: \u001b[0m eta: 1:28:05  iter: 2439  total_loss: 0.6803  loss_cls: 0.3849  loss_box_reg: 0.2613  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.0218  time: 0.4332  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:55:26 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/private.json\n",
      "\u001b[32m[09/09 14:55:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 14:55:26 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 14:55:26 d2.data.common]: \u001b[0mSerialized dataset takes 2.16 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 14:55:26 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 14:55:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/09 14:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0008 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:03:15\n",
      "\u001b[32m[09/09 14:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 128/4871. Dataloading: 0.0010 s/iter. Inference: 0.0415 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:03:22\n",
      "\u001b[32m[09/09 14:55:37 d2.evaluation.evaluator]: \u001b[0mInference done 237/4871. Dataloading: 0.0010 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0442 s/iter. ETA=0:03:24\n",
      "\u001b[32m[09/09 14:55:42 d2.evaluation.evaluator]: \u001b[0mInference done 362/4871. Dataloading: 0.0010 s/iter. Inference: 0.0415 s/iter. Eval: 0.0002 s/iter. Total: 0.0428 s/iter. ETA=0:03:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:55:47 d2.evaluation.evaluator]: \u001b[0mInference done 487/4871. Dataloading: 0.0010 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:03:04\n",
      "\u001b[32m[09/09 14:55:52 d2.evaluation.evaluator]: \u001b[0mInference done 610/4871. Dataloading: 0.0010 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:58\n",
      "\u001b[32m[09/09 14:55:57 d2.evaluation.evaluator]: \u001b[0mInference done 735/4871. Dataloading: 0.0010 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:51\n",
      "\u001b[32m[09/09 14:56:02 d2.evaluation.evaluator]: \u001b[0mInference done 860/4871. Dataloading: 0.0010 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/09 14:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 985/4871. Dataloading: 0.0010 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/09 14:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 1110/4871. Dataloading: 0.0010 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:34\n",
      "\u001b[32m[09/09 14:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 1235/4871. Dataloading: 0.0010 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:29\n",
      "\u001b[32m[09/09 14:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 1360/4871. Dataloading: 0.0010 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:23\n",
      "\u001b[32m[09/09 14:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 1485/4871. Dataloading: 0.0010 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:18\n",
      "\u001b[32m[09/09 14:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 1610/4871. Dataloading: 0.0010 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:13\n",
      "\u001b[32m[09/09 14:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 1735/4871. Dataloading: 0.0010 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:08\n",
      "\u001b[32m[09/09 14:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 1858/4871. Dataloading: 0.0010 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/09 14:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 1983/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:57\n",
      "\u001b[32m[09/09 14:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 2108/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:52\n",
      "\u001b[32m[09/09 14:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 2233/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:47\n",
      "\u001b[32m[09/09 14:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 2358/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:42\n",
      "\u001b[32m[09/09 14:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 2483/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/09 14:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 2608/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:31\n",
      "\u001b[32m[09/09 14:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 2733/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:26\n",
      "\u001b[32m[09/09 14:57:22 d2.evaluation.evaluator]: \u001b[0mInference done 2858/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:21\n",
      "\u001b[32m[09/09 14:57:27 d2.evaluation.evaluator]: \u001b[0mInference done 2983/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:16\n",
      "\u001b[32m[09/09 14:57:32 d2.evaluation.evaluator]: \u001b[0mInference done 3108/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/09 14:57:37 d2.evaluation.evaluator]: \u001b[0mInference done 3230/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:06\n",
      "\u001b[32m[09/09 14:57:42 d2.evaluation.evaluator]: \u001b[0mInference done 3354/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:01\n",
      "\u001b[32m[09/09 14:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 3478/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:56\n",
      "\u001b[32m[09/09 14:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 3602/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:51\n",
      "\u001b[32m[09/09 14:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 3727/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:46\n",
      "\u001b[32m[09/09 14:58:03 d2.evaluation.evaluator]: \u001b[0mInference done 3852/4871. Dataloading: 0.0010 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:41\n",
      "\u001b[32m[09/09 14:58:08 d2.evaluation.evaluator]: \u001b[0mInference done 3977/4871. Dataloading: 0.0011 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/09 14:58:13 d2.evaluation.evaluator]: \u001b[0mInference done 4101/4871. Dataloading: 0.0011 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/09 14:58:18 d2.evaluation.evaluator]: \u001b[0mInference done 4226/4871. Dataloading: 0.0011 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/09 14:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 4351/4871. Dataloading: 0.0011 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/09 14:58:28 d2.evaluation.evaluator]: \u001b[0mInference done 4476/4871. Dataloading: 0.0011 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/09 14:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 4601/4871. Dataloading: 0.0011 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/09 14:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 4726/4871. Dataloading: 0.0011 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:00:05\n",
      "\u001b[32m[09/09 14:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 4847/4871. Dataloading: 0.0011 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/09 14:58:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:17.277213 (0.040542 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 14:58:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:10 (0.039179 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 14:58:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 14:58:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/09 14:58:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 14:58:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 14:58:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.11 seconds.\n",
      "\u001b[32m[09/09 14:58:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 14:58:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.37 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.290\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.573\n",
      "\u001b[32m[09/09 14:58:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 26.574 | 38.420 | 29.038 | 0.329 | 6.861 | 32.049 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 14:58:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 12.150 | Paper       | 22.348 | Paper pack | 28.339 |\n",
      "| Metal         | 24.791 | Glass       | 28.911 | Plastic    | 18.853 |\n",
      "| Styrofoam     | 25.212 | Plastic bag | 46.036 | Battery    | 33.110 |\n",
      "| Clothing      | 25.988 |             |        |            |        |\n",
      "\u001b[32m[09/09 14:58:48 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/09 14:58:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 14:58:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 14:58:48 d2.evaluation.testing]: \u001b[0mcopypaste: 26.5738,38.4197,29.0381,0.3285,6.8610,32.0492\n",
      "\u001b[32m[09/09 14:58:56 d2.utils.events]: \u001b[0m eta: 1:27:56  iter: 2459  total_loss: 0.6839  loss_cls: 0.3843  loss_box_reg: 0.2896  loss_rpn_cls: 0.02092  loss_rpn_loc: 0.02125  time: 0.4332  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:59:05 d2.utils.events]: \u001b[0m eta: 1:27:47  iter: 2479  total_loss: 0.6602  loss_cls: 0.3301  loss_box_reg: 0.2665  loss_rpn_cls: 0.02118  loss_rpn_loc: 0.02589  time: 0.4332  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:59:14 d2.utils.events]: \u001b[0m eta: 1:27:38  iter: 2499  total_loss: 0.7109  loss_cls: 0.3823  loss_box_reg: 0.2871  loss_rpn_cls: 0.02375  loss_rpn_loc: 0.01908  time: 0.4332  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:59:22 d2.utils.events]: \u001b[0m eta: 1:27:30  iter: 2519  total_loss: 0.7918  loss_cls: 0.3931  loss_box_reg: 0.312  loss_rpn_cls: 0.02041  loss_rpn_loc: 0.03068  time: 0.4332  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:59:31 d2.utils.events]: \u001b[0m eta: 1:27:21  iter: 2539  total_loss: 0.7085  loss_cls: 0.3954  loss_box_reg: 0.2586  loss_rpn_cls: 0.0176  loss_rpn_loc: 0.02407  time: 0.4332  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:59:40 d2.utils.events]: \u001b[0m eta: 1:27:13  iter: 2559  total_loss: 0.6597  loss_cls: 0.3537  loss_box_reg: 0.2293  loss_rpn_cls: 0.01524  loss_rpn_loc: 0.02411  time: 0.4333  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:59:50 d2.utils.events]: \u001b[0m eta: 1:27:04  iter: 2579  total_loss: 0.6431  loss_cls: 0.3584  loss_box_reg: 0.2642  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.01994  time: 0.4340  data_time: 0.0099  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 14:59:59 d2.utils.events]: \u001b[0m eta: 1:26:55  iter: 2599  total_loss: 0.6918  loss_cls: 0.3783  loss_box_reg: 0.2817  loss_rpn_cls: 0.01989  loss_rpn_loc: 0.02491  time: 0.4340  data_time: 0.0100  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:00:08 d2.utils.events]: \u001b[0m eta: 1:26:47  iter: 2619  total_loss: 0.7822  loss_cls: 0.4203  loss_box_reg: 0.2695  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.02537  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:00:17 d2.utils.events]: \u001b[0m eta: 1:26:39  iter: 2639  total_loss: 0.6954  loss_cls: 0.3794  loss_box_reg: 0.2624  loss_rpn_cls: 0.02158  loss_rpn_loc: 0.02059  time: 0.4340  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:00:25 d2.utils.events]: \u001b[0m eta: 1:26:30  iter: 2659  total_loss: 0.6609  loss_cls: 0.3642  loss_box_reg: 0.2471  loss_rpn_cls: 0.01663  loss_rpn_loc: 0.01811  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:00:34 d2.utils.events]: \u001b[0m eta: 1:26:22  iter: 2679  total_loss: 0.7128  loss_cls: 0.4225  loss_box_reg: 0.2361  loss_rpn_cls: 0.02499  loss_rpn_loc: 0.03486  time: 0.4340  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:00:43 d2.utils.events]: \u001b[0m eta: 1:26:14  iter: 2699  total_loss: 0.7141  loss_cls: 0.37  loss_box_reg: 0.252  loss_rpn_cls: 0.01654  loss_rpn_loc: 0.02363  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:00:51 d2.utils.events]: \u001b[0m eta: 1:26:05  iter: 2719  total_loss: 0.6249  loss_cls: 0.3312  loss_box_reg: 0.2728  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.01987  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:01:00 d2.utils.events]: \u001b[0m eta: 1:25:57  iter: 2739  total_loss: 0.7009  loss_cls: 0.3694  loss_box_reg: 0.2481  loss_rpn_cls: 0.02474  loss_rpn_loc: 0.02634  time: 0.4340  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:01:09 d2.utils.events]: \u001b[0m eta: 1:25:49  iter: 2759  total_loss: 0.6627  loss_cls: 0.3652  loss_box_reg: 0.2247  loss_rpn_cls: 0.0192  loss_rpn_loc: 0.02673  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:01:17 d2.utils.events]: \u001b[0m eta: 1:25:40  iter: 2779  total_loss: 0.7299  loss_cls: 0.3745  loss_box_reg: 0.2698  loss_rpn_cls: 0.02835  loss_rpn_loc: 0.02748  time: 0.4340  data_time: 0.0113  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:01:26 d2.utils.events]: \u001b[0m eta: 1:25:32  iter: 2799  total_loss: 0.7258  loss_cls: 0.4033  loss_box_reg: 0.2861  loss_rpn_cls: 0.02191  loss_rpn_loc: 0.02268  time: 0.4340  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:01:35 d2.utils.events]: \u001b[0m eta: 1:25:24  iter: 2819  total_loss: 0.7992  loss_cls: 0.4451  loss_box_reg: 0.2948  loss_rpn_cls: 0.01841  loss_rpn_loc: 0.02525  time: 0.4340  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:01:44 d2.utils.events]: \u001b[0m eta: 1:25:15  iter: 2839  total_loss: 0.8085  loss_cls: 0.4425  loss_box_reg: 0.2853  loss_rpn_cls: 0.02346  loss_rpn_loc: 0.04356  time: 0.4340  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:01:52 d2.utils.events]: \u001b[0m eta: 1:25:07  iter: 2859  total_loss: 0.7387  loss_cls: 0.4109  loss_box_reg: 0.2489  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.02056  time: 0.4340  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:02:01 d2.utils.events]: \u001b[0m eta: 1:24:58  iter: 2879  total_loss: 0.6859  loss_cls: 0.3538  loss_box_reg: 0.299  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.02866  time: 0.4340  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:02:10 d2.utils.events]: \u001b[0m eta: 1:24:49  iter: 2899  total_loss: 0.8059  loss_cls: 0.3859  loss_box_reg: 0.2769  loss_rpn_cls: 0.02382  loss_rpn_loc: 0.02423  time: 0.4340  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:02:18 d2.utils.events]: \u001b[0m eta: 1:24:40  iter: 2919  total_loss: 0.5787  loss_cls: 0.3316  loss_box_reg: 0.2459  loss_rpn_cls: 0.01715  loss_rpn_loc: 0.0197  time: 0.4340  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:02:27 d2.utils.events]: \u001b[0m eta: 1:24:32  iter: 2939  total_loss: 0.7287  loss_cls: 0.3979  loss_box_reg: 0.2488  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.0244  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:02:36 d2.utils.events]: \u001b[0m eta: 1:24:23  iter: 2959  total_loss: 0.7516  loss_cls: 0.4145  loss_box_reg: 0.2354  loss_rpn_cls: 0.0233  loss_rpn_loc: 0.02347  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:02:45 d2.utils.events]: \u001b[0m eta: 1:24:15  iter: 2979  total_loss: 0.7405  loss_cls: 0.4104  loss_box_reg: 0.2904  loss_rpn_cls: 0.01365  loss_rpn_loc: 0.01402  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:02:53 d2.utils.events]: \u001b[0m eta: 1:24:07  iter: 2999  total_loss: 0.7607  loss_cls: 0.4387  loss_box_reg: 0.2779  loss_rpn_cls: 0.0217  loss_rpn_loc: 0.03395  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:03:02 d2.utils.events]: \u001b[0m eta: 1:23:59  iter: 3019  total_loss: 0.7846  loss_cls: 0.4465  loss_box_reg: 0.3287  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.02752  time: 0.4340  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:03:11 d2.utils.events]: \u001b[0m eta: 1:23:50  iter: 3039  total_loss: 0.6449  loss_cls: 0.3783  loss_box_reg: 0.2547  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.02816  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:03:19 d2.utils.events]: \u001b[0m eta: 1:23:42  iter: 3059  total_loss: 0.6638  loss_cls: 0.374  loss_box_reg: 0.2583  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.0274  time: 0.4340  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:03:28 d2.utils.events]: \u001b[0m eta: 1:23:33  iter: 3079  total_loss: 0.725  loss_cls: 0.3926  loss_box_reg: 0.2742  loss_rpn_cls: 0.02287  loss_rpn_loc: 0.03148  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:03:37 d2.utils.events]: \u001b[0m eta: 1:23:25  iter: 3099  total_loss: 0.7457  loss_cls: 0.4092  loss_box_reg: 0.2511  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.0304  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:03:45 d2.utils.events]: \u001b[0m eta: 1:23:16  iter: 3119  total_loss: 0.7866  loss_cls: 0.4304  loss_box_reg: 0.3071  loss_rpn_cls: 0.0257  loss_rpn_loc: 0.02789  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:03:54 d2.utils.events]: \u001b[0m eta: 1:23:07  iter: 3139  total_loss: 0.795  loss_cls: 0.4109  loss_box_reg: 0.2858  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.03941  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:04:03 d2.utils.events]: \u001b[0m eta: 1:22:59  iter: 3159  total_loss: 0.7573  loss_cls: 0.4116  loss_box_reg: 0.2503  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.04413  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:04:12 d2.utils.events]: \u001b[0m eta: 1:22:50  iter: 3179  total_loss: 0.6573  loss_cls: 0.3243  loss_box_reg: 0.2417  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.0283  time: 0.4340  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:04:20 d2.utils.events]: \u001b[0m eta: 1:22:42  iter: 3199  total_loss: 0.63  loss_cls: 0.3571  loss_box_reg: 0.245  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.01339  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:04:29 d2.utils.events]: \u001b[0m eta: 1:22:33  iter: 3219  total_loss: 0.7462  loss_cls: 0.363  loss_box_reg: 0.3107  loss_rpn_cls: 0.01689  loss_rpn_loc: 0.02388  time: 0.4340  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:04:38 d2.utils.events]: \u001b[0m eta: 1:22:25  iter: 3239  total_loss: 0.65  loss_cls: 0.3517  loss_box_reg: 0.2444  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.02884  time: 0.4340  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:04:47 d2.utils.events]: \u001b[0m eta: 1:22:16  iter: 3259  total_loss: 0.6114  loss_cls: 0.2931  loss_box_reg: 0.2625  loss_rpn_cls: 0.02103  loss_rpn_loc: 0.0223  time: 0.4340  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:04:59 d2.utils.events]: \u001b[0m eta: 1:22:08  iter: 3279  total_loss: 0.6129  loss_cls: 0.3609  loss_box_reg: 0.206  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.0152  time: 0.4351  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:05:14 d2.utils.events]: \u001b[0m eta: 1:22:00  iter: 3299  total_loss: 0.792  loss_cls: 0.4561  loss_box_reg: 0.2861  loss_rpn_cls: 0.02097  loss_rpn_loc: 0.02791  time: 0.4372  data_time: 0.0101  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:05:23 d2.utils.events]: \u001b[0m eta: 1:21:52  iter: 3319  total_loss: 0.6577  loss_cls: 0.3499  loss_box_reg: 0.2452  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.01674  time: 0.4373  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:05:32 d2.utils.events]: \u001b[0m eta: 1:21:43  iter: 3339  total_loss: 0.6613  loss_cls: 0.3547  loss_box_reg: 0.2268  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.02355  time: 0.4372  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:05:41 d2.utils.events]: \u001b[0m eta: 1:21:35  iter: 3359  total_loss: 0.6928  loss_cls: 0.3675  loss_box_reg: 0.2736  loss_rpn_cls: 0.02349  loss_rpn_loc: 0.03082  time: 0.4372  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:05:50 d2.utils.events]: \u001b[0m eta: 1:21:27  iter: 3379  total_loss: 0.6326  loss_cls: 0.3231  loss_box_reg: 0.2493  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.0276  time: 0.4372  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:05:58 d2.utils.events]: \u001b[0m eta: 1:21:18  iter: 3399  total_loss: 0.6931  loss_cls: 0.3378  loss_box_reg: 0.2725  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.03725  time: 0.4372  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:06:07 d2.utils.events]: \u001b[0m eta: 1:21:09  iter: 3419  total_loss: 0.7637  loss_cls: 0.3971  loss_box_reg: 0.2831  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.03433  time: 0.4372  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:06:16 d2.utils.events]: \u001b[0m eta: 1:21:01  iter: 3439  total_loss: 0.622  loss_cls: 0.3755  loss_box_reg: 0.2452  loss_rpn_cls: 0.01652  loss_rpn_loc: 0.01737  time: 0.4371  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:06:24 d2.utils.events]: \u001b[0m eta: 1:20:52  iter: 3459  total_loss: 0.7044  loss_cls: 0.3927  loss_box_reg: 0.2692  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.02286  time: 0.4371  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:06:33 d2.utils.events]: \u001b[0m eta: 1:20:43  iter: 3479  total_loss: 0.6346  loss_cls: 0.3759  loss_box_reg: 0.2405  loss_rpn_cls: 0.02001  loss_rpn_loc: 0.02103  time: 0.4371  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:06:42 d2.utils.events]: \u001b[0m eta: 1:20:35  iter: 3499  total_loss: 0.7834  loss_cls: 0.4219  loss_box_reg: 0.2794  loss_rpn_cls: 0.02242  loss_rpn_loc: 0.02376  time: 0.4371  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:06:50 d2.utils.events]: \u001b[0m eta: 1:20:26  iter: 3519  total_loss: 0.6978  loss_cls: 0.3766  loss_box_reg: 0.2596  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.0196  time: 0.4370  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:06:59 d2.utils.events]: \u001b[0m eta: 1:20:18  iter: 3539  total_loss: 0.7288  loss_cls: 0.4021  loss_box_reg: 0.2525  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.02323  time: 0.4370  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:07:08 d2.utils.events]: \u001b[0m eta: 1:20:09  iter: 3559  total_loss: 0.7827  loss_cls: 0.3764  loss_box_reg: 0.2703  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.03018  time: 0.4370  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:07:16 d2.utils.events]: \u001b[0m eta: 1:20:00  iter: 3579  total_loss: 0.7145  loss_cls: 0.378  loss_box_reg: 0.2785  loss_rpn_cls: 0.01888  loss_rpn_loc: 0.02788  time: 0.4370  data_time: 0.0113  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:07:25 d2.utils.events]: \u001b[0m eta: 1:19:52  iter: 3599  total_loss: 0.5896  loss_cls: 0.3497  loss_box_reg: 0.2214  loss_rpn_cls: 0.01779  loss_rpn_loc: 0.01426  time: 0.4370  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:07:34 d2.utils.events]: \u001b[0m eta: 1:19:43  iter: 3619  total_loss: 0.835  loss_cls: 0.4239  loss_box_reg: 0.2827  loss_rpn_cls: 0.02108  loss_rpn_loc: 0.05519  time: 0.4369  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:07:42 d2.utils.events]: \u001b[0m eta: 1:19:34  iter: 3639  total_loss: 0.5716  loss_cls: 0.2926  loss_box_reg: 0.2552  loss_rpn_cls: 0.01568  loss_rpn_loc: 0.02133  time: 0.4369  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:07:51 d2.utils.events]: \u001b[0m eta: 1:19:25  iter: 3659  total_loss: 0.7086  loss_cls: 0.3804  loss_box_reg: 0.3016  loss_rpn_cls: 0.01747  loss_rpn_loc: 0.02527  time: 0.4369  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:07:53 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/private.json\n",
      "\u001b[32m[09/09 15:07:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 15:07:53 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 15:07:53 d2.data.common]: \u001b[0mSerialized dataset takes 2.16 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 15:07:53 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 15:07:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/09 15:07:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0007 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:03:16\n",
      "\u001b[32m[09/09 15:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 136/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:03:10\n",
      "\u001b[32m[09/09 15:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 261/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:03:05\n",
      "\u001b[32m[09/09 15:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 386/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:03:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 510/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:55\n",
      "\u001b[32m[09/09 15:08:19 d2.evaluation.evaluator]: \u001b[0mInference done 634/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:50\n",
      "\u001b[32m[09/09 15:08:24 d2.evaluation.evaluator]: \u001b[0mInference done 759/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:45\n",
      "\u001b[32m[09/09 15:08:29 d2.evaluation.evaluator]: \u001b[0mInference done 884/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/09 15:08:34 d2.evaluation.evaluator]: \u001b[0mInference done 1009/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:35\n",
      "\u001b[32m[09/09 15:08:39 d2.evaluation.evaluator]: \u001b[0mInference done 1133/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/09 15:08:44 d2.evaluation.evaluator]: \u001b[0mInference done 1258/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/09 15:08:49 d2.evaluation.evaluator]: \u001b[0mInference done 1383/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:20\n",
      "\u001b[32m[09/09 15:08:54 d2.evaluation.evaluator]: \u001b[0mInference done 1508/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:15\n",
      "\u001b[32m[09/09 15:08:59 d2.evaluation.evaluator]: \u001b[0mInference done 1633/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/09 15:09:04 d2.evaluation.evaluator]: \u001b[0mInference done 1758/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:05\n",
      "\u001b[32m[09/09 15:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 1883/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:00\n",
      "\u001b[32m[09/09 15:09:14 d2.evaluation.evaluator]: \u001b[0mInference done 2008/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/09 15:09:19 d2.evaluation.evaluator]: \u001b[0mInference done 2133/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:50\n",
      "\u001b[32m[09/09 15:09:24 d2.evaluation.evaluator]: \u001b[0mInference done 2258/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:45\n",
      "\u001b[32m[09/09 15:09:29 d2.evaluation.evaluator]: \u001b[0mInference done 2381/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:40\n",
      "\u001b[32m[09/09 15:09:34 d2.evaluation.evaluator]: \u001b[0mInference done 2506/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:35\n",
      "\u001b[32m[09/09 15:09:39 d2.evaluation.evaluator]: \u001b[0mInference done 2631/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:30\n",
      "\u001b[32m[09/09 15:09:44 d2.evaluation.evaluator]: \u001b[0mInference done 2756/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/09 15:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 2881/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:20\n",
      "\u001b[32m[09/09 15:09:55 d2.evaluation.evaluator]: \u001b[0mInference done 3006/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/09 15:10:00 d2.evaluation.evaluator]: \u001b[0mInference done 3131/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:10\n",
      "\u001b[32m[09/09 15:10:05 d2.evaluation.evaluator]: \u001b[0mInference done 3256/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/09 15:10:10 d2.evaluation.evaluator]: \u001b[0mInference done 3379/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:00\n",
      "\u001b[32m[09/09 15:10:15 d2.evaluation.evaluator]: \u001b[0mInference done 3504/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:55\n",
      "\u001b[32m[09/09 15:10:20 d2.evaluation.evaluator]: \u001b[0mInference done 3629/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/09 15:10:25 d2.evaluation.evaluator]: \u001b[0mInference done 3754/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:44\n",
      "\u001b[32m[09/09 15:10:30 d2.evaluation.evaluator]: \u001b[0mInference done 3879/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:39\n",
      "\u001b[32m[09/09 15:10:35 d2.evaluation.evaluator]: \u001b[0mInference done 4004/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:34\n",
      "\u001b[32m[09/09 15:10:40 d2.evaluation.evaluator]: \u001b[0mInference done 4129/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:29\n",
      "\u001b[32m[09/09 15:10:45 d2.evaluation.evaluator]: \u001b[0mInference done 4253/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:24\n",
      "\u001b[32m[09/09 15:10:50 d2.evaluation.evaluator]: \u001b[0mInference done 4378/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:19\n",
      "\u001b[32m[09/09 15:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 4503/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:14\n",
      "\u001b[32m[09/09 15:11:00 d2.evaluation.evaluator]: \u001b[0mInference done 4627/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:09\n",
      "\u001b[32m[09/09 15:11:05 d2.evaluation.evaluator]: \u001b[0mInference done 4751/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:04\n",
      "\u001b[32m[09/09 15:11:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:16.211401 (0.040323 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 15:11:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:09 (0.039041 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 15:11:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 15:11:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/09 15:11:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.43s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 15:11:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 15:11:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.78 seconds.\n",
      "\u001b[32m[09/09 15:11:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 15:11:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.29 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.403\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.343\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.461\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.191\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n",
      "\u001b[32m[09/09 15:11:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 28.677 | 40.265 | 30.803 | 0.437 | 7.486 | 34.281 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:11:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 15.696 | Paper       | 24.437 | Paper pack | 30.314 |\n",
      "| Metal         | 30.173 | Glass       | 29.844 | Plastic    | 19.933 |\n",
      "| Styrofoam     | 25.954 | Plastic bag | 47.139 | Battery    | 34.644 |\n",
      "| Clothing      | 28.634 |             |        |            |        |\n",
      "\u001b[32m[09/09 15:11:13 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/09 15:11:14 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 15:11:14 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 15:11:14 d2.evaluation.testing]: \u001b[0mcopypaste: 28.6768,40.2653,30.8030,0.4368,7.4862,34.2808\n",
      "\u001b[32m[09/09 15:11:21 d2.utils.events]: \u001b[0m eta: 1:19:17  iter: 3679  total_loss: 0.7044  loss_cls: 0.4085  loss_box_reg: 0.2893  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.02088  time: 0.4369  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:11:30 d2.utils.events]: \u001b[0m eta: 1:19:08  iter: 3699  total_loss: 0.6111  loss_cls: 0.357  loss_box_reg: 0.2328  loss_rpn_cls: 0.01911  loss_rpn_loc: 0.029  time: 0.4369  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:11:38 d2.utils.events]: \u001b[0m eta: 1:18:59  iter: 3719  total_loss: 0.5718  loss_cls: 0.3207  loss_box_reg: 0.2328  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.01387  time: 0.4368  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:11:47 d2.utils.events]: \u001b[0m eta: 1:18:50  iter: 3739  total_loss: 0.6784  loss_cls: 0.3369  loss_box_reg: 0.2763  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.02773  time: 0.4368  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:11:56 d2.utils.events]: \u001b[0m eta: 1:18:41  iter: 3759  total_loss: 0.6679  loss_cls: 0.3846  loss_box_reg: 0.2383  loss_rpn_cls: 0.015  loss_rpn_loc: 0.0196  time: 0.4368  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:12:04 d2.utils.events]: \u001b[0m eta: 1:18:32  iter: 3779  total_loss: 0.5992  loss_cls: 0.3071  loss_box_reg: 0.2343  loss_rpn_cls: 0.01703  loss_rpn_loc: 0.01925  time: 0.4368  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:12:13 d2.utils.events]: \u001b[0m eta: 1:18:23  iter: 3799  total_loss: 0.606  loss_cls: 0.3077  loss_box_reg: 0.2197  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.02218  time: 0.4367  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:12:22 d2.utils.events]: \u001b[0m eta: 1:18:14  iter: 3819  total_loss: 0.6369  loss_cls: 0.3569  loss_box_reg: 0.2448  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.0235  time: 0.4367  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:12:30 d2.utils.events]: \u001b[0m eta: 1:18:06  iter: 3839  total_loss: 0.6744  loss_cls: 0.3627  loss_box_reg: 0.3  loss_rpn_cls: 0.02371  loss_rpn_loc: 0.04111  time: 0.4367  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:12:39 d2.utils.events]: \u001b[0m eta: 1:17:57  iter: 3859  total_loss: 0.7132  loss_cls: 0.3769  loss_box_reg: 0.2773  loss_rpn_cls: 0.0252  loss_rpn_loc: 0.03092  time: 0.4367  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:12:48 d2.utils.events]: \u001b[0m eta: 1:17:49  iter: 3879  total_loss: 0.6737  loss_cls: 0.3589  loss_box_reg: 0.2482  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.02994  time: 0.4367  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:12:56 d2.utils.events]: \u001b[0m eta: 1:17:40  iter: 3899  total_loss: 0.6386  loss_cls: 0.3605  loss_box_reg: 0.2474  loss_rpn_cls: 0.0166  loss_rpn_loc: 0.02053  time: 0.4366  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:13:05 d2.utils.events]: \u001b[0m eta: 1:17:31  iter: 3919  total_loss: 0.6465  loss_cls: 0.3408  loss_box_reg: 0.2433  loss_rpn_cls: 0.01708  loss_rpn_loc: 0.02451  time: 0.4366  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:13:14 d2.utils.events]: \u001b[0m eta: 1:17:22  iter: 3939  total_loss: 0.6207  loss_cls: 0.3376  loss_box_reg: 0.2496  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.03034  time: 0.4366  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:13:22 d2.utils.events]: \u001b[0m eta: 1:17:13  iter: 3959  total_loss: 0.7077  loss_cls: 0.3632  loss_box_reg: 0.2918  loss_rpn_cls: 0.02223  loss_rpn_loc: 0.02803  time: 0.4366  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:13:31 d2.utils.events]: \u001b[0m eta: 1:17:05  iter: 3979  total_loss: 0.5124  loss_cls: 0.2927  loss_box_reg: 0.1863  loss_rpn_cls: 0.007139  loss_rpn_loc: 0.01067  time: 0.4366  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:13:40 d2.utils.events]: \u001b[0m eta: 1:16:56  iter: 3999  total_loss: 0.6338  loss_cls: 0.3375  loss_box_reg: 0.24  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.01706  time: 0.4366  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:13:49 d2.utils.events]: \u001b[0m eta: 1:16:47  iter: 4019  total_loss: 0.6246  loss_cls: 0.3337  loss_box_reg: 0.2519  loss_rpn_cls: 0.009557  loss_rpn_loc: 0.02127  time: 0.4366  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:13:57 d2.utils.events]: \u001b[0m eta: 1:16:39  iter: 4039  total_loss: 0.5519  loss_cls: 0.3204  loss_box_reg: 0.2333  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.01543  time: 0.4365  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:14:06 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 4059  total_loss: 0.6345  loss_cls: 0.3224  loss_box_reg: 0.2517  loss_rpn_cls: 0.01722  loss_rpn_loc: 0.02282  time: 0.4365  data_time: 0.0114  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:14:15 d2.utils.events]: \u001b[0m eta: 1:16:21  iter: 4079  total_loss: 0.5996  loss_cls: 0.3412  loss_box_reg: 0.2378  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.0126  time: 0.4365  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:14:23 d2.utils.events]: \u001b[0m eta: 1:16:13  iter: 4099  total_loss: 0.6815  loss_cls: 0.3763  loss_box_reg: 0.2391  loss_rpn_cls: 0.01984  loss_rpn_loc: 0.02429  time: 0.4365  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:14:32 d2.utils.events]: \u001b[0m eta: 1:16:04  iter: 4119  total_loss: 0.6954  loss_cls: 0.4157  loss_box_reg: 0.2121  loss_rpn_cls: 0.0166  loss_rpn_loc: 0.01805  time: 0.4365  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:14:41 d2.utils.events]: \u001b[0m eta: 1:15:55  iter: 4139  total_loss: 0.6003  loss_cls: 0.3296  loss_box_reg: 0.1957  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.01971  time: 0.4365  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:14:49 d2.utils.events]: \u001b[0m eta: 1:15:46  iter: 4159  total_loss: 0.6597  loss_cls: 0.3237  loss_box_reg: 0.2494  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.01695  time: 0.4365  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:14:58 d2.utils.events]: \u001b[0m eta: 1:15:37  iter: 4179  total_loss: 0.6828  loss_cls: 0.348  loss_box_reg: 0.2656  loss_rpn_cls: 0.01988  loss_rpn_loc: 0.02951  time: 0.4364  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:15:07 d2.utils.events]: \u001b[0m eta: 1:15:28  iter: 4199  total_loss: 0.5337  loss_cls: 0.2998  loss_box_reg: 0.217  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.01513  time: 0.4364  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:15:15 d2.utils.events]: \u001b[0m eta: 1:15:19  iter: 4219  total_loss: 0.5711  loss_cls: 0.331  loss_box_reg: 0.2183  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.02345  time: 0.4364  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:15:24 d2.utils.events]: \u001b[0m eta: 1:15:10  iter: 4239  total_loss: 0.6876  loss_cls: 0.3729  loss_box_reg: 0.2883  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.0392  time: 0.4364  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:15:33 d2.utils.events]: \u001b[0m eta: 1:15:01  iter: 4259  total_loss: 0.8106  loss_cls: 0.4015  loss_box_reg: 0.3356  loss_rpn_cls: 0.0265  loss_rpn_loc: 0.0288  time: 0.4364  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:15:41 d2.utils.events]: \u001b[0m eta: 1:14:52  iter: 4279  total_loss: 0.6829  loss_cls: 0.355  loss_box_reg: 0.2495  loss_rpn_cls: 0.01617  loss_rpn_loc: 0.032  time: 0.4364  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:15:50 d2.utils.events]: \u001b[0m eta: 1:14:42  iter: 4299  total_loss: 0.5932  loss_cls: 0.304  loss_box_reg: 0.2535  loss_rpn_cls: 0.02338  loss_rpn_loc: 0.02014  time: 0.4363  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:15:59 d2.utils.events]: \u001b[0m eta: 1:14:33  iter: 4319  total_loss: 0.6219  loss_cls: 0.3586  loss_box_reg: 0.244  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.02124  time: 0.4363  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:16:08 d2.utils.events]: \u001b[0m eta: 1:14:25  iter: 4339  total_loss: 0.7531  loss_cls: 0.3677  loss_box_reg: 0.2836  loss_rpn_cls: 0.01969  loss_rpn_loc: 0.03463  time: 0.4363  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:16:16 d2.utils.events]: \u001b[0m eta: 1:14:16  iter: 4359  total_loss: 0.6912  loss_cls: 0.3612  loss_box_reg: 0.2698  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.01713  time: 0.4363  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:16:25 d2.utils.events]: \u001b[0m eta: 1:14:07  iter: 4379  total_loss: 0.6108  loss_cls: 0.3529  loss_box_reg: 0.2288  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.02488  time: 0.4363  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:16:34 d2.utils.events]: \u001b[0m eta: 1:13:58  iter: 4399  total_loss: 0.6025  loss_cls: 0.3468  loss_box_reg: 0.2513  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.01525  time: 0.4363  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:16:42 d2.utils.events]: \u001b[0m eta: 1:13:49  iter: 4419  total_loss: 0.6573  loss_cls: 0.3844  loss_box_reg: 0.2549  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.01988  time: 0.4362  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:16:51 d2.utils.events]: \u001b[0m eta: 1:13:41  iter: 4439  total_loss: 0.7642  loss_cls: 0.3953  loss_box_reg: 0.2805  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.01683  time: 0.4362  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:17:00 d2.utils.events]: \u001b[0m eta: 1:13:32  iter: 4459  total_loss: 0.7751  loss_cls: 0.3762  loss_box_reg: 0.2792  loss_rpn_cls: 0.01639  loss_rpn_loc: 0.02219  time: 0.4362  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:17:08 d2.utils.events]: \u001b[0m eta: 1:13:23  iter: 4479  total_loss: 0.72  loss_cls: 0.4128  loss_box_reg: 0.2739  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.02242  time: 0.4362  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:17:17 d2.utils.events]: \u001b[0m eta: 1:13:15  iter: 4499  total_loss: 0.6917  loss_cls: 0.3902  loss_box_reg: 0.2893  loss_rpn_cls: 0.01767  loss_rpn_loc: 0.02049  time: 0.4362  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:17:26 d2.utils.events]: \u001b[0m eta: 1:13:06  iter: 4519  total_loss: 0.6305  loss_cls: 0.3456  loss_box_reg: 0.2669  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.01965  time: 0.4362  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:17:34 d2.utils.events]: \u001b[0m eta: 1:12:57  iter: 4539  total_loss: 0.5343  loss_cls: 0.3203  loss_box_reg: 0.2229  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.02307  time: 0.4362  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:17:43 d2.utils.events]: \u001b[0m eta: 1:12:49  iter: 4559  total_loss: 0.6929  loss_cls: 0.3715  loss_box_reg: 0.2806  loss_rpn_cls: 0.01911  loss_rpn_loc: 0.03274  time: 0.4362  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:17:52 d2.utils.events]: \u001b[0m eta: 1:12:40  iter: 4579  total_loss: 0.5801  loss_cls: 0.3352  loss_box_reg: 0.2423  loss_rpn_cls: 0.02077  loss_rpn_loc: 0.02416  time: 0.4361  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:18:00 d2.utils.events]: \u001b[0m eta: 1:12:31  iter: 4599  total_loss: 0.6794  loss_cls: 0.3816  loss_box_reg: 0.2564  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.01699  time: 0.4361  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:18:09 d2.utils.events]: \u001b[0m eta: 1:12:23  iter: 4619  total_loss: 0.7832  loss_cls: 0.4459  loss_box_reg: 0.275  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.03316  time: 0.4361  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:18:18 d2.utils.events]: \u001b[0m eta: 1:12:13  iter: 4639  total_loss: 0.634  loss_cls: 0.3444  loss_box_reg: 0.2357  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.01704  time: 0.4361  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:18:27 d2.utils.events]: \u001b[0m eta: 1:12:05  iter: 4659  total_loss: 0.7167  loss_cls: 0.3913  loss_box_reg: 0.2864  loss_rpn_cls: 0.01951  loss_rpn_loc: 0.03009  time: 0.4361  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:18:35 d2.utils.events]: \u001b[0m eta: 1:11:57  iter: 4679  total_loss: 0.7585  loss_cls: 0.3773  loss_box_reg: 0.2956  loss_rpn_cls: 0.02143  loss_rpn_loc: 0.03115  time: 0.4361  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:18:44 d2.utils.events]: \u001b[0m eta: 1:11:48  iter: 4699  total_loss: 0.6614  loss_cls: 0.3565  loss_box_reg: 0.2637  loss_rpn_cls: 0.01782  loss_rpn_loc: 0.02212  time: 0.4361  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:18:53 d2.utils.events]: \u001b[0m eta: 1:11:40  iter: 4719  total_loss: 0.7212  loss_cls: 0.3911  loss_box_reg: 0.2551  loss_rpn_cls: 0.02277  loss_rpn_loc: 0.04272  time: 0.4361  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:19:01 d2.utils.events]: \u001b[0m eta: 1:11:32  iter: 4739  total_loss: 0.6857  loss_cls: 0.3539  loss_box_reg: 0.2905  loss_rpn_cls: 0.0192  loss_rpn_loc: 0.02534  time: 0.4361  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:19:10 d2.utils.events]: \u001b[0m eta: 1:11:24  iter: 4759  total_loss: 0.723  loss_cls: 0.3881  loss_box_reg: 0.2686  loss_rpn_cls: 0.02738  loss_rpn_loc: 0.02306  time: 0.4361  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:19:19 d2.utils.events]: \u001b[0m eta: 1:11:15  iter: 4779  total_loss: 0.6495  loss_cls: 0.3534  loss_box_reg: 0.2437  loss_rpn_cls: 0.02171  loss_rpn_loc: 0.01893  time: 0.4360  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:19:27 d2.utils.events]: \u001b[0m eta: 1:11:06  iter: 4799  total_loss: 0.7222  loss_cls: 0.3701  loss_box_reg: 0.2792  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.03256  time: 0.4360  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:19:36 d2.utils.events]: \u001b[0m eta: 1:10:58  iter: 4819  total_loss: 0.6212  loss_cls: 0.3003  loss_box_reg: 0.2516  loss_rpn_cls: 0.01697  loss_rpn_loc: 0.02865  time: 0.4360  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:19:45 d2.utils.events]: \u001b[0m eta: 1:10:49  iter: 4839  total_loss: 0.7858  loss_cls: 0.3615  loss_box_reg: 0.3068  loss_rpn_cls: 0.02562  loss_rpn_loc: 0.03499  time: 0.4360  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:19:54 d2.utils.events]: \u001b[0m eta: 1:10:40  iter: 4859  total_loss: 0.6132  loss_cls: 0.3309  loss_box_reg: 0.2466  loss_rpn_cls: 0.01666  loss_rpn_loc: 0.02276  time: 0.4360  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:20:02 d2.utils.events]: \u001b[0m eta: 1:10:31  iter: 4879  total_loss: 0.8012  loss_cls: 0.4246  loss_box_reg: 0.3017  loss_rpn_cls: 0.02753  loss_rpn_loc: 0.04244  time: 0.4360  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:20:04 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/private.json\n",
      "\u001b[32m[09/09 15:20:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 15:20:05 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 15:20:05 d2.data.common]: \u001b[0mSerialized dataset takes 2.16 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 15:20:05 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 15:20:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/09 15:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0006 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0397 s/iter. ETA=0:03:13\n",
      "\u001b[32m[09/09 15:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 136/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:03:10\n",
      "\u001b[32m[09/09 15:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 261/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:03:05\n",
      "\u001b[32m[09/09 15:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 385/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:03:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:20:26 d2.evaluation.evaluator]: \u001b[0mInference done 510/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:55\n",
      "\u001b[32m[09/09 15:20:31 d2.evaluation.evaluator]: \u001b[0mInference done 635/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:50\n",
      "\u001b[32m[09/09 15:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 760/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:45\n",
      "\u001b[32m[09/09 15:20:41 d2.evaluation.evaluator]: \u001b[0mInference done 885/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/09 15:20:46 d2.evaluation.evaluator]: \u001b[0mInference done 1010/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:35\n",
      "\u001b[32m[09/09 15:20:51 d2.evaluation.evaluator]: \u001b[0mInference done 1135/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/09 15:20:56 d2.evaluation.evaluator]: \u001b[0mInference done 1258/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/09 15:21:01 d2.evaluation.evaluator]: \u001b[0mInference done 1383/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:20\n",
      "\u001b[32m[09/09 15:21:06 d2.evaluation.evaluator]: \u001b[0mInference done 1499/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:02:16\n",
      "\u001b[32m[09/09 15:21:11 d2.evaluation.evaluator]: \u001b[0mInference done 1618/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:12\n",
      "\u001b[32m[09/09 15:21:16 d2.evaluation.evaluator]: \u001b[0mInference done 1743/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:07\n",
      "\u001b[32m[09/09 15:21:21 d2.evaluation.evaluator]: \u001b[0mInference done 1859/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:02\n",
      "\u001b[32m[09/09 15:21:26 d2.evaluation.evaluator]: \u001b[0mInference done 1975/4871. Dataloading: 0.0010 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:58\n",
      "\u001b[32m[09/09 15:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 2099/4871. Dataloading: 0.0010 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:53\n",
      "\u001b[32m[09/09 15:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 2224/4871. Dataloading: 0.0010 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/09 15:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 2349/4871. Dataloading: 0.0010 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:42\n",
      "\u001b[32m[09/09 15:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 2474/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/09 15:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 2599/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:32\n",
      "\u001b[32m[09/09 15:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 2723/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:27\n",
      "\u001b[32m[09/09 15:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 2845/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:22\n",
      "\u001b[32m[09/09 15:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 2970/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:17\n",
      "\u001b[32m[09/09 15:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 3095/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:12\n",
      "\u001b[32m[09/09 15:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 3220/4871. Dataloading: 0.0010 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:07\n",
      "\u001b[32m[09/09 15:22:21 d2.evaluation.evaluator]: \u001b[0mInference done 3345/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:02\n",
      "\u001b[32m[09/09 15:22:26 d2.evaluation.evaluator]: \u001b[0mInference done 3469/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:57\n",
      "\u001b[32m[09/09 15:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 3593/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:51\n",
      "\u001b[32m[09/09 15:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 3717/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:46\n",
      "\u001b[32m[09/09 15:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 3842/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:41\n",
      "\u001b[32m[09/09 15:22:46 d2.evaluation.evaluator]: \u001b[0mInference done 3966/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/09 15:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 4091/4871. Dataloading: 0.0010 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/09 15:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 4216/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/09 15:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 4338/4871. Dataloading: 0.0011 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:21\n",
      "\u001b[32m[09/09 15:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 4463/4871. Dataloading: 0.0011 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/09 15:23:11 d2.evaluation.evaluator]: \u001b[0mInference done 4587/4871. Dataloading: 0.0011 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/09 15:23:16 d2.evaluation.evaluator]: \u001b[0mInference done 4712/4871. Dataloading: 0.0011 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/09 15:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 4837/4871. Dataloading: 0.0011 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/09 15:23:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:17.603746 (0.040609 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 15:23:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:11 (0.039285 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 15:23:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 15:23:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/09 15:23:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.50s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 15:23:25 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 15:23:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.02 seconds.\n",
      "\u001b[32m[09/09 15:23:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 15:23:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.36 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.296\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.426\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.321\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.257\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.525\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.230\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.603\n",
      "\u001b[32m[09/09 15:23:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 29.588 | 42.626 | 32.138 | 0.477 | 8.330 | 35.733 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:23:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 16.846 | Paper       | 24.698 | Paper pack | 33.147 |\n",
      "| Metal         | 30.582 | Glass       | 32.590 | Plastic    | 21.478 |\n",
      "| Styrofoam     | 30.648 | Plastic bag | 48.896 | Battery    | 28.787 |\n",
      "| Clothing      | 28.207 |             |        |            |        |\n",
      "\u001b[32m[09/09 15:23:27 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/09 15:23:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 15:23:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 15:23:27 d2.evaluation.testing]: \u001b[0mcopypaste: 29.5878,42.6262,32.1384,0.4771,8.3295,35.7333\n",
      "\u001b[32m[09/09 15:23:34 d2.utils.events]: \u001b[0m eta: 1:10:22  iter: 4899  total_loss: 0.6564  loss_cls: 0.3118  loss_box_reg: 0.2463  loss_rpn_cls: 0.01684  loss_rpn_loc: 0.02511  time: 0.4360  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:23:43 d2.utils.events]: \u001b[0m eta: 1:10:14  iter: 4919  total_loss: 0.6354  loss_cls: 0.3449  loss_box_reg: 0.2252  loss_rpn_cls: 0.01846  loss_rpn_loc: 0.02598  time: 0.4360  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:23:51 d2.utils.events]: \u001b[0m eta: 1:10:05  iter: 4939  total_loss: 0.644  loss_cls: 0.3425  loss_box_reg: 0.2752  loss_rpn_cls: 0.02308  loss_rpn_loc: 0.0297  time: 0.4359  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:24:00 d2.utils.events]: \u001b[0m eta: 1:09:56  iter: 4959  total_loss: 0.5353  loss_cls: 0.2938  loss_box_reg: 0.2256  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01508  time: 0.4359  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:24:09 d2.utils.events]: \u001b[0m eta: 1:09:47  iter: 4979  total_loss: 0.5158  loss_cls: 0.2824  loss_box_reg: 0.2243  loss_rpn_cls: 0.008667  loss_rpn_loc: 0.0153  time: 0.4359  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:24:18 d2.utils.events]: \u001b[0m eta: 1:09:38  iter: 4999  total_loss: 0.6192  loss_cls: 0.3308  loss_box_reg: 0.2447  loss_rpn_cls: 0.01797  loss_rpn_loc: 0.01721  time: 0.4359  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:24:26 d2.utils.events]: \u001b[0m eta: 1:09:30  iter: 5019  total_loss: 0.6636  loss_cls: 0.3125  loss_box_reg: 0.2677  loss_rpn_cls: 0.0147  loss_rpn_loc: 0.02426  time: 0.4359  data_time: 0.0096  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:24:35 d2.utils.events]: \u001b[0m eta: 1:09:21  iter: 5039  total_loss: 0.5998  loss_cls: 0.3418  loss_box_reg: 0.2662  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.01678  time: 0.4359  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:24:44 d2.utils.events]: \u001b[0m eta: 1:09:12  iter: 5059  total_loss: 0.5995  loss_cls: 0.3239  loss_box_reg: 0.2385  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.01618  time: 0.4359  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:24:52 d2.utils.events]: \u001b[0m eta: 1:09:03  iter: 5079  total_loss: 0.6399  loss_cls: 0.3455  loss_box_reg: 0.2405  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.02564  time: 0.4359  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:25:01 d2.utils.events]: \u001b[0m eta: 1:08:54  iter: 5099  total_loss: 0.702  loss_cls: 0.3733  loss_box_reg: 0.2644  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.02926  time: 0.4358  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:25:10 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 5119  total_loss: 0.7368  loss_cls: 0.3688  loss_box_reg: 0.2877  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.03289  time: 0.4358  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:25:18 d2.utils.events]: \u001b[0m eta: 1:08:37  iter: 5139  total_loss: 0.8108  loss_cls: 0.4008  loss_box_reg: 0.31  loss_rpn_cls: 0.02349  loss_rpn_loc: 0.032  time: 0.4358  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:25:27 d2.utils.events]: \u001b[0m eta: 1:08:29  iter: 5159  total_loss: 0.4844  loss_cls: 0.2705  loss_box_reg: 0.1908  loss_rpn_cls: 0.009809  loss_rpn_loc: 0.0117  time: 0.4358  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:25:36 d2.utils.events]: \u001b[0m eta: 1:08:20  iter: 5179  total_loss: 0.7196  loss_cls: 0.3448  loss_box_reg: 0.2711  loss_rpn_cls: 0.02101  loss_rpn_loc: 0.02149  time: 0.4358  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:25:44 d2.utils.events]: \u001b[0m eta: 1:08:11  iter: 5199  total_loss: 0.6651  loss_cls: 0.3888  loss_box_reg: 0.2351  loss_rpn_cls: 0.01484  loss_rpn_loc: 0.03533  time: 0.4358  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:25:53 d2.utils.events]: \u001b[0m eta: 1:08:03  iter: 5219  total_loss: 0.7251  loss_cls: 0.4083  loss_box_reg: 0.2636  loss_rpn_cls: 0.01804  loss_rpn_loc: 0.02527  time: 0.4358  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:26:02 d2.utils.events]: \u001b[0m eta: 1:07:54  iter: 5239  total_loss: 0.608  loss_cls: 0.3407  loss_box_reg: 0.2315  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.0193  time: 0.4358  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:26:10 d2.utils.events]: \u001b[0m eta: 1:07:45  iter: 5259  total_loss: 0.5299  loss_cls: 0.3271  loss_box_reg: 0.162  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.008923  time: 0.4358  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:26:19 d2.utils.events]: \u001b[0m eta: 1:07:36  iter: 5279  total_loss: 0.6139  loss_cls: 0.3374  loss_box_reg: 0.2313  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.01896  time: 0.4358  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:26:28 d2.utils.events]: \u001b[0m eta: 1:07:27  iter: 5299  total_loss: 0.649  loss_cls: 0.3312  loss_box_reg: 0.2792  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.01743  time: 0.4357  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:26:36 d2.utils.events]: \u001b[0m eta: 1:07:19  iter: 5319  total_loss: 0.653  loss_cls: 0.321  loss_box_reg: 0.2487  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.02693  time: 0.4357  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:26:45 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 5339  total_loss: 0.7749  loss_cls: 0.3918  loss_box_reg: 0.3131  loss_rpn_cls: 0.02165  loss_rpn_loc: 0.0318  time: 0.4357  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:26:54 d2.utils.events]: \u001b[0m eta: 1:07:02  iter: 5359  total_loss: 0.6284  loss_cls: 0.3174  loss_box_reg: 0.2501  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.01677  time: 0.4357  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:27:03 d2.utils.events]: \u001b[0m eta: 1:06:53  iter: 5379  total_loss: 0.6753  loss_cls: 0.338  loss_box_reg: 0.2581  loss_rpn_cls: 0.01597  loss_rpn_loc: 0.0222  time: 0.4357  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:27:11 d2.utils.events]: \u001b[0m eta: 1:06:45  iter: 5399  total_loss: 0.6673  loss_cls: 0.3507  loss_box_reg: 0.2556  loss_rpn_cls: 0.02423  loss_rpn_loc: 0.02617  time: 0.4357  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:27:20 d2.utils.events]: \u001b[0m eta: 1:06:36  iter: 5419  total_loss: 0.6568  loss_cls: 0.3507  loss_box_reg: 0.2676  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.02922  time: 0.4357  data_time: 0.0113  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:27:29 d2.utils.events]: \u001b[0m eta: 1:06:27  iter: 5439  total_loss: 0.589  loss_cls: 0.2612  loss_box_reg: 0.2304  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.01935  time: 0.4357  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:27:37 d2.utils.events]: \u001b[0m eta: 1:06:19  iter: 5459  total_loss: 0.6396  loss_cls: 0.3228  loss_box_reg: 0.2546  loss_rpn_cls: 0.01691  loss_rpn_loc: 0.02125  time: 0.4357  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:27:46 d2.utils.events]: \u001b[0m eta: 1:06:10  iter: 5479  total_loss: 0.6584  loss_cls: 0.3696  loss_box_reg: 0.2523  loss_rpn_cls: 0.01841  loss_rpn_loc: 0.02764  time: 0.4357  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:27:55 d2.utils.events]: \u001b[0m eta: 1:06:02  iter: 5499  total_loss: 0.6771  loss_cls: 0.3756  loss_box_reg: 0.2213  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.03156  time: 0.4357  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:28:03 d2.utils.events]: \u001b[0m eta: 1:05:53  iter: 5519  total_loss: 0.5695  loss_cls: 0.3189  loss_box_reg: 0.2324  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.01531  time: 0.4357  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:28:12 d2.utils.events]: \u001b[0m eta: 1:05:45  iter: 5539  total_loss: 0.7424  loss_cls: 0.4103  loss_box_reg: 0.2758  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.02532  time: 0.4357  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:28:21 d2.utils.events]: \u001b[0m eta: 1:05:36  iter: 5559  total_loss: 0.717  loss_cls: 0.3724  loss_box_reg: 0.2678  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.0255  time: 0.4357  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:28:30 d2.utils.events]: \u001b[0m eta: 1:05:27  iter: 5579  total_loss: 0.5657  loss_cls: 0.3071  loss_box_reg: 0.2284  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.02309  time: 0.4356  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:28:38 d2.utils.events]: \u001b[0m eta: 1:05:19  iter: 5599  total_loss: 0.5744  loss_cls: 0.31  loss_box_reg: 0.1809  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.02071  time: 0.4356  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:28:47 d2.utils.events]: \u001b[0m eta: 1:05:10  iter: 5619  total_loss: 0.704  loss_cls: 0.3928  loss_box_reg: 0.2711  loss_rpn_cls: 0.01862  loss_rpn_loc: 0.02783  time: 0.4356  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:28:56 d2.utils.events]: \u001b[0m eta: 1:05:02  iter: 5639  total_loss: 0.6798  loss_cls: 0.3236  loss_box_reg: 0.2402  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.02779  time: 0.4356  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:29:04 d2.utils.events]: \u001b[0m eta: 1:04:53  iter: 5659  total_loss: 0.6581  loss_cls: 0.3498  loss_box_reg: 0.2217  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.03468  time: 0.4356  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:29:13 d2.utils.events]: \u001b[0m eta: 1:04:44  iter: 5679  total_loss: 0.5051  loss_cls: 0.2701  loss_box_reg: 0.204  loss_rpn_cls: 0.01074  loss_rpn_loc: 0.01518  time: 0.4356  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:29:22 d2.utils.events]: \u001b[0m eta: 1:04:35  iter: 5699  total_loss: 0.5904  loss_cls: 0.2771  loss_box_reg: 0.2031  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.02109  time: 0.4356  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:29:30 d2.utils.events]: \u001b[0m eta: 1:04:26  iter: 5719  total_loss: 0.692  loss_cls: 0.3127  loss_box_reg: 0.2872  loss_rpn_cls: 0.01784  loss_rpn_loc: 0.02601  time: 0.4356  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:29:39 d2.utils.events]: \u001b[0m eta: 1:04:18  iter: 5739  total_loss: 0.7322  loss_cls: 0.3332  loss_box_reg: 0.3124  loss_rpn_cls: 0.02137  loss_rpn_loc: 0.03014  time: 0.4356  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:29:48 d2.utils.events]: \u001b[0m eta: 1:04:09  iter: 5759  total_loss: 0.6873  loss_cls: 0.3477  loss_box_reg: 0.2673  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.02691  time: 0.4356  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:29:57 d2.utils.events]: \u001b[0m eta: 1:04:00  iter: 5779  total_loss: 0.5183  loss_cls: 0.2772  loss_box_reg: 0.183  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.009355  time: 0.4356  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:30:05 d2.utils.events]: \u001b[0m eta: 1:03:52  iter: 5799  total_loss: 0.6045  loss_cls: 0.3337  loss_box_reg: 0.223  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.01791  time: 0.4356  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:30:14 d2.utils.events]: \u001b[0m eta: 1:03:44  iter: 5819  total_loss: 0.6576  loss_cls: 0.3232  loss_box_reg: 0.2602  loss_rpn_cls: 0.02058  loss_rpn_loc: 0.03074  time: 0.4356  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:30:23 d2.utils.events]: \u001b[0m eta: 1:03:35  iter: 5839  total_loss: 0.6274  loss_cls: 0.3595  loss_box_reg: 0.2281  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.01888  time: 0.4356  data_time: 0.0114  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:30:31 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 5859  total_loss: 0.5716  loss_cls: 0.3158  loss_box_reg: 0.2002  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.02106  time: 0.4356  data_time: 0.0113  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:30:40 d2.utils.events]: \u001b[0m eta: 1:03:19  iter: 5879  total_loss: 0.6583  loss_cls: 0.3759  loss_box_reg: 0.2345  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.01962  time: 0.4356  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:30:49 d2.utils.events]: \u001b[0m eta: 1:03:10  iter: 5899  total_loss: 0.5654  loss_cls: 0.2963  loss_box_reg: 0.2291  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.01433  time: 0.4355  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:30:57 d2.utils.events]: \u001b[0m eta: 1:03:02  iter: 5919  total_loss: 0.6602  loss_cls: 0.3373  loss_box_reg: 0.2682  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.02628  time: 0.4355  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:31:06 d2.utils.events]: \u001b[0m eta: 1:02:53  iter: 5939  total_loss: 0.6515  loss_cls: 0.3312  loss_box_reg: 0.2446  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.03748  time: 0.4355  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:31:15 d2.utils.events]: \u001b[0m eta: 1:02:44  iter: 5959  total_loss: 0.6519  loss_cls: 0.3593  loss_box_reg: 0.2364  loss_rpn_cls: 0.02069  loss_rpn_loc: 0.04539  time: 0.4355  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:31:24 d2.utils.events]: \u001b[0m eta: 1:02:36  iter: 5979  total_loss: 0.6743  loss_cls: 0.3311  loss_box_reg: 0.2494  loss_rpn_cls: 0.01813  loss_rpn_loc: 0.01977  time: 0.4355  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:31:32 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 5999  total_loss: 0.6346  loss_cls: 0.3313  loss_box_reg: 0.2468  loss_rpn_cls: 0.02069  loss_rpn_loc: 0.03747  time: 0.4355  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:31:41 d2.utils.events]: \u001b[0m eta: 1:02:18  iter: 6019  total_loss: 0.5606  loss_cls: 0.3202  loss_box_reg: 0.2099  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.02173  time: 0.4355  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:31:50 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 6039  total_loss: 0.5678  loss_cls: 0.3233  loss_box_reg: 0.2354  loss_rpn_cls: 0.01369  loss_rpn_loc: 0.01897  time: 0.4355  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:31:58 d2.utils.events]: \u001b[0m eta: 1:02:01  iter: 6059  total_loss: 0.6599  loss_cls: 0.348  loss_box_reg: 0.2618  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.02134  time: 0.4355  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:32:07 d2.utils.events]: \u001b[0m eta: 1:01:52  iter: 6079  total_loss: 0.5824  loss_cls: 0.2837  loss_box_reg: 0.2305  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.04241  time: 0.4355  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:32:16 d2.utils.events]: \u001b[0m eta: 1:01:44  iter: 6099  total_loss: 0.7415  loss_cls: 0.3871  loss_box_reg: 0.2893  loss_rpn_cls: 0.01581  loss_rpn_loc: 0.02689  time: 0.4355  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:32:18 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/private.json\n",
      "\u001b[32m[09/09 15:32:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 15:32:18 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 15:32:19 d2.data.common]: \u001b[0mSerialized dataset takes 2.16 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 15:32:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 15:32:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/09 15:32:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0006 s/iter. Inference: 0.0390 s/iter. Eval: 0.0006 s/iter. Total: 0.0402 s/iter. ETA=0:03:15\n",
      "\u001b[32m[09/09 15:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 136/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:03:10\n",
      "\u001b[32m[09/09 15:32:29 d2.evaluation.evaluator]: \u001b[0mInference done 259/4871. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:03:07\n",
      "\u001b[32m[09/09 15:32:34 d2.evaluation.evaluator]: \u001b[0mInference done 383/4871. Dataloading: 0.0010 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:03:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:32:39 d2.evaluation.evaluator]: \u001b[0mInference done 507/4871. Dataloading: 0.0010 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:02:56\n",
      "\u001b[32m[09/09 15:32:44 d2.evaluation.evaluator]: \u001b[0mInference done 632/4871. Dataloading: 0.0010 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:51\n",
      "\u001b[32m[09/09 15:32:49 d2.evaluation.evaluator]: \u001b[0mInference done 757/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/09 15:32:54 d2.evaluation.evaluator]: \u001b[0mInference done 882/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:41\n",
      "\u001b[32m[09/09 15:32:59 d2.evaluation.evaluator]: \u001b[0mInference done 1006/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:36\n",
      "\u001b[32m[09/09 15:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 1131/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/09 15:33:09 d2.evaluation.evaluator]: \u001b[0mInference done 1256/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/09 15:33:14 d2.evaluation.evaluator]: \u001b[0mInference done 1378/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:21\n",
      "\u001b[32m[09/09 15:33:20 d2.evaluation.evaluator]: \u001b[0mInference done 1503/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:16\n",
      "\u001b[32m[09/09 15:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 1628/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/09 15:33:30 d2.evaluation.evaluator]: \u001b[0mInference done 1753/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:05\n",
      "\u001b[32m[09/09 15:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 1876/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:00\n",
      "\u001b[32m[09/09 15:33:40 d2.evaluation.evaluator]: \u001b[0mInference done 2001/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/09 15:33:45 d2.evaluation.evaluator]: \u001b[0mInference done 2126/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:50\n",
      "\u001b[32m[09/09 15:33:50 d2.evaluation.evaluator]: \u001b[0mInference done 2251/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:45\n",
      "\u001b[32m[09/09 15:33:55 d2.evaluation.evaluator]: \u001b[0mInference done 2376/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:40\n",
      "\u001b[32m[09/09 15:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 2501/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:35\n",
      "\u001b[32m[09/09 15:34:05 d2.evaluation.evaluator]: \u001b[0mInference done 2626/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:30\n",
      "\u001b[32m[09/09 15:34:10 d2.evaluation.evaluator]: \u001b[0mInference done 2751/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/09 15:34:15 d2.evaluation.evaluator]: \u001b[0mInference done 2876/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:20\n",
      "\u001b[32m[09/09 15:34:20 d2.evaluation.evaluator]: \u001b[0mInference done 3001/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/09 15:34:25 d2.evaluation.evaluator]: \u001b[0mInference done 3126/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:10\n",
      "\u001b[32m[09/09 15:34:30 d2.evaluation.evaluator]: \u001b[0mInference done 3251/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/09 15:34:35 d2.evaluation.evaluator]: \u001b[0mInference done 3376/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:00\n",
      "\u001b[32m[09/09 15:34:40 d2.evaluation.evaluator]: \u001b[0mInference done 3501/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:55\n",
      "\u001b[32m[09/09 15:34:45 d2.evaluation.evaluator]: \u001b[0mInference done 3623/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/09 15:34:50 d2.evaluation.evaluator]: \u001b[0mInference done 3747/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:45\n",
      "\u001b[32m[09/09 15:34:55 d2.evaluation.evaluator]: \u001b[0mInference done 3872/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:40\n",
      "\u001b[32m[09/09 15:35:00 d2.evaluation.evaluator]: \u001b[0mInference done 3996/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/09 15:35:05 d2.evaluation.evaluator]: \u001b[0mInference done 4120/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/09 15:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 4244/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:00:25\n",
      "\u001b[32m[09/09 15:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 4368/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:00:20\n",
      "\u001b[32m[09/09 15:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 4493/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:00:15\n",
      "\u001b[32m[09/09 15:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 4618/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:00:10\n",
      "\u001b[32m[09/09 15:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 4743/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:05\n",
      "\u001b[32m[09/09 15:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 4868/4871. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/09 15:35:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:16.369991 (0.040356 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 15:35:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:09 (0.039041 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 15:35:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 15:35:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/09 15:35:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.44s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 15:35:37 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 15:35:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.89 seconds.\n",
      "\u001b[32m[09/09 15:35:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 15:35:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.32 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.445\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.084\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.232\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.601\n",
      "\u001b[32m[09/09 15:35:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 31.293 | 44.549 | 34.109 | 0.226 | 8.407 | 37.441 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:35:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 16.220 | Paper       | 25.385 | Paper pack | 35.081 |\n",
      "| Metal         | 32.175 | Glass       | 32.356 | Plastic    | 24.265 |\n",
      "| Styrofoam     | 31.529 | Plastic bag | 49.132 | Battery    | 36.953 |\n",
      "| Clothing      | 29.831 |             |        |            |        |\n",
      "\u001b[32m[09/09 15:35:39 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/09 15:35:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 15:35:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 15:35:39 d2.evaluation.testing]: \u001b[0mcopypaste: 31.2928,44.5491,34.1089,0.2257,8.4066,37.4409\n",
      "\u001b[32m[09/09 15:35:46 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 6119  total_loss: 0.6032  loss_cls: 0.3099  loss_box_reg: 0.2215  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.02361  time: 0.4355  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:35:55 d2.utils.events]: \u001b[0m eta: 1:01:26  iter: 6139  total_loss: 0.6729  loss_cls: 0.3289  loss_box_reg: 0.2477  loss_rpn_cls: 0.01369  loss_rpn_loc: 0.04044  time: 0.4355  data_time: 0.0114  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:36:03 d2.utils.events]: \u001b[0m eta: 1:01:18  iter: 6159  total_loss: 0.6267  loss_cls: 0.3296  loss_box_reg: 0.2082  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.01408  time: 0.4354  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:36:12 d2.utils.events]: \u001b[0m eta: 1:01:09  iter: 6179  total_loss: 0.6608  loss_cls: 0.3588  loss_box_reg: 0.2573  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.02115  time: 0.4354  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:36:21 d2.utils.events]: \u001b[0m eta: 1:01:01  iter: 6199  total_loss: 0.6048  loss_cls: 0.3354  loss_box_reg: 0.2332  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.01674  time: 0.4355  data_time: 0.0101  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:36:34 d2.utils.events]: \u001b[0m eta: 1:00:53  iter: 6219  total_loss: 0.5608  loss_cls: 0.3314  loss_box_reg: 0.2032  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.0127  time: 0.4362  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:36:43 d2.utils.events]: \u001b[0m eta: 1:00:45  iter: 6239  total_loss: 0.69  loss_cls: 0.3301  loss_box_reg: 0.2407  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.04379  time: 0.4362  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:36:52 d2.utils.events]: \u001b[0m eta: 1:00:36  iter: 6259  total_loss: 0.5436  loss_cls: 0.3014  loss_box_reg: 0.2094  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.02545  time: 0.4362  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:37:00 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 6279  total_loss: 0.64  loss_cls: 0.3184  loss_box_reg: 0.2521  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.02025  time: 0.4362  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:37:09 d2.utils.events]: \u001b[0m eta: 1:00:19  iter: 6299  total_loss: 0.5304  loss_cls: 0.2932  loss_box_reg: 0.2003  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.01759  time: 0.4362  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:37:18 d2.utils.events]: \u001b[0m eta: 1:00:11  iter: 6319  total_loss: 0.5314  loss_cls: 0.2795  loss_box_reg: 0.2113  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.02511  time: 0.4362  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:37:26 d2.utils.events]: \u001b[0m eta: 1:00:02  iter: 6339  total_loss: 0.5828  loss_cls: 0.3054  loss_box_reg: 0.2402  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.02661  time: 0.4362  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:37:35 d2.utils.events]: \u001b[0m eta: 0:59:53  iter: 6359  total_loss: 0.5779  loss_cls: 0.3028  loss_box_reg: 0.2514  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.02294  time: 0.4361  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:37:44 d2.utils.events]: \u001b[0m eta: 0:59:45  iter: 6379  total_loss: 0.548  loss_cls: 0.2671  loss_box_reg: 0.2311  loss_rpn_cls: 0.01859  loss_rpn_loc: 0.01795  time: 0.4361  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:37:52 d2.utils.events]: \u001b[0m eta: 0:59:36  iter: 6399  total_loss: 0.5996  loss_cls: 0.2798  loss_box_reg: 0.2406  loss_rpn_cls: 0.009944  loss_rpn_loc: 0.0116  time: 0.4361  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:38:01 d2.utils.events]: \u001b[0m eta: 0:59:27  iter: 6419  total_loss: 0.582  loss_cls: 0.29  loss_box_reg: 0.1921  loss_rpn_cls: 0.009945  loss_rpn_loc: 0.01684  time: 0.4361  data_time: 0.0103  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:38:10 d2.utils.events]: \u001b[0m eta: 0:59:19  iter: 6439  total_loss: 0.6817  loss_cls: 0.3401  loss_box_reg: 0.2469  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.02624  time: 0.4362  data_time: 0.0134  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:38:19 d2.utils.events]: \u001b[0m eta: 0:59:10  iter: 6459  total_loss: 0.6068  loss_cls: 0.3144  loss_box_reg: 0.2663  loss_rpn_cls: 0.01774  loss_rpn_loc: 0.03289  time: 0.4362  data_time: 0.0136  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:38:28 d2.utils.events]: \u001b[0m eta: 0:59:02  iter: 6479  total_loss: 0.6683  loss_cls: 0.323  loss_box_reg: 0.2766  loss_rpn_cls: 0.01808  loss_rpn_loc: 0.02703  time: 0.4362  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:38:37 d2.utils.events]: \u001b[0m eta: 0:58:53  iter: 6499  total_loss: 0.6244  loss_cls: 0.3256  loss_box_reg: 0.2541  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.02016  time: 0.4362  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:38:45 d2.utils.events]: \u001b[0m eta: 0:58:44  iter: 6519  total_loss: 0.5813  loss_cls: 0.2812  loss_box_reg: 0.2322  loss_rpn_cls: 0.007897  loss_rpn_loc: 0.01229  time: 0.4362  data_time: 0.0106  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:38:54 d2.utils.events]: \u001b[0m eta: 0:58:35  iter: 6539  total_loss: 0.6992  loss_cls: 0.3034  loss_box_reg: 0.2646  loss_rpn_cls: 0.0204  loss_rpn_loc: 0.02677  time: 0.4362  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:39:03 d2.utils.events]: \u001b[0m eta: 0:58:27  iter: 6559  total_loss: 0.5628  loss_cls: 0.2721  loss_box_reg: 0.2031  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.02026  time: 0.4362  data_time: 0.0104  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:39:11 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 6579  total_loss: 0.62  loss_cls: 0.3518  loss_box_reg: 0.2281  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.02242  time: 0.4362  data_time: 0.0102  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:39:20 d2.utils.events]: \u001b[0m eta: 0:58:09  iter: 6599  total_loss: 0.6095  loss_cls: 0.3091  loss_box_reg: 0.2532  loss_rpn_cls: 0.01683  loss_rpn_loc: 0.02454  time: 0.4361  data_time: 0.0098  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:39:29 d2.utils.events]: \u001b[0m eta: 0:58:00  iter: 6619  total_loss: 0.6774  loss_cls: 0.3639  loss_box_reg: 0.276  loss_rpn_cls: 0.02359  loss_rpn_loc: 0.03264  time: 0.4361  data_time: 0.0099  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:39:37 d2.utils.events]: \u001b[0m eta: 0:57:51  iter: 6639  total_loss: 0.5909  loss_cls: 0.3409  loss_box_reg: 0.2428  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.02247  time: 0.4361  data_time: 0.0099  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:39:46 d2.utils.events]: \u001b[0m eta: 0:57:43  iter: 6659  total_loss: 0.614  loss_cls: 0.3367  loss_box_reg: 0.2087  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.02238  time: 0.4361  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:39:55 d2.utils.events]: \u001b[0m eta: 0:57:34  iter: 6679  total_loss: 0.5894  loss_cls: 0.3054  loss_box_reg: 0.1987  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.01855  time: 0.4361  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:40:04 d2.utils.events]: \u001b[0m eta: 0:57:26  iter: 6699  total_loss: 0.5592  loss_cls: 0.3046  loss_box_reg: 0.229  loss_rpn_cls: 0.01308  loss_rpn_loc: 0.02299  time: 0.4361  data_time: 0.0098  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:40:12 d2.utils.events]: \u001b[0m eta: 0:57:17  iter: 6719  total_loss: 0.6299  loss_cls: 0.3377  loss_box_reg: 0.2299  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.02269  time: 0.4361  data_time: 0.0100  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:40:21 d2.utils.events]: \u001b[0m eta: 0:57:08  iter: 6739  total_loss: 0.559  loss_cls: 0.2893  loss_box_reg: 0.2484  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.02357  time: 0.4361  data_time: 0.0115  lr: 0.001  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:40:30 d2.utils.events]: \u001b[0m eta: 0:57:00  iter: 6759  total_loss: 0.4717  loss_cls: 0.2804  loss_box_reg: 0.1771  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.01572  time: 0.4362  data_time: 0.0159  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:40:39 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 6779  total_loss: 0.5713  loss_cls: 0.2807  loss_box_reg: 0.1991  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.01898  time: 0.4362  data_time: 0.0138  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:40:48 d2.utils.events]: \u001b[0m eta: 0:56:43  iter: 6799  total_loss: 0.5685  loss_cls: 0.3087  loss_box_reg: 0.2187  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.01284  time: 0.4362  data_time: 0.0135  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:40:57 d2.utils.events]: \u001b[0m eta: 0:56:35  iter: 6819  total_loss: 0.5345  loss_cls: 0.3023  loss_box_reg: 0.2232  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.01622  time: 0.4363  data_time: 0.0154  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:41:06 d2.utils.events]: \u001b[0m eta: 0:56:27  iter: 6839  total_loss: 0.5976  loss_cls: 0.2955  loss_box_reg: 0.2287  loss_rpn_cls: 0.006344  loss_rpn_loc: 0.01721  time: 0.4364  data_time: 0.0129  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:41:16 d2.utils.events]: \u001b[0m eta: 0:56:18  iter: 6859  total_loss: 0.5916  loss_cls: 0.3345  loss_box_reg: 0.2266  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.02118  time: 0.4364  data_time: 0.0124  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:41:25 d2.utils.events]: \u001b[0m eta: 0:56:10  iter: 6879  total_loss: 0.7579  loss_cls: 0.3708  loss_box_reg: 0.2777  loss_rpn_cls: 0.01867  loss_rpn_loc: 0.02944  time: 0.4365  data_time: 0.0130  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:41:34 d2.utils.events]: \u001b[0m eta: 0:56:02  iter: 6899  total_loss: 0.6145  loss_cls: 0.298  loss_box_reg: 0.2752  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.03032  time: 0.4365  data_time: 0.0142  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:41:43 d2.utils.events]: \u001b[0m eta: 0:55:55  iter: 6919  total_loss: 0.6115  loss_cls: 0.3105  loss_box_reg: 0.2568  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.01737  time: 0.4365  data_time: 0.0131  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:41:52 d2.utils.events]: \u001b[0m eta: 0:55:47  iter: 6939  total_loss: 0.7181  loss_cls: 0.3449  loss_box_reg: 0.2791  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.03332  time: 0.4365  data_time: 0.0123  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:42:00 d2.utils.events]: \u001b[0m eta: 0:55:40  iter: 6959  total_loss: 0.5288  loss_cls: 0.2805  loss_box_reg: 0.2191  loss_rpn_cls: 0.009867  loss_rpn_loc: 0.01376  time: 0.4366  data_time: 0.0124  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:42:09 d2.utils.events]: \u001b[0m eta: 0:55:32  iter: 6979  total_loss: 0.6909  loss_cls: 0.3266  loss_box_reg: 0.2761  loss_rpn_cls: 0.01426  loss_rpn_loc: 0.02567  time: 0.4366  data_time: 0.0129  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:42:19 d2.utils.events]: \u001b[0m eta: 0:55:25  iter: 6999  total_loss: 0.6077  loss_cls: 0.3096  loss_box_reg: 0.2499  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.02102  time: 0.4367  data_time: 0.0157  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:42:28 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 7019  total_loss: 0.7261  loss_cls: 0.3708  loss_box_reg: 0.2608  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.02848  time: 0.4367  data_time: 0.0162  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:42:37 d2.utils.events]: \u001b[0m eta: 0:55:10  iter: 7039  total_loss: 0.6644  loss_cls: 0.3639  loss_box_reg: 0.2269  loss_rpn_cls: 0.02077  loss_rpn_loc: 0.02915  time: 0.4368  data_time: 0.0129  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:42:46 d2.utils.events]: \u001b[0m eta: 0:55:04  iter: 7059  total_loss: 0.6071  loss_cls: 0.3034  loss_box_reg: 0.2315  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.02937  time: 0.4368  data_time: 0.0129  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:42:55 d2.utils.events]: \u001b[0m eta: 0:54:58  iter: 7079  total_loss: 0.6528  loss_cls: 0.3683  loss_box_reg: 0.2493  loss_rpn_cls: 0.02227  loss_rpn_loc: 0.0204  time: 0.4369  data_time: 0.0127  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:43:04 d2.utils.events]: \u001b[0m eta: 0:54:54  iter: 7099  total_loss: 0.6613  loss_cls: 0.3111  loss_box_reg: 0.2783  loss_rpn_cls: 0.01797  loss_rpn_loc: 0.0265  time: 0.4369  data_time: 0.0155  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:43:13 d2.utils.events]: \u001b[0m eta: 0:54:50  iter: 7119  total_loss: 0.6086  loss_cls: 0.3119  loss_box_reg: 0.2488  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.02328  time: 0.4370  data_time: 0.0126  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:43:22 d2.utils.events]: \u001b[0m eta: 0:54:46  iter: 7139  total_loss: 0.5522  loss_cls: 0.2572  loss_box_reg: 0.2231  loss_rpn_cls: 0.008417  loss_rpn_loc: 0.01483  time: 0.4370  data_time: 0.0121  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:43:31 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 7159  total_loss: 0.6083  loss_cls: 0.3052  loss_box_reg: 0.2553  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.01981  time: 0.4370  data_time: 0.0120  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:43:40 d2.utils.events]: \u001b[0m eta: 0:54:38  iter: 7179  total_loss: 0.6321  loss_cls: 0.3309  loss_box_reg: 0.2372  loss_rpn_cls: 0.02512  loss_rpn_loc: 0.02283  time: 0.4370  data_time: 0.0152  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:43:49 d2.utils.events]: \u001b[0m eta: 0:54:31  iter: 7199  total_loss: 0.6195  loss_cls: 0.3287  loss_box_reg: 0.2273  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.01977  time: 0.4371  data_time: 0.0166  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:43:59 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 7219  total_loss: 0.6134  loss_cls: 0.31  loss_box_reg: 0.2191  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.03268  time: 0.4372  data_time: 0.0180  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:44:08 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 7239  total_loss: 0.6788  loss_cls: 0.3383  loss_box_reg: 0.2255  loss_rpn_cls: 0.01634  loss_rpn_loc: 0.02504  time: 0.4372  data_time: 0.0131  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:44:17 d2.utils.events]: \u001b[0m eta: 0:54:10  iter: 7259  total_loss: 0.5332  loss_cls: 0.2689  loss_box_reg: 0.2056  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.02388  time: 0.4372  data_time: 0.0181  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:44:26 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 7279  total_loss: 0.6044  loss_cls: 0.3007  loss_box_reg: 0.2393  loss_rpn_cls: 0.02313  loss_rpn_loc: 0.03638  time: 0.4373  data_time: 0.0166  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:44:35 d2.utils.events]: \u001b[0m eta: 0:53:57  iter: 7299  total_loss: 0.5889  loss_cls: 0.2851  loss_box_reg: 0.2383  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.02422  time: 0.4373  data_time: 0.0152  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:44:44 d2.utils.events]: \u001b[0m eta: 0:53:49  iter: 7319  total_loss: 0.5281  loss_cls: 0.28  loss_box_reg: 0.1891  loss_rpn_cls: 0.0165  loss_rpn_loc: 0.02408  time: 0.4374  data_time: 0.0136  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:44:47 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/private.json\n",
      "\u001b[32m[09/09 15:44:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 15:44:47 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 15:44:47 d2.data.common]: \u001b[0mSerialized dataset takes 2.16 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 15:44:47 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 15:44:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/09 15:44:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0007 s/iter. Inference: 0.0446 s/iter. Eval: 0.0003 s/iter. Total: 0.0455 s/iter. ETA=0:03:41\n",
      "\u001b[32m[09/09 15:44:53 d2.evaluation.evaluator]: \u001b[0mInference done 130/4871. Dataloading: 0.0011 s/iter. Inference: 0.0408 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:03:20\n",
      "\u001b[32m[09/09 15:44:58 d2.evaluation.evaluator]: \u001b[0mInference done 242/4871. Dataloading: 0.0011 s/iter. Inference: 0.0420 s/iter. Eval: 0.0003 s/iter. Total: 0.0434 s/iter. ETA=0:03:21\n",
      "\u001b[32m[09/09 15:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 350/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0003 s/iter. Total: 0.0444 s/iter. ETA=0:03:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:45:08 d2.evaluation.evaluator]: \u001b[0mInference done 460/4871. Dataloading: 0.0013 s/iter. Inference: 0.0431 s/iter. Eval: 0.0003 s/iter. Total: 0.0447 s/iter. ETA=0:03:17\n",
      "\u001b[32m[09/09 15:45:13 d2.evaluation.evaluator]: \u001b[0mInference done 578/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0003 s/iter. Total: 0.0443 s/iter. ETA=0:03:10\n",
      "\u001b[32m[09/09 15:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 694/4871. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0003 s/iter. Total: 0.0441 s/iter. ETA=0:03:04\n",
      "\u001b[32m[09/09 15:45:24 d2.evaluation.evaluator]: \u001b[0mInference done 805/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0003 s/iter. Total: 0.0443 s/iter. ETA=0:02:59\n",
      "\u001b[32m[09/09 15:45:29 d2.evaluation.evaluator]: \u001b[0mInference done 916/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0003 s/iter. Total: 0.0444 s/iter. ETA=0:02:55\n",
      "\u001b[32m[09/09 15:45:34 d2.evaluation.evaluator]: \u001b[0mInference done 1026/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:02:51\n",
      "\u001b[32m[09/09 15:45:39 d2.evaluation.evaluator]: \u001b[0mInference done 1142/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0003 s/iter. Total: 0.0444 s/iter. ETA=0:02:45\n",
      "\u001b[32m[09/09 15:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 1253/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0445 s/iter. ETA=0:02:41\n",
      "\u001b[32m[09/09 15:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 1361/4871. Dataloading: 0.0013 s/iter. Inference: 0.0430 s/iter. Eval: 0.0003 s/iter. Total: 0.0447 s/iter. ETA=0:02:36\n",
      "\u001b[32m[09/09 15:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 1478/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0445 s/iter. ETA=0:02:31\n",
      "\u001b[32m[09/09 15:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 1586/4871. Dataloading: 0.0013 s/iter. Inference: 0.0430 s/iter. Eval: 0.0003 s/iter. Total: 0.0447 s/iter. ETA=0:02:26\n",
      "\u001b[32m[09/09 15:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 1697/4871. Dataloading: 0.0013 s/iter. Inference: 0.0431 s/iter. Eval: 0.0003 s/iter. Total: 0.0447 s/iter. ETA=0:02:21\n",
      "\u001b[32m[09/09 15:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 1815/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:02:16\n",
      "\u001b[32m[09/09 15:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 1927/4871. Dataloading: 0.0013 s/iter. Inference: 0.0430 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:02:11\n",
      "\u001b[32m[09/09 15:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 2039/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:02:06\n",
      "\u001b[32m[09/09 15:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 2152/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:02:01\n",
      "\u001b[32m[09/09 15:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 2272/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0003 s/iter. Total: 0.0444 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/09 15:46:34 d2.evaluation.evaluator]: \u001b[0mInference done 2388/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0003 s/iter. Total: 0.0444 s/iter. ETA=0:01:50\n",
      "\u001b[32m[09/09 15:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 2499/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0003 s/iter. Total: 0.0444 s/iter. ETA=0:01:45\n",
      "\u001b[32m[09/09 15:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 2621/4871. Dataloading: 0.0013 s/iter. Inference: 0.0427 s/iter. Eval: 0.0003 s/iter. Total: 0.0443 s/iter. ETA=0:01:39\n",
      "\u001b[32m[09/09 15:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 2741/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0003 s/iter. Total: 0.0442 s/iter. ETA=0:01:34\n",
      "\u001b[32m[09/09 15:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 2862/4871. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0003 s/iter. Total: 0.0441 s/iter. ETA=0:01:28\n",
      "\u001b[32m[09/09 15:46:59 d2.evaluation.evaluator]: \u001b[0mInference done 2981/4871. Dataloading: 0.0013 s/iter. Inference: 0.0424 s/iter. Eval: 0.0003 s/iter. Total: 0.0440 s/iter. ETA=0:01:23\n",
      "\u001b[32m[09/09 15:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 3093/4871. Dataloading: 0.0013 s/iter. Inference: 0.0424 s/iter. Eval: 0.0003 s/iter. Total: 0.0440 s/iter. ETA=0:01:18\n",
      "\u001b[32m[09/09 15:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 3202/4871. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0003 s/iter. Total: 0.0441 s/iter. ETA=0:01:13\n",
      "\u001b[32m[09/09 15:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 3311/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0003 s/iter. Total: 0.0442 s/iter. ETA=0:01:08\n",
      "\u001b[32m[09/09 15:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 3422/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0003 s/iter. Total: 0.0442 s/iter. ETA=0:01:04\n",
      "\u001b[32m[09/09 15:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 3535/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0003 s/iter. Total: 0.0442 s/iter. ETA=0:00:59\n",
      "\u001b[32m[09/09 15:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 3647/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0003 s/iter. Total: 0.0442 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/09 15:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 3761/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0003 s/iter. Total: 0.0442 s/iter. ETA=0:00:49\n",
      "\u001b[32m[09/09 15:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 3882/4871. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0003 s/iter. Total: 0.0441 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/09 15:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 4004/4871. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0003 s/iter. Total: 0.0441 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/09 15:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 4126/4871. Dataloading: 0.0013 s/iter. Inference: 0.0424 s/iter. Eval: 0.0003 s/iter. Total: 0.0440 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/09 15:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 4241/4871. Dataloading: 0.0013 s/iter. Inference: 0.0424 s/iter. Eval: 0.0003 s/iter. Total: 0.0440 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/09 15:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 4353/4871. Dataloading: 0.0013 s/iter. Inference: 0.0424 s/iter. Eval: 0.0003 s/iter. Total: 0.0440 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/09 15:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 4472/4871. Dataloading: 0.0013 s/iter. Inference: 0.0423 s/iter. Eval: 0.0003 s/iter. Total: 0.0439 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/09 15:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 4592/4871. Dataloading: 0.0013 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/09 15:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 4709/4871. Dataloading: 0.0013 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/09 15:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 4828/4871. Dataloading: 0.0013 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0438 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/09 15:48:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:33.278675 (0.043830 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 15:48:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:25 (0.042218 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 15:48:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 15:48:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/09 15:48:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.56s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 15:48:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 15:48:26 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.57 seconds.\n",
      "\u001b[32m[09/09 15:48:26 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:48:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.46 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.422\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.479\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n",
      "\u001b[32m[09/09 15:48:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 29.659 | 42.240 | 32.260 | 0.373 | 7.890 | 35.605 |\n",
      "\u001b[32m[09/09 15:48:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 16.181 | Paper       | 23.400 | Paper pack | 33.361 |\n",
      "| Metal         | 30.803 | Glass       | 33.851 | Plastic    | 19.563 |\n",
      "| Styrofoam     | 29.621 | Plastic bag | 47.390 | Battery    | 34.739 |\n",
      "| Clothing      | 27.684 |             |        |            |        |\n",
      "\u001b[32m[09/09 15:48:27 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/09 15:48:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 15:48:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 15:48:27 d2.evaluation.testing]: \u001b[0mcopypaste: 29.6593,42.2405,32.2598,0.3727,7.8900,35.6054\n",
      "\u001b[32m[09/09 15:48:33 d2.utils.events]: \u001b[0m eta: 0:53:42  iter: 7339  total_loss: 0.5969  loss_cls: 0.2806  loss_box_reg: 0.2294  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.02588  time: 0.4374  data_time: 0.0141  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:48:43 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 7359  total_loss: 0.6207  loss_cls: 0.3072  loss_box_reg: 0.2332  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.02344  time: 0.4375  data_time: 0.0166  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:48:52 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 7379  total_loss: 0.5515  loss_cls: 0.2677  loss_box_reg: 0.2312  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.02812  time: 0.4375  data_time: 0.0174  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:49:01 d2.utils.events]: \u001b[0m eta: 0:53:22  iter: 7399  total_loss: 0.4803  loss_cls: 0.2577  loss_box_reg: 0.2148  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.0206  time: 0.4375  data_time: 0.0129  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:49:10 d2.utils.events]: \u001b[0m eta: 0:53:15  iter: 7419  total_loss: 0.5836  loss_cls: 0.2964  loss_box_reg: 0.2382  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.01737  time: 0.4376  data_time: 0.0158  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:49:19 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 7439  total_loss: 0.4862  loss_cls: 0.254  loss_box_reg: 0.2158  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.01986  time: 0.4376  data_time: 0.0142  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:49:28 d2.utils.events]: \u001b[0m eta: 0:53:00  iter: 7459  total_loss: 0.6712  loss_cls: 0.3084  loss_box_reg: 0.2493  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.02005  time: 0.4377  data_time: 0.0159  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:49:37 d2.utils.events]: \u001b[0m eta: 0:52:52  iter: 7479  total_loss: 0.538  loss_cls: 0.2847  loss_box_reg: 0.2298  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01632  time: 0.4377  data_time: 0.0132  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:49:46 d2.utils.events]: \u001b[0m eta: 0:52:45  iter: 7499  total_loss: 0.5903  loss_cls: 0.2911  loss_box_reg: 0.2274  loss_rpn_cls: 0.01581  loss_rpn_loc: 0.02389  time: 0.4377  data_time: 0.0153  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:49:55 d2.utils.events]: \u001b[0m eta: 0:52:37  iter: 7519  total_loss: 0.5988  loss_cls: 0.3027  loss_box_reg: 0.2318  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.02572  time: 0.4378  data_time: 0.0140  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:50:04 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 7539  total_loss: 0.5527  loss_cls: 0.2832  loss_box_reg: 0.2493  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.01967  time: 0.4378  data_time: 0.0114  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:50:13 d2.utils.events]: \u001b[0m eta: 0:52:20  iter: 7559  total_loss: 0.5729  loss_cls: 0.2891  loss_box_reg: 0.255  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.02211  time: 0.4378  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:50:21 d2.utils.events]: \u001b[0m eta: 0:52:11  iter: 7579  total_loss: 0.5156  loss_cls: 0.3073  loss_box_reg: 0.213  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.02727  time: 0.4378  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:50:30 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 7599  total_loss: 0.58  loss_cls: 0.2919  loss_box_reg: 0.2115  loss_rpn_cls: 0.009311  loss_rpn_loc: 0.0143  time: 0.4377  data_time: 0.0114  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:50:39 d2.utils.events]: \u001b[0m eta: 0:51:54  iter: 7619  total_loss: 0.5391  loss_cls: 0.3232  loss_box_reg: 0.2178  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.02415  time: 0.4377  data_time: 0.0114  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:50:47 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 7639  total_loss: 0.557  loss_cls: 0.2689  loss_box_reg: 0.2218  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.02251  time: 0.4377  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:50:56 d2.utils.events]: \u001b[0m eta: 0:51:36  iter: 7659  total_loss: 0.5881  loss_cls: 0.3313  loss_box_reg: 0.2495  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.02732  time: 0.4377  data_time: 0.0105  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:51:05 d2.utils.events]: \u001b[0m eta: 0:51:26  iter: 7679  total_loss: 0.5565  loss_cls: 0.2598  loss_box_reg: 0.2203  loss_rpn_cls: 0.01144  loss_rpn_loc: 0.02337  time: 0.4377  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:51:14 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 7699  total_loss: 0.5498  loss_cls: 0.3019  loss_box_reg: 0.2142  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.02139  time: 0.4377  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:51:22 d2.utils.events]: \u001b[0m eta: 0:51:09  iter: 7719  total_loss: 0.4968  loss_cls: 0.2654  loss_box_reg: 0.1946  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.01451  time: 0.4377  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:51:31 d2.utils.events]: \u001b[0m eta: 0:51:00  iter: 7739  total_loss: 0.5895  loss_cls: 0.2864  loss_box_reg: 0.2476  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.02968  time: 0.4377  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:51:40 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 7759  total_loss: 0.5458  loss_cls: 0.2974  loss_box_reg: 0.1987  loss_rpn_cls: 0.009867  loss_rpn_loc: 0.02026  time: 0.4377  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:51:48 d2.utils.events]: \u001b[0m eta: 0:50:39  iter: 7779  total_loss: 0.6335  loss_cls: 0.325  loss_box_reg: 0.26  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.0225  time: 0.4377  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:51:57 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 7799  total_loss: 0.5776  loss_cls: 0.3196  loss_box_reg: 0.2189  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.02094  time: 0.4377  data_time: 0.0107  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:52:06 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 7819  total_loss: 0.4894  loss_cls: 0.2339  loss_box_reg: 0.2173  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.017  time: 0.4377  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:52:15 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 7839  total_loss: 0.5155  loss_cls: 0.2509  loss_box_reg: 0.2433  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.02201  time: 0.4377  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:52:23 d2.utils.events]: \u001b[0m eta: 0:49:58  iter: 7859  total_loss: 0.5955  loss_cls: 0.2682  loss_box_reg: 0.2674  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.016  time: 0.4377  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:52:32 d2.utils.events]: \u001b[0m eta: 0:49:48  iter: 7879  total_loss: 0.5766  loss_cls: 0.2854  loss_box_reg: 0.2605  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.02854  time: 0.4377  data_time: 0.0112  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:52:41 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 7899  total_loss: 0.5722  loss_cls: 0.2851  loss_box_reg: 0.2097  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.0252  time: 0.4376  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:52:50 d2.utils.events]: \u001b[0m eta: 0:49:28  iter: 7919  total_loss: 0.6606  loss_cls: 0.3253  loss_box_reg: 0.2649  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.03468  time: 0.4376  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:52:58 d2.utils.events]: \u001b[0m eta: 0:49:18  iter: 7939  total_loss: 0.5781  loss_cls: 0.3  loss_box_reg: 0.2492  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.02037  time: 0.4376  data_time: 0.0110  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:53:07 d2.utils.events]: \u001b[0m eta: 0:49:08  iter: 7959  total_loss: 0.5533  loss_cls: 0.2971  loss_box_reg: 0.2095  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.03207  time: 0.4376  data_time: 0.0111  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:53:16 d2.utils.events]: \u001b[0m eta: 0:48:56  iter: 7979  total_loss: 0.5953  loss_cls: 0.313  loss_box_reg: 0.2547  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.01946  time: 0.4376  data_time: 0.0109  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:53:24 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 7999  total_loss: 0.5268  loss_cls: 0.3067  loss_box_reg: 0.1802  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.01494  time: 0.4376  data_time: 0.0108  lr: 0.001  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:53:33 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 8019  total_loss: 0.5051  loss_cls: 0.2674  loss_box_reg: 0.1704  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.01858  time: 0.4376  data_time: 0.0108  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:53:42 d2.utils.events]: \u001b[0m eta: 0:48:21  iter: 8039  total_loss: 0.5609  loss_cls: 0.2892  loss_box_reg: 0.2175  loss_rpn_cls: 0.01389  loss_rpn_loc: 0.01631  time: 0.4376  data_time: 0.0111  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:53:51 d2.utils.events]: \u001b[0m eta: 0:48:10  iter: 8059  total_loss: 0.6228  loss_cls: 0.3447  loss_box_reg: 0.2279  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.03183  time: 0.4376  data_time: 0.0118  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:53:59 d2.utils.events]: \u001b[0m eta: 0:47:57  iter: 8079  total_loss: 0.5155  loss_cls: 0.2803  loss_box_reg: 0.2227  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01615  time: 0.4376  data_time: 0.0109  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:54:08 d2.utils.events]: \u001b[0m eta: 0:47:46  iter: 8099  total_loss: 0.639  loss_cls: 0.3024  loss_box_reg: 0.2698  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.02466  time: 0.4376  data_time: 0.0112  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:54:17 d2.utils.events]: \u001b[0m eta: 0:47:33  iter: 8119  total_loss: 0.5084  loss_cls: 0.2713  loss_box_reg: 0.1975  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.01502  time: 0.4376  data_time: 0.0109  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:54:26 d2.utils.events]: \u001b[0m eta: 0:47:23  iter: 8139  total_loss: 0.5828  loss_cls: 0.3068  loss_box_reg: 0.2734  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.02721  time: 0.4376  data_time: 0.0112  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:54:34 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 8159  total_loss: 0.522  loss_cls: 0.2978  loss_box_reg: 0.193  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.01449  time: 0.4376  data_time: 0.0113  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:54:43 d2.utils.events]: \u001b[0m eta: 0:47:02  iter: 8179  total_loss: 0.4966  loss_cls: 0.2728  loss_box_reg: 0.1931  loss_rpn_cls: 0.01506  loss_rpn_loc: 0.02212  time: 0.4376  data_time: 0.0111  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:54:52 d2.utils.events]: \u001b[0m eta: 0:46:53  iter: 8199  total_loss: 0.6312  loss_cls: 0.3199  loss_box_reg: 0.2667  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.02845  time: 0.4376  data_time: 0.0113  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:55:01 d2.utils.events]: \u001b[0m eta: 0:46:43  iter: 8219  total_loss: 0.5044  loss_cls: 0.269  loss_box_reg: 0.1996  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.02401  time: 0.4376  data_time: 0.0118  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:55:09 d2.utils.events]: \u001b[0m eta: 0:46:33  iter: 8239  total_loss: 0.5628  loss_cls: 0.3134  loss_box_reg: 0.2001  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.03306  time: 0.4375  data_time: 0.0111  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:55:18 d2.utils.events]: \u001b[0m eta: 0:46:24  iter: 8259  total_loss: 0.5682  loss_cls: 0.273  loss_box_reg: 0.2317  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.0267  time: 0.4375  data_time: 0.0111  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:55:27 d2.utils.events]: \u001b[0m eta: 0:46:14  iter: 8279  total_loss: 0.5222  loss_cls: 0.2711  loss_box_reg: 0.2059  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.02123  time: 0.4375  data_time: 0.0114  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:55:35 d2.utils.events]: \u001b[0m eta: 0:46:05  iter: 8299  total_loss: 0.5568  loss_cls: 0.281  loss_box_reg: 0.2207  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01615  time: 0.4375  data_time: 0.0109  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:55:44 d2.utils.events]: \u001b[0m eta: 0:45:55  iter: 8319  total_loss: 0.5251  loss_cls: 0.2436  loss_box_reg: 0.2122  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.01703  time: 0.4375  data_time: 0.0112  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:55:53 d2.utils.events]: \u001b[0m eta: 0:45:46  iter: 8339  total_loss: 0.5756  loss_cls: 0.2746  loss_box_reg: 0.2295  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.0165  time: 0.4375  data_time: 0.0113  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:56:02 d2.utils.events]: \u001b[0m eta: 0:45:37  iter: 8359  total_loss: 0.6195  loss_cls: 0.3353  loss_box_reg: 0.2636  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.026  time: 0.4375  data_time: 0.0110  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:56:10 d2.utils.events]: \u001b[0m eta: 0:45:28  iter: 8379  total_loss: 0.5934  loss_cls: 0.3073  loss_box_reg: 0.2605  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.02639  time: 0.4375  data_time: 0.0108  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:56:19 d2.utils.events]: \u001b[0m eta: 0:45:18  iter: 8399  total_loss: 0.6552  loss_cls: 0.3278  loss_box_reg: 0.2717  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.02182  time: 0.4375  data_time: 0.0112  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:56:28 d2.utils.events]: \u001b[0m eta: 0:45:09  iter: 8419  total_loss: 0.6253  loss_cls: 0.316  loss_box_reg: 0.25  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.0338  time: 0.4375  data_time: 0.0111  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:56:37 d2.utils.events]: \u001b[0m eta: 0:45:00  iter: 8439  total_loss: 0.5654  loss_cls: 0.3011  loss_box_reg: 0.241  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.03111  time: 0.4375  data_time: 0.0109  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:56:45 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 8459  total_loss: 0.5737  loss_cls: 0.3073  loss_box_reg: 0.2295  loss_rpn_cls: 0.01721  loss_rpn_loc: 0.02809  time: 0.4375  data_time: 0.0110  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:56:54 d2.utils.events]: \u001b[0m eta: 0:44:42  iter: 8479  total_loss: 0.5089  loss_cls: 0.256  loss_box_reg: 0.2033  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.02446  time: 0.4375  data_time: 0.0110  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:57:03 d2.utils.events]: \u001b[0m eta: 0:44:33  iter: 8499  total_loss: 0.5019  loss_cls: 0.2715  loss_box_reg: 0.2047  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.02213  time: 0.4375  data_time: 0.0107  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:57:11 d2.utils.events]: \u001b[0m eta: 0:44:24  iter: 8519  total_loss: 0.5856  loss_cls: 0.2781  loss_box_reg: 0.2601  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.02803  time: 0.4375  data_time: 0.0108  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 15:57:20 d2.utils.events]: \u001b[0m eta: 0:44:15  iter: 8539  total_loss: 0.4849  loss_cls: 0.2231  loss_box_reg: 0.2108  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.01671  time: 0.4375  data_time: 0.0107  lr: 5e-06  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 15:57:24 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/private.json\n",
      "\u001b[32m[09/09 15:57:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 15:57:24 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 15:57:24 d2.data.common]: \u001b[0mSerialized dataset takes 2.16 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 15:57:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 15:57:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/09 15:57:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0007 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:03:17\n",
      "\u001b[32m[09/09 15:57:30 d2.evaluation.evaluator]: \u001b[0mInference done 135/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:03:11\n",
      "\u001b[32m[09/09 15:57:35 d2.evaluation.evaluator]: \u001b[0mInference done 259/4871. Dataloading: 0.0010 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:03:06\n",
      "\u001b[32m[09/09 15:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 342/4871. Dataloading: 0.0010 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0455 s/iter. ETA=0:03:25\n",
      "\u001b[32m[09/09 15:57:45 d2.evaluation.evaluator]: \u001b[0mInference done 452/4871. Dataloading: 0.0010 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0455 s/iter. ETA=0:03:21\n",
      "\u001b[32m[09/09 15:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 577/4871. Dataloading: 0.0010 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0443 s/iter. ETA=0:03:10\n",
      "\u001b[32m[09/09 15:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 702/4871. Dataloading: 0.0010 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0436 s/iter. ETA=0:03:01\n",
      "\u001b[32m[09/09 15:58:00 d2.evaluation.evaluator]: \u001b[0mInference done 827/4871. Dataloading: 0.0010 s/iter. Inference: 0.0418 s/iter. Eval: 0.0002 s/iter. Total: 0.0431 s/iter. ETA=0:02:54\n",
      "\u001b[32m[09/09 15:58:05 d2.evaluation.evaluator]: \u001b[0mInference done 952/4871. Dataloading: 0.0010 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:02:47\n",
      "\u001b[32m[09/09 15:58:10 d2.evaluation.evaluator]: \u001b[0mInference done 1061/4871. Dataloading: 0.0010 s/iter. Inference: 0.0418 s/iter. Eval: 0.0002 s/iter. Total: 0.0431 s/iter. ETA=0:02:44\n",
      "\u001b[32m[09/09 15:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 1173/4871. Dataloading: 0.0010 s/iter. Inference: 0.0420 s/iter. Eval: 0.0002 s/iter. Total: 0.0432 s/iter. ETA=0:02:39\n",
      "\u001b[32m[09/09 15:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 1298/4871. Dataloading: 0.0010 s/iter. Inference: 0.0417 s/iter. Eval: 0.0002 s/iter. Total: 0.0429 s/iter. ETA=0:02:33\n",
      "\u001b[32m[09/09 15:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 1423/4871. Dataloading: 0.0010 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/09 15:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 1548/4871. Dataloading: 0.0010 s/iter. Inference: 0.0412 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:02:21\n",
      "\u001b[32m[09/09 15:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 1670/4871. Dataloading: 0.0010 s/iter. Inference: 0.0411 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:02:15\n",
      "\u001b[32m[09/09 15:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 1795/4871. Dataloading: 0.0010 s/iter. Inference: 0.0410 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:02:09\n",
      "\u001b[32m[09/09 15:58:45 d2.evaluation.evaluator]: \u001b[0mInference done 1920/4871. Dataloading: 0.0010 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:02:04\n",
      "\u001b[32m[09/09 15:58:50 d2.evaluation.evaluator]: \u001b[0mInference done 2022/4871. Dataloading: 0.0010 s/iter. Inference: 0.0412 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:02:01\n",
      "\u001b[32m[09/09 15:58:55 d2.evaluation.evaluator]: \u001b[0mInference done 2146/4871. Dataloading: 0.0010 s/iter. Inference: 0.0411 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/09 15:59:00 d2.evaluation.evaluator]: \u001b[0mInference done 2271/4871. Dataloading: 0.0010 s/iter. Inference: 0.0410 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/09 15:59:05 d2.evaluation.evaluator]: \u001b[0mInference done 2396/4871. Dataloading: 0.0010 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:44\n",
      "\u001b[32m[09/09 15:59:10 d2.evaluation.evaluator]: \u001b[0mInference done 2521/4871. Dataloading: 0.0010 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:38\n",
      "\u001b[32m[09/09 15:59:15 d2.evaluation.evaluator]: \u001b[0mInference done 2646/4871. Dataloading: 0.0010 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:33\n",
      "\u001b[32m[09/09 15:59:20 d2.evaluation.evaluator]: \u001b[0mInference done 2771/4871. Dataloading: 0.0010 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:27\n",
      "\u001b[32m[09/09 15:59:25 d2.evaluation.evaluator]: \u001b[0mInference done 2896/4871. Dataloading: 0.0010 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:22\n",
      "\u001b[32m[09/09 15:59:30 d2.evaluation.evaluator]: \u001b[0mInference done 3021/4871. Dataloading: 0.0010 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:17\n",
      "\u001b[32m[09/09 15:59:35 d2.evaluation.evaluator]: \u001b[0mInference done 3145/4871. Dataloading: 0.0010 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/09 15:59:40 d2.evaluation.evaluator]: \u001b[0mInference done 3269/4871. Dataloading: 0.0010 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:06\n",
      "\u001b[32m[09/09 15:59:45 d2.evaluation.evaluator]: \u001b[0mInference done 3391/4871. Dataloading: 0.0010 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:01\n",
      "\u001b[32m[09/09 15:59:50 d2.evaluation.evaluator]: \u001b[0mInference done 3516/4871. Dataloading: 0.0010 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:56\n",
      "\u001b[32m[09/09 15:59:55 d2.evaluation.evaluator]: \u001b[0mInference done 3641/4871. Dataloading: 0.0010 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:51\n",
      "\u001b[32m[09/09 16:00:00 d2.evaluation.evaluator]: \u001b[0mInference done 3766/4871. Dataloading: 0.0010 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:45\n",
      "\u001b[32m[09/09 16:00:05 d2.evaluation.evaluator]: \u001b[0mInference done 3891/4871. Dataloading: 0.0010 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:40\n",
      "\u001b[32m[09/09 16:00:10 d2.evaluation.evaluator]: \u001b[0mInference done 4016/4871. Dataloading: 0.0010 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:35\n",
      "\u001b[32m[09/09 16:00:15 d2.evaluation.evaluator]: \u001b[0mInference done 4141/4871. Dataloading: 0.0010 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/09 16:00:20 d2.evaluation.evaluator]: \u001b[0mInference done 4266/4871. Dataloading: 0.0011 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:25\n",
      "\u001b[32m[09/09 16:00:25 d2.evaluation.evaluator]: \u001b[0mInference done 4391/4871. Dataloading: 0.0011 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:19\n",
      "\u001b[32m[09/09 16:00:31 d2.evaluation.evaluator]: \u001b[0mInference done 4516/4871. Dataloading: 0.0011 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:14\n",
      "\u001b[32m[09/09 16:00:36 d2.evaluation.evaluator]: \u001b[0mInference done 4641/4871. Dataloading: 0.0011 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:09\n",
      "\u001b[32m[09/09 16:00:41 d2.evaluation.evaluator]: \u001b[0mInference done 4766/4871. Dataloading: 0.0011 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 16:00:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:20.507703 (0.041206 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 16:00:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:14 (0.039904 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 16:00:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/09 16:00:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.42s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 16:00:46 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 16:00:48 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.83 seconds.\n",
      "\u001b[32m[09/09 16:00:48 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 16:00:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.31 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.329\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.458\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.354\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.086\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.496\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.531\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n",
      "\u001b[32m[09/09 16:00:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 32.900 | 45.769 | 35.400 | 0.458 | 8.617 | 39.673 |\n",
      "\u001b[32m[09/09 16:00:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 17.779 | Paper       | 28.651 | Paper pack | 37.706 |\n",
      "| Metal         | 34.996 | Glass       | 32.876 | Plastic    | 24.883 |\n",
      "| Styrofoam     | 33.526 | Plastic bag | 50.814 | Battery    | 35.489 |\n",
      "| Clothing      | 32.282 |             |        |            |        |\n",
      "\u001b[32m[09/09 16:00:49 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/09 16:00:49 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 16:00:49 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 16:00:49 d2.evaluation.testing]: \u001b[0mcopypaste: 32.9001,45.7687,35.4002,0.4584,8.6174,39.6728\n",
      "\u001b[32m[09/09 16:00:54 d2.utils.events]: \u001b[0m eta: 0:44:06  iter: 8559  total_loss: 0.3939  loss_cls: 0.2173  loss_box_reg: 0.1582  loss_rpn_cls: 0.008291  loss_rpn_loc: 0.01042  time: 0.4374  data_time: 0.0109  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:01:03 d2.utils.events]: \u001b[0m eta: 0:43:57  iter: 8579  total_loss: 0.5047  loss_cls: 0.2529  loss_box_reg: 0.2059  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.01988  time: 0.4374  data_time: 0.0107  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:01:12 d2.utils.events]: \u001b[0m eta: 0:43:48  iter: 8599  total_loss: 0.5119  loss_cls: 0.2418  loss_box_reg: 0.2433  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.02617  time: 0.4374  data_time: 0.0109  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:01:20 d2.utils.events]: \u001b[0m eta: 0:43:39  iter: 8619  total_loss: 0.488  loss_cls: 0.2365  loss_box_reg: 0.2322  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.01498  time: 0.4374  data_time: 0.0111  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:01:29 d2.utils.events]: \u001b[0m eta: 0:43:30  iter: 8639  total_loss: 0.5161  loss_cls: 0.2643  loss_box_reg: 0.2169  loss_rpn_cls: 0.01758  loss_rpn_loc: 0.01855  time: 0.4374  data_time: 0.0111  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:01:38 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 8659  total_loss: 0.5882  loss_cls: 0.3163  loss_box_reg: 0.2185  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.03742  time: 0.4374  data_time: 0.0112  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:01:47 d2.utils.events]: \u001b[0m eta: 0:43:13  iter: 8679  total_loss: 0.5228  loss_cls: 0.2536  loss_box_reg: 0.2226  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.01707  time: 0.4374  data_time: 0.0107  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:01:55 d2.utils.events]: \u001b[0m eta: 0:43:04  iter: 8699  total_loss: 0.54  loss_cls: 0.2823  loss_box_reg: 0.239  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.01923  time: 0.4374  data_time: 0.0106  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:02:04 d2.utils.events]: \u001b[0m eta: 0:42:55  iter: 8719  total_loss: 0.5695  loss_cls: 0.3047  loss_box_reg: 0.2195  loss_rpn_cls: 0.01633  loss_rpn_loc: 0.03089  time: 0.4374  data_time: 0.0110  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:02:13 d2.utils.events]: \u001b[0m eta: 0:42:47  iter: 8739  total_loss: 0.5364  loss_cls: 0.2516  loss_box_reg: 0.2074  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.02581  time: 0.4374  data_time: 0.0109  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:02:21 d2.utils.events]: \u001b[0m eta: 0:42:38  iter: 8759  total_loss: 0.5543  loss_cls: 0.2922  loss_box_reg: 0.2009  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.01956  time: 0.4374  data_time: 0.0109  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:02:30 d2.utils.events]: \u001b[0m eta: 0:42:29  iter: 8779  total_loss: 0.6286  loss_cls: 0.2945  loss_box_reg: 0.247  loss_rpn_cls: 0.0234  loss_rpn_loc: 0.03629  time: 0.4374  data_time: 0.0105  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:02:39 d2.utils.events]: \u001b[0m eta: 0:42:20  iter: 8799  total_loss: 0.4788  loss_cls: 0.2523  loss_box_reg: 0.1988  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.02126  time: 0.4373  data_time: 0.0108  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:02:48 d2.utils.events]: \u001b[0m eta: 0:42:12  iter: 8819  total_loss: 0.5331  loss_cls: 0.246  loss_box_reg: 0.2274  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.02364  time: 0.4373  data_time: 0.0112  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:02:56 d2.utils.events]: \u001b[0m eta: 0:42:03  iter: 8839  total_loss: 0.5355  loss_cls: 0.2575  loss_box_reg: 0.1787  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.0215  time: 0.4373  data_time: 0.0110  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:03:05 d2.utils.events]: \u001b[0m eta: 0:41:54  iter: 8859  total_loss: 0.5401  loss_cls: 0.2483  loss_box_reg: 0.212  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.03646  time: 0.4373  data_time: 0.0110  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:03:14 d2.utils.events]: \u001b[0m eta: 0:41:45  iter: 8879  total_loss: 0.4515  loss_cls: 0.2299  loss_box_reg: 0.1912  loss_rpn_cls: 0.009756  loss_rpn_loc: 0.01182  time: 0.4373  data_time: 0.0106  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:03:22 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 8899  total_loss: 0.5158  loss_cls: 0.254  loss_box_reg: 0.1805  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.02952  time: 0.4373  data_time: 0.0105  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:03:31 d2.utils.events]: \u001b[0m eta: 0:41:27  iter: 8919  total_loss: 0.4643  loss_cls: 0.2485  loss_box_reg: 0.1578  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.01864  time: 0.4373  data_time: 0.0111  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:03:40 d2.utils.events]: \u001b[0m eta: 0:41:19  iter: 8939  total_loss: 0.5175  loss_cls: 0.2943  loss_box_reg: 0.1901  loss_rpn_cls: 0.00953  loss_rpn_loc: 0.01398  time: 0.4373  data_time: 0.0110  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:03:48 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 8959  total_loss: 0.6003  loss_cls: 0.3046  loss_box_reg: 0.2179  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.02268  time: 0.4373  data_time: 0.0108  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:03:57 d2.utils.events]: \u001b[0m eta: 0:41:01  iter: 8979  total_loss: 0.4605  loss_cls: 0.2333  loss_box_reg: 0.2141  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.01664  time: 0.4373  data_time: 0.0107  lr: 5e-06  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 16:04:06 d2.utils.events]: \u001b[0m eta: 0:40:52  iter: 8999  total_loss: 0.5775  loss_cls: 0.2893  loss_box_reg: 0.2373  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.02713  time: 0.4373  data_time: 0.0105  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:04:14 d2.utils.events]: \u001b[0m eta: 0:40:44  iter: 9019  total_loss: 0.5337  loss_cls: 0.2745  loss_box_reg: 0.1822  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.02099  time: 0.4373  data_time: 0.0108  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:04:23 d2.utils.events]: \u001b[0m eta: 0:40:35  iter: 9039  total_loss: 0.5204  loss_cls: 0.2492  loss_box_reg: 0.2256  loss_rpn_cls: 0.01906  loss_rpn_loc: 0.02421  time: 0.4373  data_time: 0.0110  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:04:32 d2.utils.events]: \u001b[0m eta: 0:40:26  iter: 9059  total_loss: 0.606  loss_cls: 0.3122  loss_box_reg: 0.2395  loss_rpn_cls: 0.01677  loss_rpn_loc: 0.04389  time: 0.4372  data_time: 0.0108  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:04:41 d2.utils.events]: \u001b[0m eta: 0:40:17  iter: 9079  total_loss: 0.5366  loss_cls: 0.2837  loss_box_reg: 0.1992  loss_rpn_cls: 0.012  loss_rpn_loc: 0.01872  time: 0.4372  data_time: 0.0108  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:04:49 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 9099  total_loss: 0.5683  loss_cls: 0.277  loss_box_reg: 0.2407  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.02515  time: 0.4372  data_time: 0.0107  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:04:58 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 9119  total_loss: 0.3862  loss_cls: 0.1798  loss_box_reg: 0.145  loss_rpn_cls: 0.009593  loss_rpn_loc: 0.02183  time: 0.4372  data_time: 0.0107  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:05:07 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 9139  total_loss: 0.5183  loss_cls: 0.2744  loss_box_reg: 0.2081  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.0205  time: 0.4372  data_time: 0.0106  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:05:16 d2.utils.events]: \u001b[0m eta: 0:39:42  iter: 9159  total_loss: 0.6155  loss_cls: 0.2648  loss_box_reg: 0.243  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.02742  time: 0.4373  data_time: 0.0138  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:05:25 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 9179  total_loss: 0.491  loss_cls: 0.2476  loss_box_reg: 0.2129  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.02339  time: 0.4373  data_time: 0.0120  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:05:34 d2.utils.events]: \u001b[0m eta: 0:39:25  iter: 9199  total_loss: 0.5861  loss_cls: 0.3159  loss_box_reg: 0.222  loss_rpn_cls: 0.00936  loss_rpn_loc: 0.02134  time: 0.4373  data_time: 0.0126  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:05:43 d2.utils.events]: \u001b[0m eta: 0:39:17  iter: 9219  total_loss: 0.6118  loss_cls: 0.3199  loss_box_reg: 0.2623  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.01789  time: 0.4373  data_time: 0.0145  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:05:52 d2.utils.events]: \u001b[0m eta: 0:39:08  iter: 9239  total_loss: 0.5675  loss_cls: 0.2883  loss_box_reg: 0.2058  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.02542  time: 0.4374  data_time: 0.0128  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:06:01 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 9259  total_loss: 0.4912  loss_cls: 0.24  loss_box_reg: 0.2145  loss_rpn_cls: 0.008836  loss_rpn_loc: 0.01871  time: 0.4374  data_time: 0.0150  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:06:10 d2.utils.events]: \u001b[0m eta: 0:38:51  iter: 9279  total_loss: 0.4866  loss_cls: 0.2531  loss_box_reg: 0.2143  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.01922  time: 0.4374  data_time: 0.0113  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:06:19 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 9299  total_loss: 0.4737  loss_cls: 0.2415  loss_box_reg: 0.1942  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.02235  time: 0.4375  data_time: 0.0115  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:06:28 d2.utils.events]: \u001b[0m eta: 0:38:35  iter: 9319  total_loss: 0.4862  loss_cls: 0.2583  loss_box_reg: 0.2197  loss_rpn_cls: 0.01684  loss_rpn_loc: 0.01616  time: 0.4375  data_time: 0.0131  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:06:37 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 9339  total_loss: 0.5817  loss_cls: 0.2813  loss_box_reg: 0.2437  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.02801  time: 0.4375  data_time: 0.0129  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:06:47 d2.utils.events]: \u001b[0m eta: 0:38:18  iter: 9359  total_loss: 0.5035  loss_cls: 0.2724  loss_box_reg: 0.2039  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.02407  time: 0.4376  data_time: 0.0150  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:06:56 d2.utils.events]: \u001b[0m eta: 0:38:10  iter: 9379  total_loss: 0.5436  loss_cls: 0.2477  loss_box_reg: 0.2512  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.02337  time: 0.4376  data_time: 0.0154  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:07:05 d2.utils.events]: \u001b[0m eta: 0:38:02  iter: 9399  total_loss: 0.4645  loss_cls: 0.2582  loss_box_reg: 0.1846  loss_rpn_cls: 0.007505  loss_rpn_loc: 0.01578  time: 0.4376  data_time: 0.0122  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:07:14 d2.utils.events]: \u001b[0m eta: 0:37:53  iter: 9419  total_loss: 0.5231  loss_cls: 0.2643  loss_box_reg: 0.2063  loss_rpn_cls: 0.01436  loss_rpn_loc: 0.01904  time: 0.4377  data_time: 0.0152  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:07:23 d2.utils.events]: \u001b[0m eta: 0:37:45  iter: 9439  total_loss: 0.3963  loss_cls: 0.2055  loss_box_reg: 0.1615  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.0208  time: 0.4377  data_time: 0.0160  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:07:32 d2.utils.events]: \u001b[0m eta: 0:37:37  iter: 9459  total_loss: 0.5345  loss_cls: 0.249  loss_box_reg: 0.2015  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.02173  time: 0.4377  data_time: 0.0146  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:07:41 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 9479  total_loss: 0.5774  loss_cls: 0.2582  loss_box_reg: 0.1928  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.02631  time: 0.4378  data_time: 0.0137  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:07:50 d2.utils.events]: \u001b[0m eta: 0:37:21  iter: 9499  total_loss: 0.6666  loss_cls: 0.3213  loss_box_reg: 0.2821  loss_rpn_cls: 0.02392  loss_rpn_loc: 0.03471  time: 0.4378  data_time: 0.0132  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:07:59 d2.utils.events]: \u001b[0m eta: 0:37:14  iter: 9519  total_loss: 0.5649  loss_cls: 0.2719  loss_box_reg: 0.2281  loss_rpn_cls: 0.007261  loss_rpn_loc: 0.01801  time: 0.4379  data_time: 0.0171  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:08:08 d2.utils.events]: \u001b[0m eta: 0:37:07  iter: 9539  total_loss: 0.5754  loss_cls: 0.2535  loss_box_reg: 0.2329  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.02701  time: 0.4379  data_time: 0.0144  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:08:17 d2.utils.events]: \u001b[0m eta: 0:37:00  iter: 9559  total_loss: 0.4581  loss_cls: 0.2345  loss_box_reg: 0.1996  loss_rpn_cls: 0.01365  loss_rpn_loc: 0.02223  time: 0.4379  data_time: 0.0119  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:08:26 d2.utils.events]: \u001b[0m eta: 0:36:54  iter: 9579  total_loss: 0.5401  loss_cls: 0.278  loss_box_reg: 0.2361  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.01505  time: 0.4379  data_time: 0.0134  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:08:36 d2.utils.events]: \u001b[0m eta: 0:36:48  iter: 9599  total_loss: 0.5716  loss_cls: 0.2772  loss_box_reg: 0.2196  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.0243  time: 0.4380  data_time: 0.0129  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:08:45 d2.utils.events]: \u001b[0m eta: 0:36:43  iter: 9619  total_loss: 0.4029  loss_cls: 0.2325  loss_box_reg: 0.1638  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.01602  time: 0.4380  data_time: 0.0132  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:08:54 d2.utils.events]: \u001b[0m eta: 0:36:37  iter: 9639  total_loss: 0.581  loss_cls: 0.2852  loss_box_reg: 0.2439  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.02244  time: 0.4380  data_time: 0.0141  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:09:03 d2.utils.events]: \u001b[0m eta: 0:36:32  iter: 9659  total_loss: 0.5374  loss_cls: 0.2737  loss_box_reg: 0.1913  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.04257  time: 0.4380  data_time: 0.0129  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:09:12 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 9679  total_loss: 0.4539  loss_cls: 0.2155  loss_box_reg: 0.1988  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01839  time: 0.4381  data_time: 0.0179  lr: 5e-06  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 16:09:21 d2.utils.events]: \u001b[0m eta: 0:36:18  iter: 9699  total_loss: 0.5209  loss_cls: 0.2617  loss_box_reg: 0.1844  loss_rpn_cls: 0.0105  loss_rpn_loc: 0.01681  time: 0.4381  data_time: 0.0152  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:09:30 d2.utils.events]: \u001b[0m eta: 0:36:12  iter: 9719  total_loss: 0.5863  loss_cls: 0.3086  loss_box_reg: 0.2064  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.02037  time: 0.4381  data_time: 0.0124  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:09:39 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 9739  total_loss: 0.4895  loss_cls: 0.2603  loss_box_reg: 0.2054  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.01852  time: 0.4382  data_time: 0.0158  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:09:48 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 9759  total_loss: 0.528  loss_cls: 0.2642  loss_box_reg: 0.2286  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.02293  time: 0.4382  data_time: 0.0158  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:09:53 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/private.json\n",
      "\u001b[32m[09/09 16:09:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/09 16:09:53 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/09 16:09:53 d2.data.common]: \u001b[0mSerialized dataset takes 2.16 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/09 16:09:53 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/09 16:09:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[09/09 16:09:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0016 s/iter. Inference: 0.0488 s/iter. Eval: 0.0008 s/iter. Total: 0.0511 s/iter. ETA=0:04:08\n",
      "\u001b[32m[09/09 16:09:59 d2.evaluation.evaluator]: \u001b[0mInference done 119/4871. Dataloading: 0.0015 s/iter. Inference: 0.0450 s/iter. Eval: 0.0003 s/iter. Total: 0.0468 s/iter. ETA=0:03:42\n",
      "\u001b[32m[09/09 16:10:04 d2.evaluation.evaluator]: \u001b[0mInference done 232/4871. Dataloading: 0.0014 s/iter. Inference: 0.0439 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:03:31\n",
      "\u001b[32m[09/09 16:10:09 d2.evaluation.evaluator]: \u001b[0mInference done 349/4871. Dataloading: 0.0013 s/iter. Inference: 0.0430 s/iter. Eval: 0.0002 s/iter. Total: 0.0447 s/iter. ETA=0:03:22\n",
      "\u001b[32m[09/09 16:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 458/4871. Dataloading: 0.0014 s/iter. Inference: 0.0433 s/iter. Eval: 0.0002 s/iter. Total: 0.0450 s/iter. ETA=0:03:18\n",
      "\u001b[32m[09/09 16:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 567/4871. Dataloading: 0.0014 s/iter. Inference: 0.0435 s/iter. Eval: 0.0002 s/iter. Total: 0.0452 s/iter. ETA=0:03:14\n",
      "\u001b[32m[09/09 16:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 679/4871. Dataloading: 0.0014 s/iter. Inference: 0.0435 s/iter. Eval: 0.0003 s/iter. Total: 0.0452 s/iter. ETA=0:03:09\n",
      "\u001b[32m[09/09 16:10:29 d2.evaluation.evaluator]: \u001b[0mInference done 791/4871. Dataloading: 0.0013 s/iter. Inference: 0.0435 s/iter. Eval: 0.0002 s/iter. Total: 0.0451 s/iter. ETA=0:03:04\n",
      "\u001b[32m[09/09 16:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 910/4871. Dataloading: 0.0013 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0447 s/iter. ETA=0:02:57\n",
      "\u001b[32m[09/09 16:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 1028/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:02:50\n",
      "\u001b[32m[09/09 16:10:44 d2.evaluation.evaluator]: \u001b[0mInference done 1150/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0002 s/iter. Total: 0.0441 s/iter. ETA=0:02:44\n",
      "\u001b[32m[09/09 16:10:49 d2.evaluation.evaluator]: \u001b[0mInference done 1270/4871. Dataloading: 0.0012 s/iter. Inference: 0.0424 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:02:38\n",
      "\u001b[32m[09/09 16:10:54 d2.evaluation.evaluator]: \u001b[0mInference done 1381/4871. Dataloading: 0.0012 s/iter. Inference: 0.0425 s/iter. Eval: 0.0002 s/iter. Total: 0.0440 s/iter. ETA=0:02:33\n",
      "\u001b[32m[09/09 16:10:59 d2.evaluation.evaluator]: \u001b[0mInference done 1479/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/09 16:11:04 d2.evaluation.evaluator]: \u001b[0mInference done 1594/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/09 16:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 1709/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0002 s/iter. Total: 0.0444 s/iter. ETA=0:02:20\n",
      "\u001b[32m[09/09 16:11:14 d2.evaluation.evaluator]: \u001b[0mInference done 1822/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0002 s/iter. Total: 0.0444 s/iter. ETA=0:02:15\n",
      "\u001b[32m[09/09 16:11:19 d2.evaluation.evaluator]: \u001b[0mInference done 1931/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/09 16:11:24 d2.evaluation.evaluator]: \u001b[0mInference done 2045/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:02:05\n",
      "\u001b[32m[09/09 16:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 2164/4871. Dataloading: 0.0013 s/iter. Inference: 0.0428 s/iter. Eval: 0.0002 s/iter. Total: 0.0444 s/iter. ETA=0:02:00\n",
      "\u001b[32m[09/09 16:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 2284/4871. Dataloading: 0.0013 s/iter. Inference: 0.0426 s/iter. Eval: 0.0002 s/iter. Total: 0.0442 s/iter. ETA=0:01:54\n",
      "\u001b[32m[09/09 16:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 2406/4871. Dataloading: 0.0013 s/iter. Inference: 0.0425 s/iter. Eval: 0.0002 s/iter. Total: 0.0441 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/09 16:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 2524/4871. Dataloading: 0.0013 s/iter. Inference: 0.0424 s/iter. Eval: 0.0002 s/iter. Total: 0.0440 s/iter. ETA=0:01:43\n",
      "\u001b[32m[09/09 16:11:50 d2.evaluation.evaluator]: \u001b[0mInference done 2644/4871. Dataloading: 0.0013 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/09 16:11:55 d2.evaluation.evaluator]: \u001b[0mInference done 2765/4871. Dataloading: 0.0012 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0438 s/iter. ETA=0:01:32\n",
      "\u001b[32m[09/09 16:12:00 d2.evaluation.evaluator]: \u001b[0mInference done 2876/4871. Dataloading: 0.0013 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0438 s/iter. ETA=0:01:27\n",
      "\u001b[32m[09/09 16:12:05 d2.evaluation.evaluator]: \u001b[0mInference done 2989/4871. Dataloading: 0.0013 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:01:22\n",
      "\u001b[32m[09/09 16:12:10 d2.evaluation.evaluator]: \u001b[0mInference done 3103/4871. Dataloading: 0.0013 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:01:17\n",
      "\u001b[32m[09/09 16:12:15 d2.evaluation.evaluator]: \u001b[0mInference done 3217/4871. Dataloading: 0.0013 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:01:12\n",
      "\u001b[32m[09/09 16:12:20 d2.evaluation.evaluator]: \u001b[0mInference done 3328/4871. Dataloading: 0.0012 s/iter. Inference: 0.0424 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:01:07\n",
      "\u001b[32m[09/09 16:12:25 d2.evaluation.evaluator]: \u001b[0mInference done 3443/4871. Dataloading: 0.0013 s/iter. Inference: 0.0424 s/iter. Eval: 0.0002 s/iter. Total: 0.0439 s/iter. ETA=0:01:02\n",
      "\u001b[32m[09/09 16:12:30 d2.evaluation.evaluator]: \u001b[0mInference done 3564/4871. Dataloading: 0.0012 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0438 s/iter. ETA=0:00:57\n",
      "\u001b[32m[09/09 16:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 3683/4871. Dataloading: 0.0012 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0438 s/iter. ETA=0:00:52\n",
      "\u001b[32m[09/09 16:12:40 d2.evaluation.evaluator]: \u001b[0mInference done 3805/4871. Dataloading: 0.0012 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0437 s/iter. ETA=0:00:46\n",
      "\u001b[32m[09/09 16:12:45 d2.evaluation.evaluator]: \u001b[0mInference done 3920/4871. Dataloading: 0.0012 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0437 s/iter. ETA=0:00:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 16:12:50 d2.evaluation.evaluator]: \u001b[0mInference done 4032/4871. Dataloading: 0.0012 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0437 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/09 16:12:55 d2.evaluation.evaluator]: \u001b[0mInference done 4150/4871. Dataloading: 0.0012 s/iter. Inference: 0.0422 s/iter. Eval: 0.0002 s/iter. Total: 0.0437 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/09 16:13:00 d2.evaluation.evaluator]: \u001b[0mInference done 4268/4871. Dataloading: 0.0013 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0437 s/iter. ETA=0:00:26\n",
      "\u001b[32m[09/09 16:13:05 d2.evaluation.evaluator]: \u001b[0mInference done 4391/4871. Dataloading: 0.0013 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0436 s/iter. ETA=0:00:20\n",
      "\u001b[32m[09/09 16:13:10 d2.evaluation.evaluator]: \u001b[0mInference done 4502/4871. Dataloading: 0.0013 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0437 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/09 16:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 4618/4871. Dataloading: 0.0013 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0436 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/09 16:13:20 d2.evaluation.evaluator]: \u001b[0mInference done 4733/4871. Dataloading: 0.0013 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0436 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/09 16:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 4850/4871. Dataloading: 0.0012 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0436 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/09 16:13:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:32.427184 (0.043655 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 16:13:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:24 (0.042077 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/09 16:13:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/09 16:13:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[09/09 16:13:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/09 16:13:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/09 16:13:30 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.23 seconds.\n",
      "\u001b[32m[09/09 16:13:30 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/09 16:13:31 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.37 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.461\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.358\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.089\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.271\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.499\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.615\n",
      "\u001b[32m[09/09 16:13:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 33.479 | 46.123 | 35.849 | 0.410 | 8.880 | 40.389 |\n",
      "\u001b[32m[09/09 16:13:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 18.706 | Paper       | 28.602 | Paper pack | 38.539 |\n",
      "| Metal         | 35.554 | Glass       | 34.403 | Plastic    | 25.292 |\n",
      "| Styrofoam     | 33.170 | Plastic bag | 51.310 | Battery    | 36.368 |\n",
      "| Clothing      | 32.851 |             |        |            |        |\n",
      "\u001b[32m[09/09 16:13:31 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[09/09 16:13:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/09 16:13:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/09 16:13:31 d2.evaluation.testing]: \u001b[0mcopypaste: 33.4794,46.1227,35.8489,0.4095,8.8795,40.3886\n",
      "\u001b[32m[09/09 16:13:37 d2.utils.events]: \u001b[0m eta: 0:35:50  iter: 9779  total_loss: 0.5919  loss_cls: 0.3018  loss_box_reg: 0.2194  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.02042  time: 0.4383  data_time: 0.0166  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:13:46 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 9799  total_loss: 0.4899  loss_cls: 0.2374  loss_box_reg: 0.2271  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.02312  time: 0.4383  data_time: 0.0152  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:13:55 d2.utils.events]: \u001b[0m eta: 0:35:35  iter: 9819  total_loss: 0.5356  loss_cls: 0.2893  loss_box_reg: 0.2131  loss_rpn_cls: 0.009575  loss_rpn_loc: 0.03384  time: 0.4383  data_time: 0.0137  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:14:04 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 9839  total_loss: 0.5376  loss_cls: 0.2627  loss_box_reg: 0.2347  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.01924  time: 0.4384  data_time: 0.0160  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:14:13 d2.utils.events]: \u001b[0m eta: 0:35:19  iter: 9859  total_loss: 0.569  loss_cls: 0.299  loss_box_reg: 0.218  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.02365  time: 0.4384  data_time: 0.0151  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:14:22 d2.utils.events]: \u001b[0m eta: 0:35:12  iter: 9879  total_loss: 0.6008  loss_cls: 0.293  loss_box_reg: 0.2098  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.02283  time: 0.4384  data_time: 0.0199  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:14:32 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 9899  total_loss: 0.5582  loss_cls: 0.2924  loss_box_reg: 0.2256  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.02692  time: 0.4385  data_time: 0.0158  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:14:41 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 9919  total_loss: 0.4654  loss_cls: 0.2534  loss_box_reg: 0.1976  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.01693  time: 0.4385  data_time: 0.0163  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:14:50 d2.utils.events]: \u001b[0m eta: 0:34:51  iter: 9939  total_loss: 0.5201  loss_cls: 0.2604  loss_box_reg: 0.2242  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.02373  time: 0.4386  data_time: 0.0208  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:14:59 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 9959  total_loss: 0.5304  loss_cls: 0.2733  loss_box_reg: 0.2415  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.01982  time: 0.4386  data_time: 0.0141  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:15:08 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 9979  total_loss: 0.4746  loss_cls: 0.2352  loss_box_reg: 0.2008  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.01635  time: 0.4386  data_time: 0.0126  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:15:17 d2.utils.events]: \u001b[0m eta: 0:34:28  iter: 9999  total_loss: 0.5874  loss_cls: 0.2924  loss_box_reg: 0.213  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.02629  time: 0.4387  data_time: 0.0186  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:15:26 d2.utils.events]: \u001b[0m eta: 0:34:21  iter: 10019  total_loss: 0.4936  loss_cls: 0.2714  loss_box_reg: 0.1831  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.01289  time: 0.4387  data_time: 0.0145  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:15:36 d2.utils.events]: \u001b[0m eta: 0:34:13  iter: 10039  total_loss: 0.5271  loss_cls: 0.251  loss_box_reg: 0.2003  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.01979  time: 0.4387  data_time: 0.0143  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:15:44 d2.utils.events]: \u001b[0m eta: 0:34:06  iter: 10059  total_loss: 0.4968  loss_cls: 0.2543  loss_box_reg: 0.1821  loss_rpn_cls: 0.009436  loss_rpn_loc: 0.01488  time: 0.4387  data_time: 0.0139  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:15:54 d2.utils.events]: \u001b[0m eta: 0:33:58  iter: 10079  total_loss: 0.5405  loss_cls: 0.249  loss_box_reg: 0.1968  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.02986  time: 0.4388  data_time: 0.0176  lr: 5e-06  max_mem: 12916M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/09 16:16:03 d2.utils.events]: \u001b[0m eta: 0:33:51  iter: 10099  total_loss: 0.4543  loss_cls: 0.2278  loss_box_reg: 0.1924  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.01535  time: 0.4388  data_time: 0.0154  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:16:12 d2.utils.events]: \u001b[0m eta: 0:33:42  iter: 10119  total_loss: 0.6084  loss_cls: 0.2854  loss_box_reg: 0.2182  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.01917  time: 0.4388  data_time: 0.0124  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:16:21 d2.utils.events]: \u001b[0m eta: 0:33:34  iter: 10139  total_loss: 0.4656  loss_cls: 0.2181  loss_box_reg: 0.1986  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.03103  time: 0.4388  data_time: 0.0134  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:16:30 d2.utils.events]: \u001b[0m eta: 0:33:25  iter: 10159  total_loss: 0.4951  loss_cls: 0.2871  loss_box_reg: 0.1693  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.02914  time: 0.4389  data_time: 0.0138  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:16:39 d2.utils.events]: \u001b[0m eta: 0:33:17  iter: 10179  total_loss: 0.6441  loss_cls: 0.2914  loss_box_reg: 0.2569  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.0435  time: 0.4389  data_time: 0.0143  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:16:48 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 10199  total_loss: 0.4208  loss_cls: 0.2275  loss_box_reg: 0.1649  loss_rpn_cls: 0.009514  loss_rpn_loc: 0.0165  time: 0.4389  data_time: 0.0131  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:16:57 d2.utils.events]: \u001b[0m eta: 0:32:59  iter: 10219  total_loss: 0.5177  loss_cls: 0.2697  loss_box_reg: 0.2324  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.01536  time: 0.4390  data_time: 0.0167  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:17:06 d2.utils.events]: \u001b[0m eta: 0:32:50  iter: 10239  total_loss: 0.6265  loss_cls: 0.2872  loss_box_reg: 0.2606  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.03289  time: 0.4390  data_time: 0.0141  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:17:15 d2.utils.events]: \u001b[0m eta: 0:32:40  iter: 10259  total_loss: 0.475  loss_cls: 0.2192  loss_box_reg: 0.2085  loss_rpn_cls: 0.01339  loss_rpn_loc: 0.01938  time: 0.4390  data_time: 0.0121  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:17:24 d2.utils.events]: \u001b[0m eta: 0:32:32  iter: 10279  total_loss: 0.5335  loss_cls: 0.2773  loss_box_reg: 0.2133  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.01873  time: 0.4390  data_time: 0.0126  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:17:34 d2.utils.events]: \u001b[0m eta: 0:32:23  iter: 10299  total_loss: 0.5261  loss_cls: 0.3017  loss_box_reg: 0.1941  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.02065  time: 0.4391  data_time: 0.0156  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:17:43 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 10319  total_loss: 0.4683  loss_cls: 0.2522  loss_box_reg: 0.1978  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.0177  time: 0.4391  data_time: 0.0162  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:17:52 d2.utils.events]: \u001b[0m eta: 0:32:06  iter: 10339  total_loss: 0.5091  loss_cls: 0.2755  loss_box_reg: 0.2273  loss_rpn_cls: 0.01729  loss_rpn_loc: 0.01941  time: 0.4391  data_time: 0.0173  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:18:01 d2.utils.events]: \u001b[0m eta: 0:31:56  iter: 10359  total_loss: 0.4308  loss_cls: 0.236  loss_box_reg: 0.1735  loss_rpn_cls: 0.008033  loss_rpn_loc: 0.01231  time: 0.4392  data_time: 0.0130  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:18:10 d2.utils.events]: \u001b[0m eta: 0:31:46  iter: 10379  total_loss: 0.6004  loss_cls: 0.2683  loss_box_reg: 0.2392  loss_rpn_cls: 0.01635  loss_rpn_loc: 0.02689  time: 0.4392  data_time: 0.0125  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:18:19 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 10399  total_loss: 0.4497  loss_cls: 0.2568  loss_box_reg: 0.1832  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.02222  time: 0.4392  data_time: 0.0136  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:18:28 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 10419  total_loss: 0.5783  loss_cls: 0.3063  loss_box_reg: 0.2145  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.02472  time: 0.4392  data_time: 0.0139  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:18:37 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 10439  total_loss: 0.5236  loss_cls: 0.2675  loss_box_reg: 0.2037  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.02377  time: 0.4392  data_time: 0.0136  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:18:46 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 10459  total_loss: 0.4489  loss_cls: 0.2258  loss_box_reg: 0.1795  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.0209  time: 0.4392  data_time: 0.0143  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:18:55 d2.utils.events]: \u001b[0m eta: 0:30:59  iter: 10479  total_loss: 0.4543  loss_cls: 0.2334  loss_box_reg: 0.201  loss_rpn_cls: 0.008199  loss_rpn_loc: 0.0136  time: 0.4393  data_time: 0.0165  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:19:04 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 10499  total_loss: 0.5386  loss_cls: 0.278  loss_box_reg: 0.2111  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.01386  time: 0.4393  data_time: 0.0140  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:19:13 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 10519  total_loss: 0.5311  loss_cls: 0.2583  loss_box_reg: 0.2024  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.02473  time: 0.4393  data_time: 0.0174  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:19:23 d2.utils.events]: \u001b[0m eta: 0:30:33  iter: 10539  total_loss: 0.5918  loss_cls: 0.2982  loss_box_reg: 0.2101  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.02406  time: 0.4394  data_time: 0.0165  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:19:34 d2.utils.events]: \u001b[0m eta: 0:30:26  iter: 10559  total_loss: 0.599  loss_cls: 0.2803  loss_box_reg: 0.2248  loss_rpn_cls: 0.02234  loss_rpn_loc: 0.03256  time: 0.4397  data_time: 0.0132  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:19:47 d2.utils.events]: \u001b[0m eta: 0:30:18  iter: 10579  total_loss: 0.5031  loss_cls: 0.2651  loss_box_reg: 0.2337  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.01922  time: 0.4400  data_time: 0.0159  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:20:00 d2.utils.events]: \u001b[0m eta: 0:30:10  iter: 10599  total_loss: 0.5191  loss_cls: 0.2695  loss_box_reg: 0.2225  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.01576  time: 0.4404  data_time: 0.0161  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:20:13 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 10619  total_loss: 0.5095  loss_cls: 0.245  loss_box_reg: 0.2035  loss_rpn_cls: 0.009265  loss_rpn_loc: 0.02106  time: 0.4408  data_time: 0.0164  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:20:25 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 10639  total_loss: 0.5581  loss_cls: 0.3148  loss_box_reg: 0.2146  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01448  time: 0.4411  data_time: 0.0130  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:20:38 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 10659  total_loss: 0.4895  loss_cls: 0.2409  loss_box_reg: 0.1818  loss_rpn_cls: 0.009108  loss_rpn_loc: 0.01835  time: 0.4415  data_time: 0.0141  lr: 5e-06  max_mem: 12916M\n",
      "\u001b[32m[09/09 16:20:51 d2.utils.events]: \u001b[0m eta: 0:29:42  iter: 10679  total_loss: 0.5357  loss_cls: 0.2919  loss_box_reg: 0.2019  loss_rpn_cls: 0.008866  loss_rpn_loc: 0.01961  time: 0.4419  data_time: 0.0165  lr: 5e-06  max_mem: 12916M\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

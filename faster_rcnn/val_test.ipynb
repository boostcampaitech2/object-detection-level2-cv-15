{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "# faster rcnn model이 포함된 library\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(target):\n",
    "    # target 에 존재하는 train.json 파일을 엽니다.\n",
    "    with open(target, 'r') as f:\n",
    "        json_datas = json.load(f) # python dict 처럼 접근하게끔 변환\n",
    "    \t#dict_keys(['info', 'licenses', 'images', 'categories', 'annotations'])\n",
    "\n",
    "    category = {}\n",
    "    file_info = {}\n",
    "    make_frame = defaultdict(list)\n",
    "\n",
    "    # 이미지 정보 중 파일 경로와 아이디만 추출해서 file_info 에 저장\n",
    "    for item in json_datas['images']:\n",
    "        file_info[item['id']] = {'id' : item['id'], 'file_name' : item['file_name']}\n",
    "    # 카테고리 정보를 category 에 저장\n",
    "    for item in json_datas['categories']:\n",
    "        category[item['id']] = item['name']\n",
    "    # annotations 에 속하는 아이템들을 images 에 속하는 아이템의 정보와 합치기 위함\n",
    "    for annotation in json_datas['annotations']:\n",
    "        save_dict = file_info[annotation['image_id']]\n",
    "        # 각 이미지에 해당하는 bounding box 정보와 class 정보 area(넓이) 정보를 추가\n",
    "        bbox = np.array(annotation['bbox'])\n",
    "        bbox[2] = bbox[2] + bbox[0]\n",
    "        bbox[3] = bbox[3] + bbox[1]\n",
    "        save_dict.update({\n",
    "            'class': annotation['category_id'], # 배경은 0, 나머지 +1 in faster_rcnn\n",
    "            'x_min': bbox[0],\n",
    "            'y_min': bbox[1],\n",
    "            'x_max': bbox[2],\n",
    "            'y_max': bbox[3],\n",
    "            'area':annotation['area']\n",
    "            })\n",
    "\n",
    "        for k,v in save_dict.items():\n",
    "            # dataframe 으로 만들기 위해서 'key' : [item1,item2...] 형태로 저장\n",
    "            make_frame[k].append(v)\n",
    "\n",
    "    # dictionary 가 잘 만들어 졌는지 길이를 측정해서 확인해보세요!\n",
    "    print(len(json_datas['annotations']))\n",
    "    # dictionary to DataFrame\n",
    "    df = pd.DataFrame.from_dict(make_frame)\n",
    "    df.to_csv('./detection_info.csv',index=False)\n",
    "    print(df.head())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23144\n",
      "   id       file_name  class  x_min  y_min  x_max  y_max       area\n",
      "0   0  train/0000.jpg      0  197.6  193.7  745.4  663.4  257301.66\n",
      "1   1  train/0001.jpg      3    0.0  407.4   57.6  588.0   10402.56\n",
      "2   1  train/0001.jpg      7    0.0  455.6  144.6  637.2   26259.36\n",
      "3   1  train/0001.jpg      4  722.3  313.4  996.6  565.3   69096.17\n",
      "4   1  train/0001.jpg      5  353.2  671.0  586.9  774.4   24164.58\n"
     ]
    }
   ],
   "source": [
    "annotation = '../dataset/train.json' # annotation 경로\n",
    "train_df = make_dataframe(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "\n",
    "    #stratified_group_k_fold(train_x, train_y, groups, k=5)\n",
    "\n",
    "    labels_num = np.max(y) + 1 # class num ()\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num)) # 그룹마다 클래스의 수 분포를 파악\n",
    "    y_distr = Counter() # 모든 라벨의 개수를 세어서 dict 형태로 반환 \n",
    "\n",
    "    for label, g in zip(y, groups):\n",
    "        y_counts_per_group[g][label] += 1 # 그룹마다 라벨의 위치에 클래스 개수를 늘려준다.\n",
    "        y_distr[label] += 1 # 총 라벨의 개수 증가\n",
    "    #print(y_distr)\n",
    "\n",
    "    #print(y_counts_per_group[\"train/4882.jpg\"])\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num)) # fold마다 클래스의 수 분포를 파악\n",
    "    groups_per_fold = defaultdict(set) # fold별 group 만들기\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts # fold 하나에 Image label이 더해집니다. (계산하기 위한 용도?, Numpy는 list끼리 더하기가 가능하다.\n",
    "        std_per_label = []\n",
    "        #print(y_counts_per_fold[fold])\n",
    "        for label in range(labels_num): # 10개\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)]) # 모든 fold에 있는 라벨들에 대해 비율을 구하고 그 표준편차를 구한다.\n",
    "            std_per_label.append(label_std) # 라벨 당 표준편차들을 구합니다.\n",
    "            \n",
    "        y_counts_per_fold[fold] -= y_counts # fold당 모든 이미지의 라벨을 다시 뺴줍니다.\n",
    "        return np.mean(std_per_label)\n",
    "    \n",
    "    groups_and_y_counts = list(y_counts_per_group.items()) # list화  [file_name, label_list]\n",
    "    random.Random(seed).shuffle(groups_and_y_counts) # list random shuffle 섞을 필요가 있나? 밑에서 sort를 하는데..?\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])): # image당 라벨 개수들의 분포에 -표준편차를 기준으로 sort\n",
    "    #for g, y_counts in groups_and_y_counts:\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k): # k: fold 개수\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i) # group이 가지고 있는 라벨에서 / fold 별로 각 label의 표준 편차를 구하고 / 그룹에 있는 라벨들의 표준 편차의 평균을 구한다.\n",
    "            if min_eval is None or fold_eval < min_eval: # 라벨들의 표준편차 그리고 그에 평균 값이 가장 적은 곳에 best_fold를 해준다.\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "\n",
    "        # 결국 라벨들의 분포를 골고루 넣어주기 위한 과정\n",
    "\n",
    "        y_counts_per_fold[best_fold] += y_counts  # 폴드 당 라벨들의 합이 들어있따.\n",
    "        groups_per_fold[best_fold].add(g) # 폴드당 이미지들을 다 넣어줌\n",
    "\n",
    "    all_groups = set(groups) # 중복 그룹 제거\n",
    "    for i in range(k): # fold = 0, 1, 2, 3, 4 일 때,train/test group 만들기\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[\"id\"]\n",
    "train_y = train_df[\"class\"]\n",
    "groups = train_df[\"file_name\"]\n",
    "\n",
    "def get_distribution(y_vals):\n",
    "        y_distr = Counter(y_vals)\n",
    "        y_vals_sum = sum(y_distr.values())\n",
    "        return [f'{y_distr[i] / y_vals_sum:.2%}' for i in range(np.max(y_vals) + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# target 에 존재하는 train.json 파일을 엽니다.\n",
    "\n",
    "def make_json(fold_ind, dev_id_json, val_id_json):\n",
    "\n",
    "    train_path = \"/opt/ml/detection/dataset/train.json\"\n",
    "    train_file_name = f\"../dataset/fold_test/fold{fold_ind}_train.json\"\n",
    "    valid_file_name = f\"../dataset/fold_test/fold{fold_ind}_valid.json\"\n",
    "    \n",
    "    # print(fold_ind)\n",
    "    # print(dev_id_json[0])\n",
    "    # print(val_id_json[0])\n",
    "    with open(train_path, 'r') as f:\n",
    "        json_datas = json.load(f) # python dict 처럼 접근하게끔 변환\n",
    "    \t#dict_keys(['info', 'licenses', 'images', 'categories', 'annotations'])\n",
    "    # category = {}\n",
    "    # file_info = {}\n",
    "\n",
    "    info = json_datas[\"info\"]\n",
    "    licenses = json_datas[\"licenses\"]\n",
    "    categories = json_datas[\"licenses\"]\n",
    "\n",
    "    images_train = []\n",
    "    images_valid = []\n",
    "\n",
    "    annotations_train = []\n",
    "    annotations_valid = []\n",
    "\n",
    "    for item in json_datas[\"images\"]:\n",
    "        if item[\"id\"] in dev_id_json:\n",
    "            images_train.append(item)\n",
    "        elif item[\"id\"] in val_id_json:\n",
    "            images_valid.append(item)\n",
    "        else:\n",
    "            print(\"no id in images\")\n",
    "\n",
    "\n",
    "    for item in json_datas[\"annotations\"]:\n",
    "        if item[\"image_id\"] in dev_id_json:\n",
    "            annotations_train.append(item)\n",
    "        elif item[\"image_id\"] in val_id_json:\n",
    "            annotations_valid.append(item)\n",
    "        else:\n",
    "            print(\"no id in annotations\")\n",
    "\n",
    "    make_json_train = defaultdict(list)\n",
    "    make_json_valid = defaultdict(list)\n",
    "    make_json_train = {\"info\":info, \"licenses\" : licenses, \"images\": images_train, \"categories\":categories, \"annotations\":annotations_train}\n",
    "    make_json_valid = {\"info\":info, \"licenses\" : licenses, \"images\": images_valid, \"categories\":categories, \"annotations\":annotations_valid}\n",
    "\n",
    "    # 개수 파악\n",
    "    if len(json_datas[\"images\"]) != len(make_json_train[\"images\"]) + len(make_json_valid[\"images\"]):\n",
    "        print(\"images length, diff\")\n",
    "\n",
    "    if len(json_datas[\"annotations\"]) != len(make_json_train[\"annotations\"]) + len(make_json_valid[\"annotations\"]):\n",
    "        print(\"annotations length, diff\")\n",
    "\n",
    "    # 이름 중복 파악 - > 모든 성분 파악\n",
    "    # for item in make_json_train[\"images\"] (dict):\n",
    "    #     if item[\"file_name\"] in make_json_valid[\"images\"]:\n",
    "    #         print(\"same file name exist\")\n",
    "    \n",
    "    # for item in make_json_train[\"annotations\"]:\n",
    "    #     if item[\"file_name\"] in make_json_valid[\"annotations\"]:\n",
    "    #         print(\"same file name exist\")\n",
    "\n",
    "    #assert len(set(make_json_train[\"annotations\"]) & set(make_json_valid[\"annotations\"])) == 0\n",
    "\n",
    "    #print(make_json)\n",
    "    \n",
    "    \n",
    "    with open(train_file_name, 'w') as output:\n",
    "        json.dump(make_json_train, output, indent=2)\n",
    "\n",
    "    with open(valid_file_name, 'w') as output:\n",
    "        json.dump(make_json_valid, output, indent=2)\n",
    "\n",
    "    # train, valid 개수랑 겹치는 부분\n",
    "\n",
    "    \n",
    "\n",
    "# fold0_train_path = \"/opt/ml/detection/dataset/fold_test/fold0_train.json\"\n",
    "# fold0_val_path = \"/opt/ml/detection/dataset/fold_test/fold0_val.json\"\n",
    "\n",
    "# with open(fold0_train_path, 'w') as f:\n",
    "#     json.dump(dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distrs = [get_distribution(train_y)]\n",
    "index = ['training set']\n",
    "\n",
    "for fold_ind, (dev_ind, val_ind) in enumerate(stratified_group_k_fold(train_x, train_y, groups, k=5)):\n",
    "    # dev_ind, val_ind는 list 형태로 들어가서 Series형식의 id, Image id를 뽑는다.\n",
    "    dev_y, val_y = train_y[dev_ind], train_y[val_ind] # train index, \n",
    "    dev_groups, val_groups = groups[dev_ind], groups[val_ind] # Image id index,\n",
    "    dev_id, val_id = train_x[dev_ind], train_x[val_ind]\n",
    "\n",
    "    assert len(set(dev_groups) & set(val_groups)) == 0 # 가정 설정문,  동일한게 image file이 있는 지 확인 True이면 그대로 진행 아니라면 Assertion Error 생성\n",
    "    \n",
    "    distrs.append(get_distribution(dev_y))\n",
    "    index.append(f'development set - fold {fold_ind}')\n",
    "    distrs.append(get_distribution(val_y))\n",
    "    index.append(f'validation set - fold {fold_ind}')\n",
    "\n",
    "    #if fold_ind == 0:\n",
    "    #print(dev_id)\n",
    "    dev_id_json = list(set(dev_id))\n",
    "    val_id_json = list(set(val_id))\n",
    "    \n",
    "    make_json(fold_ind, dev_id_json, val_id_json)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution per class:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label 0</th>\n",
       "      <th>Label 1</th>\n",
       "      <th>Label 2</th>\n",
       "      <th>Label 3</th>\n",
       "      <th>Label 4</th>\n",
       "      <th>Label 5</th>\n",
       "      <th>Label 6</th>\n",
       "      <th>Label 7</th>\n",
       "      <th>Label 8</th>\n",
       "      <th>Label 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training set</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 0</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 0</th>\n",
       "      <td>17.13%</td>\n",
       "      <td>27.43%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.06%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>12.71%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.36%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 1</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.05%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 1</th>\n",
       "      <td>17.12%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 2</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.05%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>12.71%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 2</th>\n",
       "      <td>17.13%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.23%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.47%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 3</th>\n",
       "      <td>17.13%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 3</th>\n",
       "      <td>17.15%</td>\n",
       "      <td>27.46%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.71%</td>\n",
       "      <td>5.45%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 4</th>\n",
       "      <td>17.13%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 4</th>\n",
       "      <td>17.15%</td>\n",
       "      <td>27.47%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.45%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>0.67%</td>\n",
       "      <td>2.01%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Label 0 Label 1 Label 2 Label 3 Label 4 Label 5  \\\n",
       "training set              17.14%  27.45%   3.88%   4.04%   4.24%  12.72%   \n",
       "development set - fold 0  17.14%  27.45%   3.87%   4.04%   4.24%  12.72%   \n",
       "validation set - fold 0   17.13%  27.43%   3.88%   4.06%   4.25%  12.71%   \n",
       "development set - fold 1  17.14%  27.45%   3.87%   4.05%   4.24%  12.72%   \n",
       "validation set - fold 1   17.12%  27.44%   3.89%   4.04%   4.25%  12.72%   \n",
       "development set - fold 2  17.14%  27.45%   3.88%   4.05%   4.25%  12.71%   \n",
       "validation set - fold 2   17.13%  27.44%   3.87%   4.04%   4.23%  12.72%   \n",
       "development set - fold 3  17.13%  27.44%   3.88%   4.04%   4.24%  12.72%   \n",
       "validation set - fold 3   17.15%  27.46%   3.87%   4.04%   4.24%  12.71%   \n",
       "development set - fold 4  17.13%  27.44%   3.88%   4.04%   4.24%  12.72%   \n",
       "validation set - fold 4   17.15%  27.47%   3.87%   4.04%   4.24%  12.72%   \n",
       "\n",
       "                         Label 6 Label 7 Label 8 Label 9  \n",
       "training set               5.46%  22.37%   0.69%   2.02%  \n",
       "development set - fold 0   5.46%  22.38%   0.69%   2.02%  \n",
       "validation set - fold 0    5.46%  22.36%   0.69%   2.03%  \n",
       "development set - fold 1   5.46%  22.37%   0.69%   2.02%  \n",
       "validation set - fold 1    5.46%  22.37%   0.69%   2.03%  \n",
       "development set - fold 2   5.46%  22.37%   0.69%   2.02%  \n",
       "validation set - fold 2    5.47%  22.38%   0.69%   2.03%  \n",
       "development set - fold 3   5.46%  22.37%   0.69%   2.02%  \n",
       "validation set - fold 3    5.45%  22.38%   0.69%   2.01%  \n",
       "development set - fold 4   5.46%  22.37%   0.69%   2.02%  \n",
       "validation set - fold 4    5.45%  22.38%   0.67%   2.01%  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('Distribution per class:')\n",
    "pd.DataFrame(distrs, index=index, columns=[f'Label {l}' for l in range(np.max(train_y) + 1)]) # label의 구성 퍼센티지들을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dir = \"./fold4_retinanet_resnet50_fpn_8_0.3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2873370343.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_77754/2873370343.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    #print(predict_string)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(submission_dir)\n",
    "print(df.head())\n",
    "print(df[\"PredictionString\"].head())\n",
    "\n",
    "data_idx = 1\n",
    "img_id = df[\"image_id\"][data_idx]\n",
    "\n",
    "predict_string = df[\"PredictionString\"].iloc[data_idx].split(\" \")[:-1]\n",
    "\n",
    "for idx, coord in enumerate(predict_string):\n",
    "    if idx % 5 == 0:\n",
    "\n",
    "\n",
    "\n",
    "#print(predict_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b94c6de4bce9a87a354a5fa9998691adc0532adddb9d4140f5ba941d00b01fae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('detection': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

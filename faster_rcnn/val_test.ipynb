{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "# faster rcnn model이 포함된 library\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "      data_dir: data가 존재하는 폴더 경로\n",
    "      transforms: data transform (resize, crop, Totensor, etc,,,)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotation, data_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.predictions = {\n",
    "            \"images\": self.coco.dataset[\"images\"].copy(),\n",
    "            \"categories\": self.coco.dataset[\"categories\"].copy(),\n",
    "            \"annotations\": None\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "\n",
    "        # boxex (x_min, y_min, x_max, y_max)\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        # torchvision faster_rcnn은 label=0을 background로 취급\n",
    "        # class_id를 1~10으로 수정 \n",
    "        labels = np.array([x['category_id']+1 for x in anns]) \n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        areas = np.array([x['area'] for x in anns])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "                                \n",
    "        is_crowds = np.array([x['iscrowd'] for x in anns])\n",
    "        is_crowds = torch.as_tensor(is_crowds, dtype=torch.int64)\n",
    "\n",
    "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([index]), 'area': areas,\n",
    "                  'iscrowd': is_crowds}\n",
    "\n",
    "        # transform\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            target['boxes'] = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
    "\n",
    "        return image, target, image_id\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(1024, 1024),\n",
    "        A.Flip(p=0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def make_dataframe(target):\n",
    "    # target 에 존재하는 train.json 파일을 엽니다.\n",
    "    with open(target, 'r') as f:\n",
    "        json_datas = json.load(f) # python dict 처럼 접근하게끔 변환\n",
    "    \t\t#dict_keys(['info', 'licenses', 'images', 'categories', 'annotations'])\n",
    "\n",
    "    category = {}\n",
    "    file_info = {}\n",
    "    make_frame = defaultdict(list)\n",
    "\n",
    "    # 이미지 정보 중 파일 경로와 아이디만 추출해서 file_info 에 저장\n",
    "    for item in json_datas['images']:\n",
    "        file_info[item['id']] = {'id' : item['id'], 'file_name' : item['file_name']}\n",
    "    # 카테고리 정보를 category 에 저장\n",
    "    for item in json_datas['categories']:\n",
    "        category[item['id']] = item['name']\n",
    "    # annotations 에 속하는 아이템들을 images 에 속하는 아이템의 정보와 합치기 위함\n",
    "    for annotation in json_datas['annotations']:\n",
    "        save_dict = file_info[annotation['image_id']]\n",
    "        # 각 이미지에 해당하는 bounding box 정보와 class 정보 area(넓이) 정보를 추가\n",
    "        bbox = np.array(annotation['bbox'])\n",
    "        bbox[2] = bbox[2] + bbox[0]\n",
    "        bbox[3] = bbox[3] + bbox[1]\n",
    "        save_dict.update({\n",
    "            'class': annotation['category_id'], # 배경은 0, 나머지 +1 in faster_rcnn\n",
    "            'x_min': bbox[0],\n",
    "            'y_min': bbox[1],\n",
    "            'x_max': bbox[2],\n",
    "            'y_max': bbox[3],\n",
    "            'area':annotation['area']\n",
    "            })\n",
    "\n",
    "        for k,v in save_dict.items():\n",
    "            # dataframe 으로 만들기 위해서 'key' : [item1,item2...] 형태로 저장\n",
    "            make_frame[k].append(v)\n",
    "\n",
    "    # dictionary 가 잘 만들어 졌는지 길이를 측정해서 확인해보세요!\n",
    "    print(len(json_datas['annotations']))\n",
    "    # dictionary to DataFrame\n",
    "    df = pd.DataFrame.from_dict(make_frame)\n",
    "    df.to_csv('./detection_info.csv',index=False)\n",
    "    print(df.head())\n",
    "\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "annotation = '../dataset/train.json' # annotation 경로\n",
    "data_dir = '../dataset' # data_dir 경로\n",
    "train_df = make_dataframe(annotation)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23144\n",
      "   id       file_name  class  x_min  y_min  x_max  y_max       area\n",
      "0   0  train/0000.jpg      0  197.6  193.7  745.4  663.4  257301.66\n",
      "1   1  train/0001.jpg      3    0.0  407.4   57.6  588.0   10402.56\n",
      "2   1  train/0001.jpg      7    0.0  455.6  144.6  637.2   26259.36\n",
      "3   1  train/0001.jpg      4  722.3  313.4  996.6  565.3   69096.17\n",
      "4   1  train/0001.jpg      5  353.2  671.0  586.9  774.4   24164.58\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def stratified_group_k_fold(X, y, groups, k, seed=None):\n",
    "    labels_num = np.max(train_y) + 1 # class num ()\n",
    "    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num)) # 그룹마다 클래스의 수 분포를 파악\n",
    "    y_distr = Counter() # 모든 라벨의 개수를 세어서 dict 형태로 반환 \n",
    "\n",
    "    for label, g in zip(train_y, groups):\n",
    "        y_counts_per_group[g][label] += 1 # 그룹마다 라벨의 위치에 클래스 개수를 늘려준다.\n",
    "        y_distr[label] += 1 # 라벨의 개수 증가\n",
    "    #print(y_counts_per_group[\"train/4882.jpg\"])\n",
    "    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num)) # fold마다 클래스의 수 분포를 파악\n",
    "    groups_per_fold = defaultdict(set) # fold별 group 만들기\n",
    "\n",
    "    def eval_y_counts_per_fold(y_counts, fold):\n",
    "        y_counts_per_fold[fold] += y_counts\n",
    "        std_per_label = []\n",
    "        for label in range(labels_num):\n",
    "            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n",
    "            std_per_label.append(label_std)\n",
    "        y_counts_per_fold[fold] -= y_counts\n",
    "        return np.mean(std_per_label)\n",
    "    \n",
    "    groups_and_y_counts = list(y_counts_per_group.items())\n",
    "\n",
    "    random.Random(seed).shuffle(groups_and_y_counts)\n",
    "\n",
    "    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "        best_fold = None\n",
    "        min_eval = None\n",
    "        for i in range(k):\n",
    "            fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "            if min_eval is None or fold_eval < min_eval:\n",
    "                min_eval = fold_eval\n",
    "                best_fold = i\n",
    "        y_counts_per_fold[best_fold] += y_counts\n",
    "        groups_per_fold[best_fold].add(g)\n",
    "\n",
    "    all_groups = set(groups)\n",
    "    for i in range(k):\n",
    "        train_groups = all_groups - groups_per_fold[i]\n",
    "        test_groups = groups_per_fold[i]\n",
    "\n",
    "        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "        yield train_indices, test_indices\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_x = train_df[\"id\"]\n",
    "train_y = train_df[\"class\"]\n",
    "groups = train_df[\"file_name\"]\n",
    "\n",
    "def get_distribution(y_vals):\n",
    "        y_distr = Counter(y_vals)\n",
    "        y_vals_sum = sum(y_distr.values())\n",
    "        return [f'{y_distr[i] / y_vals_sum:.2%}' for i in range(np.max(y_vals) + 1)]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\n",
    "distrs = [get_distribution(train_y)]\n",
    "index = ['training set']\n",
    "\n",
    "for fold_ind, (dev_ind, val_ind) in enumerate(stratified_group_k_fold(train_x, train_y, groups, k=5)):\n",
    "    dev_y, val_y = train_y[dev_ind], train_y[val_ind]\n",
    "    dev_groups, val_groups = groups[dev_ind], groups[val_ind]\n",
    "    \n",
    "    assert len(set(dev_groups) & set(val_groups)) == 0\n",
    "    \n",
    "    distrs.append(get_distribution(dev_y))\n",
    "    index.append(f'development set - fold {fold_ind}')\n",
    "    distrs.append(get_distribution(val_y))\n",
    "    index.append(f'validation set - fold {fold_ind}')\n",
    "\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\n",
    "print('Distribution per class:')\n",
    "pd.DataFrame(distrs, index=index, columns=[f'Label {l}' for l in range(np.max(train_y) + 1)])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Distribution per class:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label 0</th>\n",
       "      <th>Label 1</th>\n",
       "      <th>Label 2</th>\n",
       "      <th>Label 3</th>\n",
       "      <th>Label 4</th>\n",
       "      <th>Label 5</th>\n",
       "      <th>Label 6</th>\n",
       "      <th>Label 7</th>\n",
       "      <th>Label 8</th>\n",
       "      <th>Label 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training set</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 0</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 0</th>\n",
       "      <td>17.13%</td>\n",
       "      <td>27.43%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.06%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>12.71%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.36%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 1</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.05%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 1</th>\n",
       "      <td>17.12%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 2</th>\n",
       "      <td>17.14%</td>\n",
       "      <td>27.45%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.05%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>12.71%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 2</th>\n",
       "      <td>17.13%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.23%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.47%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 3</th>\n",
       "      <td>17.13%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 3</th>\n",
       "      <td>17.15%</td>\n",
       "      <td>27.46%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.71%</td>\n",
       "      <td>5.45%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 4</th>\n",
       "      <td>17.13%</td>\n",
       "      <td>27.44%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.46%</td>\n",
       "      <td>22.37%</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>2.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 4</th>\n",
       "      <td>17.15%</td>\n",
       "      <td>27.47%</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>4.24%</td>\n",
       "      <td>12.72%</td>\n",
       "      <td>5.45%</td>\n",
       "      <td>22.38%</td>\n",
       "      <td>0.67%</td>\n",
       "      <td>2.01%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Label 0 Label 1 Label 2 Label 3 Label 4 Label 5  \\\n",
       "training set              17.14%  27.45%   3.88%   4.04%   4.24%  12.72%   \n",
       "development set - fold 0  17.14%  27.45%   3.87%   4.04%   4.24%  12.72%   \n",
       "validation set - fold 0   17.13%  27.43%   3.88%   4.06%   4.25%  12.71%   \n",
       "development set - fold 1  17.14%  27.45%   3.87%   4.05%   4.24%  12.72%   \n",
       "validation set - fold 1   17.12%  27.44%   3.89%   4.04%   4.25%  12.72%   \n",
       "development set - fold 2  17.14%  27.45%   3.88%   4.05%   4.25%  12.71%   \n",
       "validation set - fold 2   17.13%  27.44%   3.87%   4.04%   4.23%  12.72%   \n",
       "development set - fold 3  17.13%  27.44%   3.88%   4.04%   4.24%  12.72%   \n",
       "validation set - fold 3   17.15%  27.46%   3.87%   4.04%   4.24%  12.71%   \n",
       "development set - fold 4  17.13%  27.44%   3.88%   4.04%   4.24%  12.72%   \n",
       "validation set - fold 4   17.15%  27.47%   3.87%   4.04%   4.24%  12.72%   \n",
       "\n",
       "                         Label 6 Label 7 Label 8 Label 9  \n",
       "training set               5.46%  22.37%   0.69%   2.02%  \n",
       "development set - fold 0   5.46%  22.38%   0.69%   2.02%  \n",
       "validation set - fold 0    5.46%  22.36%   0.69%   2.03%  \n",
       "development set - fold 1   5.46%  22.37%   0.69%   2.02%  \n",
       "validation set - fold 1    5.46%  22.37%   0.69%   2.03%  \n",
       "development set - fold 2   5.46%  22.37%   0.69%   2.02%  \n",
       "validation set - fold 2    5.47%  22.38%   0.69%   2.03%  \n",
       "development set - fold 3   5.46%  22.37%   0.69%   2.02%  \n",
       "validation set - fold 3    5.45%  22.38%   0.69%   2.01%  \n",
       "development set - fold 4   5.46%  22.37%   0.69%   2.02%  \n",
       "validation set - fold 4    5.45%  22.38%   0.67%   2.01%  "
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('detection': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "29b0cbc8c2bc4924fb253dd9334aba0cc9ad3225fd824ea55dea16089b664698"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
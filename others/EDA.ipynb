{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f905b9a0-afba-4a2e-b88d-28fb416751bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'images', 'categories', 'annotations'])\n",
      "23144\n",
      "         id       file_name  class      x      y      w      h       area  \\\n",
      "0         0  train/0000.jpg      0  197.6  193.7  547.8  469.7  257301.66   \n",
      "1         1  train/0001.jpg      3    0.0  407.4   57.6  180.6   10402.56   \n",
      "2         1  train/0001.jpg      7    0.0  455.6  144.6  181.6   26259.36   \n",
      "3         1  train/0001.jpg      4  722.3  313.4  274.3  251.9   69096.17   \n",
      "4         1  train/0001.jpg      5  353.2  671.0  233.7  103.4   24164.58   \n",
      "...     ...             ...    ...    ...    ...    ...    ...        ...   \n",
      "23139  4882  train/4882.jpg      5    0.0  116.2  944.1  814.1  768591.81   \n",
      "23140  4882  train/4882.jpg      7  302.1  439.3  265.2  216.1   57309.72   \n",
      "23141  4882  train/4882.jpg      0  511.3  451.1   58.7   30.2    1772.74   \n",
      "23142  4882  train/4882.jpg      1  255.0  421.4  271.7  195.1   53008.67   \n",
      "23143  4882  train/4882.jpg      1  145.4  295.4  420.2  356.1  149633.22   \n",
      "\n",
      "          ratio  \n",
      "0      0.857430  \n",
      "1      3.135417  \n",
      "2      1.255878  \n",
      "3      0.918338  \n",
      "4      0.442448  \n",
      "...         ...  \n",
      "23139  0.862303  \n",
      "23140  0.814857  \n",
      "23141  0.514480  \n",
      "23142  0.718071  \n",
      "23143  0.847454  \n",
      "\n",
      "[23144 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "target = './detection/dataset/train.json'\n",
    "category = {}\n",
    "file_info = {}\n",
    "make_frame = defaultdict(list)\n",
    "\n",
    "# target 에 존재하는 train.json 파일을 엽니다.\n",
    "with open(target, 'r') as f:\n",
    "    json_datas = json.load(f) # python dict 처럼 접근하게끔 변환\n",
    "\n",
    "    print(json_datas.keys())\n",
    "    #dict_keys(['info', 'licenses', 'images', 'categories', 'annotations'])\n",
    "\n",
    "    # 이미지 정보 중 파일 경로와 아이디만 추출해서 file_info 에 저장\n",
    "    for item in json_datas['images']:\n",
    "        file_info[item['id']] = {'id' : item['id'], 'file_name' : item['file_name']}\n",
    "\n",
    "    # 카테고리 정보를 category 에 저장\n",
    "    for item in json_datas['categories']:\n",
    "        category[item['id']] = item['name']\n",
    "\n",
    "    # annotations 에 속하는 아이템들을 images 에 속하는 아이템의 정보와 합치기 위함\n",
    "    for annotation in json_datas['annotations']:\n",
    "        save_dict = file_info[annotation['image_id']]\n",
    "        \n",
    "        # 각 이미지에 해당하는 bounding box 정보와 class 정보 area(넓이) 정보를 추가\n",
    "        save_dict.update({\n",
    "            'class':annotation['category_id'],\n",
    "            'x': annotation['bbox'][0],\n",
    "            'y': annotation['bbox'][1],\n",
    "            'w': annotation['bbox'][2],\n",
    "            'h': annotation['bbox'][3],\n",
    "            'area': annotation['area'],\n",
    "            'ratio': annotation['bbox'][3] / annotation['bbox'][2]\n",
    "            })\n",
    "\n",
    "        for k,v in save_dict.items():\n",
    "            # dataframe 으로 만들기 위해서 'key' : [item1,item2...] 형태로 저장\n",
    "            make_frame[k].append(v)\n",
    "    # print(make_frame)\n",
    "\n",
    "    # dictionary 가 잘 만들어 졌는지 길이를 측정해서 확인해보세요!\n",
    "    print(len(json_datas['annotations']))\n",
    "    # dictionary to DataFrame\n",
    "    a = pd.DataFrame.from_dict(make_frame)\n",
    "    # index 를 제외하고 csv 파일로 저장\n",
    "    a.to_csv('detection_info.csv',index=False)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2eb535a0-49ba-42ba-a746-585f29a52e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    23144.000000\n",
       "mean         1.207635\n",
       "std          0.986826\n",
       "min          0.036649\n",
       "25%          0.650489\n",
       "50%          0.954637\n",
       "75%          1.446871\n",
       "max         18.053571\n",
       "Name: ratio, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dc8a8-d9db-49d7-ba5e-ce3384601ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689ab429-af97-460f-adac-b517d4e1c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = './detection/dataset/train.json'\n",
    "category = {}\n",
    "file_info = {}\n",
    "make_frame = defaultdict(list)\n",
    "\n",
    "# target 에 존재하는 train.json 파일을 엽니다.\n",
    "with open(target, 'r') as f:\n",
    "    json_datas = json.load(f) # python dict 처럼 접근하게끔 변환\n",
    "\n",
    "    # 이미지 정보 중 파일 경로와 아이디만 추출해서 file_info 에 저장\n",
    "    for item in json_datas['images']:\n",
    "        file_info[item['id']] = {'id' : item['id'], 'file_name' : item['file_name']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c668c-a5e3-4286-99d9-a2bad35bab64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "248f6bed-4430-4dc8-b281-a7dc4a8606c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def get_img_stats(img_dir, img_ids):\n",
    "    \"\"\"\n",
    "    데이터셋에 있는 이미지들의 크기와 RGB 평균 및 표준편차를 수집하는 함수입니다.\n",
    "    \n",
    "    Args:\n",
    "        img_dir: 학습 데이터셋 이미지 폴더 경로 \n",
    "        img_ids: 학습 데이터셋 하위폴더 이름들\n",
    "\n",
    "    Returns:\n",
    "        img_info: 이미지들의 정보 (크기, 평균, 표준편차)\n",
    "    \"\"\"\n",
    "    img_info = dict(heights=[], widths=[], means=[], stds=[])\n",
    "    for img_id in tqdm(img_ids):\n",
    "        img = np.array(Image.open(os.path.join(img_dir, img_id)))\n",
    "        h, w, _ = img.shape\n",
    "        img_info['heights'].append(h)\n",
    "        img_info['widths'].append(w)\n",
    "        img_info['means'].append(img.mean(axis=(0,1)))\n",
    "        img_info['stds'].append(img.std(axis=(0,1)))\n",
    "    return img_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06911dd3-0074-457d-b6d1-e99ae691d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4883\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "FilePath = []\n",
    "\n",
    "# print(file_info)\n",
    "\n",
    "for file in file_info.values():\n",
    "    FilePath.append(file['file_name'])\n",
    "    \n",
    "print(len(FilePath))\n",
    "print(type(FilePath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a99b1a41-75fc-45db-ae49-05459023326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './detection/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0eeac8ea-6c06-454a-9106-10543566a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:26<00:00,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Mean: [0.48490459 0.46038158 0.43166834]\n",
      "RGB Standard Deviation: [0.21190031 0.20929289 0.21483885]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_info = get_img_stats(img_dir, FilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81ff0bdd-1762-48ed-9070-65ee3497bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Mean: [123.6506697  117.39730243 110.07542563]\n",
      "RGB Standard Deviation: [54.03457934 53.36968771 54.78390763]\n"
     ]
    }
   ],
   "source": [
    "print(f'RGB Mean: {np.mean(img_info[\"means\"], axis=0)}')\n",
    "print(f'RGB Standard Deviation: {np.mean(img_info[\"stds\"], axis=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7c9f3-2662-4132-bfce-dba3b43daff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c48cf-7e91-40f5-90a1-349db5bf7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detection",
   "language": "python",
   "name": "detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
